[
  {
    "objectID": "qmd/chicago.html",
    "href": "qmd/chicago.html",
    "title": "Chicago Analysis",
    "section": "",
    "text": "Imports\n%matplotlib inline\nimport matplotlib_inline\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport warnings\n\nimport matplotlib.pyplot as plt\n\n# from enrich.console import Console, get_theme\nfrom ClimRR import get_logger, DATA_DIR, set_plot_style\nmatplotlib_inline.backend_inline.set_matplotlib_formats('svg')\nset_plot_style()\nlog = get_logger('ClimRR')\nfrom rich.console import Console as rConsole\nfrom enrich.style import STYLES\nfrom rich.theme import Theme\n\ntheme = Theme(STYLES)\nlog = get_logger('ClimRR')\nconsole = rConsole(theme=theme, log_path=False, markup=True)\n\n\nUsing updated plot style for matplotlib\n\n\n\n\n\nCode\nfrom ClimRR import load_shapefile, load_csvs\n\nshape = load_shapefile()\ndata = load_csvs(shape)\n\n\ndata['FireWeatherIndex_Wildfire'].shape=(62834, 35)\n\n\n\ndata['HeatingDegreeDays'].shape=(62834, 10)\n\n\n\ndata['AnnualTemperatureMinimum'].shape=(62834, 18)\n\n\n\ndata['SeasonalTemperatureMaximum'].shape=(62834, 27)\n\n\n\ndata['ConsecutiveDayswithNoPrecipitation'].shape=(55896, 19)\n\n\n\ndata['SeasonalTemperatureMinimum'].shape=(62834, 27)\n\n\n\ndata['WindSpeed'].shape=(62834, 18)\n\n\n\ndata['AnnualTemperatureMaximum'].shape=(62834, 18)\n\n\n\ndata['Precipitation_inches_AnnualTotal'].shape=(55896, 18)\n\n\n\n\n\nCode\nsquare = shape[shape[\"Crossmodel\"] == 'R146C497']\nsquare.explore()\n\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n\nCode\nimport geodatasets\nchipop = gpd.read_file(\n    geodatasets.get_path('geoda.chicago_commpop')\n).to_crs(square.crs)\nchihealth = gpd.read_file(\n    geodatasets.get_path('geoda.chicago_health')\n).to_crs(square.crs)\nchigroc = gpd.read_file(\n    geodatasets.get_path('geoda.groceries')\n).to_crs(square.crs)\n\n\n\n\nCode\nfig, ax = plt.subplots(figsize=(10, 7))\nax = chipop.to_crs(square.crs).plot(column=\"POP2010\", legend=True, ax=ax)\nax.set_axis_off()\n_ = ax.set_title(f\"Chicago population by Neighborhood [2010]\")\n\n\n\n\n\n\n\nCode\nchipop['boundary'] = chipop.boundary\n\n\n\n\nCode\nfig, ax = plt.subplots(figsize=(10, 7))\nax = chipop.boundary.plot(linewidth=0.8, color='#838383', ax=ax)\nax.set_axis_off()\n_ = ax.set_title('Chicago Neighborhoods')\n\n\n\n\n\n\n\nCode\nwtown = chipop[chipop[\"community\"] == 'WEST TOWN']\nhumboldt = chipop[chipop[\"community\"] == 'HUMBOLDT PARK']\n\n\n\n\nCode\nhumboldt.explore()\n\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n\nCode\nfig, ax = plt.subplots(figsize=(10, 7))\nax = humboldt.overlay(shape, how='intersection').plot(ax=ax, legend=True)\nax = (\n    hp := chipop[chipop['community'] == 'HUMBOLDT PARK'].overlay(\n        shape,\n        how='intersection'\n    )\n).plot(ax=ax, legend=True)\nax = (\n    lp := chipop[chipop['community'] == 'LINCOLN PARK'].overlay(\n        shape,\n        how='intersection'\n    )\n).plot(ax=ax, legend=True)\nax = chipop.boundary.plot(ax=ax, color='#666666', linewidth=0.8)\nax = lp.boundary.plot(color='red', ax=ax)\nax = hp.boundary.plot(color='red', ax=ax)\nax.set_axis_off()\n_ = ax.set_title('Intersection of Humboldt Park & ClimRR data')\n\n\n\n\n\n\n\nCode\nfig, ax = plt.subplots(figsize=(10, 7))\nchiwind = data['WindSpeed'].overlay(\n    chipop,\n    how='intersection'\n).overlay(chipop, how='union')\nax = chiwind.boundary.plot(ax=ax, color='#666666', linewidth=0.8)\nax.set_axis_off()\n\n\n\n\n\n\n\nCode\n_, ax = plt.subplots(figsize=(10, 7))\nax = chipop.boundary.plot(color='#666666', linewidth=0.8, ax=ax, alpha=0.2)\nax = chiwind.plot(column='hist', ax=ax, legend=True)\nax.set_axis_off()\nax.set_title('Historical Wind Data across Chicago Neighborhoods')\nplt.tight_layout()\n\n\n\n\n\n\n\nCode\nchiwind.explore(column='hist')\n\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n\nCode\n_, ax = plt.subplots()\nax = chiwind.plot(column='hist', scheme='quantiles', k=8, ax=ax)\n_ = ax.set_title('WindSpeed, historical')\nax.set_axis_off()\nplt.tight_layout()\n\n\n\n\n\n\n\nCode\nfig, ax = plt.subplots()\nax = chiwind.plot(column='rcp45_midc', scheme='quantiles', k=3, ax=ax)\nax.set_axis_off()\n_ = ax.set_title('WindSpeed, Mid-Century [RCP45]')\nplt.tight_layout()\n\n\n\n\n\n\n\nCode\nfig, ax = plt.subplots()\nax = chiwind.plot(column='rcp45_endc', scheme='quantiles', k=3, ax=ax)\n_ = ax.set_title('WindSpeed, End-Century [RCP45]')\nplt.tight_layout()\n\n\n\n\n\n\n\nCode\nfig, ax = plt.subplots(ncols=3, figsize=(16, 7))\nax0 = chiwind.plot('hist', ax=ax[0])\nax1 = chiwind.plot('rcp45_midc', ax=ax[1])\nax2 = chiwind.plot('rcp45_midc', ax=ax[2])\nax0.set_axis_off()\nax1.set_axis_off()\nax2.set_axis_off()\n\n\n\n\n\n\n\nCode\ndata['WindSpeed'].shape\n\n\n(62834, 18)\n\n\n\n\nCode\nselection = shape[0:5]\n\nfor index, row in selection.iterrows():\n    # get the area of the polygon\n    poly_area = row['geometry'].area\n    console.print(f\"Polygon area at {index} is {poly_area:.3f}\")\n\n\nPolygon area at 0 is 252927293.657\n\n\n\nPolygon area at 1 is 235501313.715\n\n\n\nPolygon area at 2 is 233416379.950\n\n\n\nPolygon area at 3 is 261761834.191\n\n\n\nPolygon area at 4 is 226073092.218\n\n\n\n\n\n\nCitationBibTeX citation:@misc{foreman2023,\n  author = {Foreman, Sam},\n  date = {2023-07-13},\n  url = {https://saforem2.github.io/climate-analysis},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nForeman, Sam. 2023. Intro to HPC: Climate Analysis with ClimRR.\nhttps://saforem2.github.io/climate-analysis."
  },
  {
    "objectID": "qmd/ClimRR.html",
    "href": "qmd/ClimRR.html",
    "title": "Climate Analysis with ClimRR",
    "section": "",
    "text": "We use GeoPandas, an open source project to make working with geospatial data in python easier. GeoPandas extends the datatypes used by pandas to allow spatial operations on geometric types.\nGeometric operations are performed by shapely.\nGeoPandas further depends on fiona and matplotlib for plotting.\nGeoPandas can read almost any vector-based spatial data format including ESRI shapefile, GeoJSON files and more using the command\nimport geopandas as gpd\ngpd.read_file()\nwhich returns a GeoDataFrame object.\nA GeoDataFrame is a tabular data structure that contains a GeoSeries.\nThe most important property of a GeoDataFrame is that it always has one GeoSeries column that holds a special status.\nThis GeoSeries is referred to as the GeoDataFrame’s “geometry”. When a spatial method is applied to a GeoDataFrame (or a spatial attribute like area is called), this commands will always act on the “geometry” column1.\n\n\n\n\n\nImports\n%matplotlib inline\nimport matplotlib_inline\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport warnings\n\nimport matplotlib.pyplot as plt\n\nfrom enrich.style import STYLES\nfrom rich.theme import Theme\nfrom rich.console import Console as rConsole\nfrom ClimRR import get_logger, DATA_DIR, set_plot_style\n\nmatplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n\nset_plot_style()\ntheme = Theme(STYLES)\nlog = get_logger()\nconsole = rConsole(theme=Theme(STYLES), log_path=False, markup=True, width=512)\n\n\nUsing updated plot style for matplotlib"
  },
  {
    "objectID": "qmd/ClimRR.html#getting-started",
    "href": "qmd/ClimRR.html#getting-started",
    "title": "Climate Analysis with ClimRR",
    "section": "",
    "text": "We use GeoPandas, an open source project to make working with geospatial data in python easier. GeoPandas extends the datatypes used by pandas to allow spatial operations on geometric types.\nGeometric operations are performed by shapely.\nGeoPandas further depends on fiona and matplotlib for plotting.\nGeoPandas can read almost any vector-based spatial data format including ESRI shapefile, GeoJSON files and more using the command\nimport geopandas as gpd\ngpd.read_file()\nwhich returns a GeoDataFrame object.\nA GeoDataFrame is a tabular data structure that contains a GeoSeries.\nThe most important property of a GeoDataFrame is that it always has one GeoSeries column that holds a special status.\nThis GeoSeries is referred to as the GeoDataFrame’s “geometry”. When a spatial method is applied to a GeoDataFrame (or a spatial attribute like area is called), this commands will always act on the “geometry” column1.\n\n\n\n\n\nImports\n%matplotlib inline\nimport matplotlib_inline\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport warnings\n\nimport matplotlib.pyplot as plt\n\nfrom enrich.style import STYLES\nfrom rich.theme import Theme\nfrom rich.console import Console as rConsole\nfrom ClimRR import get_logger, DATA_DIR, set_plot_style\n\nmatplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n\nset_plot_style()\ntheme = Theme(STYLES)\nlog = get_logger()\nconsole = rConsole(theme=Theme(STYLES), log_path=False, markup=True, width=512)\n\n\nUsing updated plot style for matplotlib"
  },
  {
    "objectID": "qmd/ClimRR.html#load-shapefile-and-inspect",
    "href": "qmd/ClimRR.html#load-shapefile-and-inspect",
    "title": "Climate Analysis with ClimRR",
    "section": "Load Shapefile and inspect",
    "text": "Load Shapefile and inspect\nA shapefile is provided in the ClimRR Data Download (ANL) and can be loaded using geopandas.read_file(...) which will return a geopandas.GeoDataFrame:\n\nshpfile = DATA_DIR.joinpath(\n    \"GridCells2Shapefile/GridCellsShapefile/GridCells.shp\"\n)\nshape = gpd.read_file(shpfile)\n\nEach entry in this table defines a single grid cell (12km x 12 km) which collectively tile the United States.\nWe can get a better understanding of whats going on by looking at the first few entries:\n\nshape.head(n=2)\n\n\n\n\n\n\n\n\nOBJECTID\nCrossmodel\nShape_Leng\nShape_Area\ngeometry\n\n\n\n\n0\n1\nR161C438\n63614.764866\n2.529273e+08\nPOLYGON ((-9530601.177 4726046.614, -9534793.8...\n\n\n1\n2\nR125C222\n61384.219597\n2.355013e+08\nPOLYGON ((-12959076.287 4395610.472, -12974301...\n\n\n\n\n\n\n\nWe see that each row has the following columns: {OBJECTID, Crossmodel, Shape_Leng, Shape_Area, geometry}.\nIn particular, the Crossmodel2 column is a text ID that uniquely identifies an individual cell.\nTo be explicit, let’s look at the WindSpeed.csv file."
  },
  {
    "objectID": "qmd/ClimRR.html#tiling-the-us-cells-grids",
    "href": "qmd/ClimRR.html#tiling-the-us-cells-grids",
    "title": "Climate Analysis with ClimRR",
    "section": "1.2 Tiling the US: Cells + Grids",
    "text": "1.2 Tiling the US: Cells + Grids\nOur shapefile contains a grid of cells (12km x 12km) which tile the continental US.\nWe can inspect a single cell:\n\n\nCode\nsquare = shape[shape[\"Crossmodel\"] == 'R146C497']\nsquare.explore()\n\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "qmd/ClimRR.html#load-data-from-.csv-files",
    "href": "qmd/ClimRR.html#load-data-from-.csv-files",
    "title": "Climate Analysis with ClimRR",
    "section": "Load data from *.csv files",
    "text": "Load data from *.csv files\nEach entry (row) in the .csv has a Crossmodel column (e.g. R146C497) which corresponds to a row in our shapefile that uniquely determines its location on the Earth.\nWe can associate with each of the .csvs the geometry used in our shapefile to position our data on the globe.\n\nimport pandas as pd\ncsvs = [i for i in DATA_DIR.joinpath('csv').rglob('*.csv')]\ndata = {}\nfor f in csvs:\n    key = f.stem\n    tmp = pd.read_csv(f.as_posix())\n    gdf = shape.merge(tmp, on='Crossmodel')\n    gdf['boundary'] = gdf.boundary\n    gdf['centroid'] = gdf.centroid\n    data[key] = gdf\n    console.log(f\"data['{key}'].shape={data[key].shape}\")\n\n[14:26:44] data['FireWeatherIndex_Wildfire'].shape=(62834, 35)                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n\n\n\n           data['HeatingDegreeDays'].shape=(62834, 10)                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n\n\n\n[14:26:45] data['AnnualTemperatureMinimum'].shape=(62834, 18)                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n\n\n\n           data['SeasonalTemperatureMaximum'].shape=(62834, 27)                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n\n\n\n           data['ConsecutiveDayswithNoPrecipitation'].shape=(55896, 19)                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n\n\n\n           data['SeasonalTemperatureMinimum'].shape=(62834, 27)                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n\n\n\n           data['WindSpeed'].shape=(62834, 18)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n\n\n\n           data['AnnualTemperatureMaximum'].shape=(62834, 18)                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n\n\n\n[14:26:46] data['Precipitation_inches_AnnualTotal'].shape=(55896, 18)"
  },
  {
    "objectID": "qmd/ClimRR.html#look-at-the-windspeed-data",
    "href": "qmd/ClimRR.html#look-at-the-windspeed-data",
    "title": "Climate Analysis with ClimRR",
    "section": "Look at the WindSpeed data",
    "text": "Look at the WindSpeed data\nLets inspect one of the entries in our data[(...)] dictionary, WindSpeed, for example:\n\ndata[\"WindSpeed\"].head()\n\n\n\n\n\n\n\n\nOBJECTID\nCrossmodel\nShape_Leng\nShape_Area\ngeometry\nhist\nrcp45_midc\nrcp45_endc\nrcp85_midc\nrcp85_endc\nmid45_hist\nend45_hist\nmid85_hist\nend85_hist\nmid85_45\nend85_45\nboundary\ncentroid\n\n\n\n\n0\n1\nR161C438\n63614.764866\n2.529273e+08\nPOLYGON ((-9530601.177 4726046.614, -9534793.8...\n7.21540\n7.19415\n7.38917\n7.30470\n7.22690\n-0.021256\n0.173764\n0.089297\n0.011499\n0.110553\n-0.162264\nLINESTRING (-9530601.177 4726046.614, -9534793...\nPOINT (-9540369.710 4720470.575)\n\n\n1\n2\nR125C222\n61384.219597\n2.355013e+08\nPOLYGON ((-12959076.287 4395610.472, -12974301...\n8.32612\n8.11360\n8.26028\n8.17420\n8.02081\n-0.212523\n-0.065843\n-0.151919\n-0.305307\n0.060603\n-0.239465\nLINESTRING (-12959076.287 4395610.472, -129743...\nPOINT (-12967596.341 4402326.143)\n\n\n2\n3\nR121C235\n61111.892875\n2.334164e+08\nPOLYGON ((-12754805.395 4355815.951, -12770000...\n8.58573\n8.59828\n8.56058\n8.54483\n8.55421\n0.012547\n-0.025149\n-0.040898\n-0.031519\n-0.053446\n-0.006370\nLINESTRING (-12754805.395 4355815.951, -127700...\nPOINT (-12763132.114 4362694.465)\n\n\n3\n4\nR169C431\n64716.234995\n2.617618e+08\nPOLYGON ((-9605729.481 4879238.815, -9609863.1...\n9.17284\n9.21681\n9.44966\n9.26548\n9.14917\n0.043968\n0.276813\n0.092635\n-0.023674\n0.048667\n-0.300487\nLINESTRING (-9605729.481 4879238.815, -9609863...\nPOINT (-9615619.029 4873482.586)\n\n\n4\n5\nR146C497\n60142.919468\n2.260731e+08\nPOLYGON ((-8733007.764 4224658.634, -8738250.3...\n8.25430\n8.19130\n8.34417\n8.29698\n8.29411\n-0.062996\n0.089874\n0.042684\n0.039807\n0.105680\n-0.050067\nLINESTRING (-8733007.764 4224658.634, -8738250...\nPOINT (-8742676.917 4220233.536)\n\n\n\n\n\n\n\nWe see that each entry has a geometry column, as well as columns for {hist,rcp45_midc, rcp45_endc, rcp85_midc, rcp85_endc, ...} which contains the numerical value of the WindSpeed in each cell under different scenarios at different points in time.\n\nLet’s look at the WindSpeed for our individual cell:\n\ncell_wind = data[\"WindSpeed\"][data[\"WindSpeed\"][\"Crossmodel\"] == 'R146C497']\n\n\nax = cell_wind.plot(column='hist', legend=True)\nax.set_axis_off()\n_ = ax.set_title(\"WindSpeed [Hist] for CELL: R146C497\")\n\n\n\n\n\n\n\n\nCode\nfig, ax = plt.subplots(\n    figsize=(12, 3.5),\n    nrows=1,\n    ncols=3,\n    sharey='row'\n)\nax = ax.flatten()\npairs = {\n    '1k': list(range(1000)),\n    '5k': list(range(5000)),\n    '20k': list(range(20000)),\n}\nfor idx, (key, val) in enumerate(pairs.items()):\n    ax[idx] = shape.loc[val, :].plot(ax=ax[idx])\n    ax[idx].set_axis_off()\n    _ = ax[idx].set_title(f\"First {key} cells\")\nplt.tight_layout()\n\n\n\n\n\nFigure 1: As we include more cells, we see the outline of the US beginning to take shape."
  },
  {
    "objectID": "qmd/ClimRR.html#footnotes",
    "href": "qmd/ClimRR.html#footnotes",
    "title": "Climate Analysis with ClimRR",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe “geometry” column – no matter its name – can be accessed through the geometry attribute (gdf.geometry), and the name of the geometry column can be found by typing gdf.geometry.name.↩︎\nTruncated name for “Crossmodel_CellName”.↩︎"
  },
  {
    "objectID": "index.html#climate-scenarios",
    "href": "index.html#climate-scenarios",
    "title": "",
    "section": "1.1 Climate Scenarios",
    "text": "1.1 Climate Scenarios\nClimate scenarios are the set of conditions used to represent estimates of future greenhouse gas (GHG) concentrations in the atmosphere. Climate models then evaluate how these GHG concentrations affect future (projected) climate.\nThe data in ClimRR include model results from two future climate scenarios, called Representative Concentration Pathways (RCPs):\n\nRCP4.5: in this scenario, human GHG emissions peak around 2040, then decline\nRCP8.5: in this scenario, human GHG emissions continue to rise throughout the 21-st century\n\nEach RCP is modeled over a mid-century period (2045—2054) and end-of-century-period (2081 to 2094). A historical period (1995—2004) is also modeled using GHG concentrations during this period."
  },
  {
    "objectID": "index.html#downscaled-climate-models",
    "href": "index.html#downscaled-climate-models",
    "title": "",
    "section": "1.2 Downscaled Climate Models",
    "text": "1.2 Downscaled Climate Models\nA global climate model (GCM) is a complex mathematical representation of the major climate system components (atmosphere, land surface, ocean, and sea ice) and their interactions.\nThese models project climatic conditions at frequent intervals over long periods of time (e.g., every 3 hours for the next 50—100 years), often with the purpose of evaluating how one or more GHG scenarios will impact future climate.\nMost GCMs project patterns at relatively coarse spatial resolutions, using grid cells ranging from 100km to 200km.\nThe climate data presented in this portal has been downscaled to a higher spatial resolution (12km) to fill a growing need for risk analysis and resilience planning at the local level.\nWe use dynamical downscaling, which applies the outputs of a GCM as inputs to a separate, high-resolution regional climate model.\nDynamical downscaling accounts for the physical processes and natural features of a region, as well as the complex interaction between these elements and global dynamics under a climate scenario.\nArgonne’s dynamical downscaling uses the Weather Research and Forecasting (WRF) model, which is a regional weather model for North America developed by the National Center for Atmospheric Research.\nScientists at Argonne dynamically downscaled three different GCMs, including:\n\nCCSM: The Community Climate System Model (Version 4) is a coupled global climate model developed by the University Corporation for Atmospheric Research with funding from the National Science Foundation, the Department of Energy, and the National Aeronautics and Space Administration. It is comprised of atmospheric, land surface, and sea ice submodels that run simultaneously with a central coupler component.\nGFDL: The Geophysical Fluid Dynamics Laboratory at the National Oceanic and Atmospheric Administration developed the Earth System Model Version 2G (note: the general convention, which we use, is to use the Laboratory’s abbreviation to identify this model). It includes an atmospheric circulation model and an oceanic circulation model, and takes into account land, sea ice, and iceberg dynamics.\nHadGEM: The United Kingdom’s Met Office developed the Hadley Global Environment Model 2—Earth System. It is used for both operational weather forecasting and climate research, and includes coupled atmosphere‐ocean analysis and an earth system component that includes dynamic vegetation, ocean biology, and atmospheric chemistry."
  },
  {
    "objectID": "index.html#ensemble-means",
    "href": "index.html#ensemble-means",
    "title": "",
    "section": "1.3 Ensemble Means",
    "text": "1.3 Ensemble Means\nAll data layers in ClimRR represent a climate variable along with its associated time period and climate scenario (e.g. mid-century RCP4.5). Each time period comprises one decade’s worth of information:\n\nhistorical: (1995 — 2004)\nmid-century: (2045 — 2054)\nend-of-century: (2085 — 2094)\n\nFor each scenario, the WRF model is run with each of the three GCM outputs, producing three individual decades of weather data for each scenario.\nIn other words, 30 years of downscaled climate data is produced for each decadal scenario.\nBy using the outputs from three different GCMs, rather than a single model, Argonne’s climate projections better account for the internal uncertainty associated with any single model."
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Climate Analysis with ClimRR",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nClimRR was developed by the Center for Climate Resilience and Decision Science (CCRDS) at Argonne National Laboratory in collaboration with AT&T and the United States Department of Homeland Security’s Federal Emergency Management Agency (FEMA). Climate change is increasing the complexity, intensity, and frequency of disasters. Understanding future climate conditions in cities and towns across the United States is necessary to prepare for future climate realities.↩︎"
  },
  {
    "objectID": "qmd/iris.html",
    "href": "qmd/iris.html",
    "title": "Mapping and Plotting Tools with GeoPandas",
    "section": "",
    "text": "Code\nimport geodatasets\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n\nchicago = gpd.read_file(geodatasets.get_path('geoda.chicago_commpop'))\ngroceries = gpd.read_file(geodatasets.get_path('geoda.groceries'))\nCode\nchicago.head()\n\n\n\n\n\n\n\n\n\ncommunity\nNID\nPOP2010\nPOP2000\nPOPCH\nPOPPERCH\npopplus\npopneg\ngeometry\n\n\n\n\n0\nDOUGLAS\n35\n18238\n26470\n-8232\n-31.099358\n0\n1\nMULTIPOLYGON (((-87.60914 41.84469, -87.60915 ...\n\n\n1\nOAKLAND\n36\n5918\n6110\n-192\n-3.142390\n0\n1\nMULTIPOLYGON (((-87.59215 41.81693, -87.59231 ...\n\n\n2\nFULLER PARK\n37\n2876\n3420\n-544\n-15.906433\n0\n1\nMULTIPOLYGON (((-87.62880 41.80189, -87.62879 ...\n\n\n3\nGRAND BOULEVARD\n38\n21929\n28006\n-6077\n-21.698922\n0\n1\nMULTIPOLYGON (((-87.60671 41.81681, -87.60670 ...\n\n\n4\nKENWOOD\n39\n17841\n18363\n-522\n-2.842673\n0\n1\nMULTIPOLYGON (((-87.59215 41.81693, -87.59215 ...\nCode\nax = chicago.plot()\nax.set_axis_off()\n\nax = chicago.plot(\n    column='POP2010',\n    legend=True,\n    legend_kwds={\n        'label': 'Population in 2010',\n        'orientation': 'vertical',\n    }\n)\nplt.tight_layout()\nax.set_axis_off()\nCode\nax = chicago.boundary.plot()\nax.set_axis_off()\nCode\nax = groceries.plot(marker='.', color='red', markersize=5)\nCode\ngroceries = groceries.to_crs(chicago.crs)\nCode\nimport geopandas\nimport geodatasets\n\nnybb = geopandas.read_file(geodatasets.get_path(\"nybb\"))\nchicago = geopandas.read_file(geodatasets.get_path(\"geoda.chicago_commpop\"))\ngroceries = geopandas.read_file(\n    geodatasets.get_path(\"geoda.groceries\")\n).explode(ignore_index=True)"
  },
  {
    "objectID": "qmd/iris.html#climate-plots-using-iris",
    "href": "qmd/iris.html#climate-plots-using-iris",
    "title": "Mapping and Plotting Tools with GeoPandas",
    "section": "1 Climate Plots using Iris",
    "text": "1 Climate Plots using Iris\nIris: A powerful, format-agnostic, community-drive Python package for analysing and visualizing Earth science data.\n\n\n\n\n\n\nNote\n\n\n\nThe plots below are just for testing functionality, WIP to replace with ClimRR data\n\n\n\n\nCode\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport warnings\n\nimport cartopy.crs as ccrs\nimport matplotlib.pyplot as plt\n\nimport iris\nimport iris.plot as iplt\nimport iris.quickplot as qplt\n\nwarnings.filterwarnings('ignore')\n# testing comment\n%matplotlib inline\nimport matplotlib_inline\nmatplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n\nfrom pathlib import Path\n\nfrom ClimRR import DATA_DIR\nplt.rcParams.update({\n    'axes.facecolor': 'none',\n    'figure.facecolor': 'none',\n    'savefig.facecolor': 'none',\n    'savefig.format': 'svg',\n    'axes.edgecolor': 'none',\n    'axes.grid': True,\n    'axes.labelcolor': '#666',\n    'axes.titlecolor': '#666',\n    'grid.color': '#666',\n    'text.color': '#666',\n    'grid.linestyle': '--',\n    'grid.linewidth': 0.5,\n    'grid.alpha': 0.4,\n    'xtick.color': 'none',\n    'ytick.color': 'none',\n    'xtick.labelcolor': '#666',\n    'legend.edgecolor': 'none',\n    'ytick.labelcolor': '#666',\n    'savefig.transparent': True,\n    'figure.figsize': (12.4, 4.8),\n})\n\n\n\n\nCode\nshape = gpd.read_file(\n    DATA_DIR.joinpath(\n        \"GridCells2Shapefile/\"\n        \"GridCellsShapefile/GridCells.shp\"\n    )\n)\nprint(f\"shape: {shape}\")\n\n\nshape:        OBJECTID Crossmodel    Shape_Leng    Shape_Area  \\\n0             1   R161C438  63614.764866  2.529273e+08   \n1             2   R125C222  61384.219597  2.355013e+08   \n2             3   R121C235  61111.892875  2.334164e+08   \n3             4   R169C431  64716.234995  2.617618e+08   \n4             5   R146C497  60142.919468  2.260731e+08   \n...         ...        ...           ...           ...   \n62829     62830   R055C359  54822.101620  1.878414e+08   \n62830     62831   R072C387  55964.448729  1.957512e+08   \n62831     62832   R085C337  57646.273207  2.076932e+08   \n62832     62833   R082C288  57528.265213  2.068438e+08   \n62833     62834   R088C416  56916.790562  2.024700e+08   \n\n                                                geometry  \n0      POLYGON ((-9530601.177 4726046.614, -9534793.8...  \n1      POLYGON ((-12959076.287 4395610.472, -12974301...  \n2      POLYGON ((-12754805.395 4355815.951, -12770000...  \n3      POLYGON ((-9605729.481 4879238.815, -9609863.1...  \n4      POLYGON ((-8733007.764 4224658.634, -8738250.3...  \n...                                                  ...  \n62829  POLYGON ((-10965528.715 3400674.224, -10966978...  \n62830  POLYGON ((-10550370.700 3584259.218, -10552496...  \n62831  POLYGON ((-11249641.912 3850046.022, -11235259...  \n62832  POLYGON ((-11942487.554 3816894.598, -11956857...  \n62833  POLYGON ((-10110300.079 3720413.967, -10124231...  \n\n[62834 rows x 5 columns]\n\n\n\n\nCode\nshape.plot()\n\n\n&lt;AxesSubplot: &gt;\n\n\n\n\n\n\n\nCode\nimport cartopy.crs as ccrs\nimport matplotlib.pyplot as plt\n\nimport iris\nimport iris.analysis.cartography\nimport iris.plot as iplt\nimport iris.quickplot as qplt\n\n# Load some test data.\nfname = iris.sample_data_path(\"rotated_pole.nc\")\nair_pressure = iris.load_cube(fname)\n\n# Plot #1: Point plot showing data values & a colorbar\n# plt.figure()\nfig, ax = plt.subplots()\npoints = qplt.points(air_pressure, c=air_pressure.data)\ncb = plt.colorbar(points, orientation=\"horizontal\")\ncb.set_label(air_pressure.units)\nplt.gca().coastlines()\n\n# Plot #2: Contourf of the point based data\nplt.figure()\nqplt.contourf(air_pressure, 15)\nplt.gca().coastlines()\n# iplt.show()\n\n# Plot #3: Contourf overlaid by coloured point data\nplt.figure()\nqplt.contourf(air_pressure)\niplt.points(air_pressure, c=air_pressure.data)\nplt.gca().coastlines()\n\n# For the purposes of this example, add some bounds to the latitude\n# and longitude\nair_pressure.coord(\"grid_latitude\").guess_bounds()\nair_pressure.coord(\"grid_longitude\").guess_bounds()\n\n# Plot #4: Block plot\nplt.figure()\n# fig, ax = plt.subplots()\nplt.axes(projection=ccrs.PlateCarree())\niplt.pcolormesh(air_pressure)\nplt.gca().stock_img()\nplt.gca().coastlines()\n\n\n&lt;cartopy.mpl.feature_artist.FeatureArtist at 0x14f0736d0&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nfname = iris.sample_data_path(\"air_temp.pp\")\ntemperature = iris.load_cube(fname)\n\nfig, ax = plt.subplots()\n\n# Plot #1: contourf with axes longitude from -180 to 180\n#plt.figure(figsize=(8, 5))\nplt.subplot(121)\nqplt.contourf(temperature, 15)\nfig.gca().coastlines()\n\n# Plot #2: contourf with axes longitude from 0 to 360\nproj = ccrs.PlateCarree(central_longitude=-180.0)\nplt.subplot(122, projection=proj)\nqplt.contourf(temperature, 15)\nfig.gca().coastlines()\n\n\n&lt;cartopy.mpl.feature_artist.FeatureArtist at 0x14f42aad0&gt;\n\n\n\n\n\n\n\nCode\nfname = iris.sample_data_path(\"air_temp.pp\")\n\nfig, ax = plt.subplots()\n# Load exactly one cube from the given file.\ntemperature = iris.load_cube(fname)\n# We only want a small number of latitudes, so filter some out\n# using \"extract\".\ntemperature = temperature.extract(\n    iris.Constraint(latitude=lambda cell: 68 &lt;= cell &lt; 78)\n)\n\nfor cube in temperature.slices(\"longitude\"):\n    # Create a string label to identify this cube (i.e. latitude: value).\n    cube_label = \"latitude: %s\" % cube.coord(\"latitude\").points[0]\n\n    # Plot the cube, and associate it with a label.\n    qplt.plot(cube, label=cube_label)\n\n# Add the legend with 2 columns.\nax.legend(ncol=2)\n# Put a grid on the plot.\nax.grid(True)\n# Tell matplotlib not to extend the plot axes range to nicely\n# rounded numbers.\nplt.axis(\"tight\")\n\n\n(-17.81249542236328, 374.0624038696289, 253.4506408691406, 277.34959106445314)"
  },
  {
    "objectID": "qmd/iris.html#test-data-showing-inset-plots",
    "href": "qmd/iris.html#test-data-showing-inset-plots",
    "title": "Mapping and Plotting Tools with GeoPandas",
    "section": "2 Test Data Showing Inset Plots",
    "text": "2 Test Data Showing Inset Plots\nThis example demonstrates the use of a single 3D data cube with time, latitude and longitude dimensions to plot a temperature series for a single latitude coordinate, with an inset plot of the data region.\n\n\nCode\nimport numpy as np\ncube1 = iris.load_cube(iris.sample_data_path(\"ostia_monthly.nc\"))\n# Slice into cube to retrieve data for the inset map showing the\n# data region\nregion = cube1[-1, :, :]\n# Average over latitude to reduce cube to 1 dimension\nplot_line = region.collapsed(\"latitude\", iris.analysis.MEAN)\n\n# Open a window for plotting\nfig = plt.figure()\n# Add a single subplot (axes). Could also use \"ax_main = plt.subplot()\"\nax_main = fig.add_subplot(1, 1, 1)\n# Produce a quick plot of the 1D cube\nqplt.plot(plot_line)\n\n# Set x limits to match the data\nax_main.set_xlim(0, plot_line.coord(\"longitude\").points.max())\n# Adjust the y limits so that the inset map won't clash with main plot\nax_main.set_ylim(294, 310)\nax_main.set_title(\"Meridional Mean Temperature\")\n# Add grid lines\nax_main.grid()\n\n# Add a second set of axes specifying the fractional coordinates within\n# the figure with bottom left corner at x=0.55, y=0.58 with width\n# 0.3 and height 0.25.\n# Also specify the projection\nax_sub = fig.add_axes(\n  [0.55, 0.58, 0.3, 0.25],\n  projection=ccrs.Mollweide(central_longitude=180),\n)\n\n# Use iris.plot (iplt) here so colour bar properties can be specified\n# Also use a sequential colour scheme to reduce confusion for those with\n# colour-blindness\niplt.pcolormesh(region, cmap=\"Blues\")\n# Manually set the orientation and tick marks on your colour bar\nticklist = np.linspace(np.min(region.data), np.max(region.data), 4)\nplt.colorbar(orientation=\"horizontal\", ticks=ticklist)\nax_sub.set_title(\"Data Region\")\n# Add coastlines\nax_sub.coastlines()\n# request to show entire map, using the colour mesh on the data region only\nax_sub.set_global()\n\n\n\n\n\n\n\nCode\nimport iris\n\nimport numpy as np\nimport iris.plot as iplt\nimport iris.quickplot as qplt\n\nfrom iris.analysis import MEAN\n\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\n\n# Loads air_temp.pp and \"collapses\" longitude into a single, average value.\nfname = iris.sample_data_path(\"air_temp.pp\")\ntemperature = iris.load_cube(fname)\ncollapsed_temp = temperature.collapsed(\"longitude\", MEAN)\n\n\n# Set y-axes with -90 and 90 limits and steps of 15 per tick.\nstart, stop, step = -90, 90, 15\nyticks = np.arange(start, stop + step, step)\nylim = [start, stop]\n\n# Plot \"temperature\" on a cartographic plot and set the ticks and titles\n# on the axes.\nfig = plt.figure(figsize=[12, 8])\n#fig, ax = plt.subplots()\n\nax1 = fig.add_subplot(111, projection=ccrs.PlateCarree())\nim = iplt.contourf(temperature, cmap=\"RdYlBu_r\")\nax1.coastlines()\nax1.gridlines()\nax1.set_xticks([-180, -90, 0, 90, 180])\nax1.set_yticks(yticks)\nax1.set_title(\"Air Temperature\")\nax1.set_ylabel(f\"Latitude / {temperature.coord('latitude').units}\")\nax1.set_xlabel(f\"Longitude / {temperature.coord('longitude').units}\")\nax1.set_ylim(*ylim)\n\n# Create a Matplotlib AxesDivider object to allow alignment of other\n# Axes objects.\ndivider = make_axes_locatable(ax1)\n\n# Gives the air temperature bar size, colour and a title.\nax2 = divider.new_vertical(\n    size=\"5%\", pad=0.5, axes_class=plt.Axes, pack_start=True\n)  # creates 2nd axis\nfig.add_axes(ax2)\ncbar = plt.colorbar(\n    im, cax=ax2, orientation=\"horizontal\"\n)  # puts colour bar on second axis\ncbar.ax.set_xlabel(f\"{temperature.units}\")  # labels colour bar\n\n# Plot \"collapsed_temp\" on the mean graph and set the ticks and titles\n# on the axes.\nax3 = divider.new_horizontal(\n    size=\"30%\", pad=0.4, axes_class=plt.Axes\n)  # create 3rd axis\nfig.add_axes(ax3)\nqplt.plot(\n    collapsed_temp, collapsed_temp.coord(\"latitude\")\n)  # plots temperature collapsed over longitude against latitude\nax3.axhline(0, color=\"k\", linewidth=0.5)\n\n# Creates zonal mean details\nax3.set_title(\"Zonal Mean\")\nax3.yaxis.set_label_position(\"right\")\nax3.yaxis.tick_right()\nax3.set_yticks(yticks)\nax3.grid()\n\n# Round each tick for the third ax to the nearest 20 (ready for use).\ndata_max = collapsed_temp.data.max()\nx_max = data_max - data_max % -20\ndata_min = collapsed_temp.data.min()\nx_min = data_min - data_min % 20\nax3.set_xlim(x_min, x_max)\nax3.set_ylim(*ylim)\nplt.tight_layout()\n\n\n\n\n\n\n\nCode\nfname = iris.sample_data_path(\"air_temp.pp\")\n\n# Load exactly one cube from the given file.\ntemperature = iris.load_cube(fname)\n\n# We only want a small number of latitudes, so filter some out\n# using \"extract\".\ntemperature = temperature.extract(\n    iris.Constraint(latitude=lambda cell: 68 &lt;= cell &lt; 78)\n)\n\nfig, ax = plt.subplots()\n\nfor cube in temperature.slices(\"longitude\"):\n    # Create a string label to identify this cube (i.e. latitude: value).\n    cube_label = \"latitude: %s\" % cube.coord(\"latitude\").points[0]\n\n    # Plot the cube, and associate it with a label.\n    qplt.plot(cube, label=cube_label)\n\n# Add the legend with 2 columns.\nax.legend(ncol=2)\n\n# Put a grid on the plot.\nax.grid(True)\n\n# Tell matplotlib not to extend the plot axes range to nicely\n# rounded numbers.\nplt.axis(\"tight\")\n\n\n(-17.81249542236328, 374.0624038696289, 253.4506408691406, 277.34959106445314)\n\n\n\n\n\n\n\nCode\nimport iris.coord_categorisation\nimport matplotlib.colors as mcols\n\n\nfig, ax = plt.subplots()\n# Load a sample air temperatures sequence.\nfile_path = iris.sample_data_path(\"E1_north_america.nc\")\ntemperatures = iris.load_cube(file_path)\n\n# Create a year-number coordinate from the time information.\niris.coord_categorisation.add_year(temperatures, \"time\")\n\n# Create a sample anomaly field for one chosen year, by extracting that\n# year and subtracting the time mean.\nsample_year = 1982\nyear_temperature = temperatures.extract(iris.Constraint(year=sample_year))\ntime_mean = temperatures.collapsed(\"time\", iris.analysis.MEAN)\nanomaly = year_temperature - time_mean\n\n# Construct a plot title string explaining which years are involved.\nyears = temperatures.coord(\"year\").points\nplot_title = \"Temperature anomaly\"\nplot_title += \"\\n{} differences from {}-{} average.\".format(\n    sample_year, years[0], years[-1]\n)\n\n# Define scaling levels for the logarithmic colouring.\nminimum_log_level = 0.1\nmaximum_scale_level = 3.0\n\n# Use a standard colour map which varies blue-white-red.\n# For suitable options, see the 'Diverging colormaps' section in:\n# http://matplotlib.org/stable/gallery/color/colormap_reference.html\nanom_cmap = \"bwr\"\n\n# Create a 'logarithmic' data normalization.\nanom_norm = mcols.SymLogNorm(\n    linthresh=minimum_log_level,\n    linscale=0.01,\n    vmin=-maximum_scale_level,\n    vmax=maximum_scale_level,\n)\n# Setting \"linthresh=minimum_log_level\" makes its non-logarithmic\n# data range equal to our 'zero band'.\n# Setting \"linscale=0.01\" maps the whole zero band to the middle colour value\n# (i.e., 0.5), which is the neutral point of a \"diverging\" style colormap.\n\n# Create an Axes, specifying the map projection.\nplt.axes(projection=ccrs.LambertConformal())\n\n# Make a pseudocolour plot using this colour scheme.\nmesh = iplt.pcolormesh(anomaly, cmap=anom_cmap, norm=anom_norm)\n\n# Add a colourbar, with extensions to show handling of out-of-range values.\nbar = plt.colorbar(mesh, orientation=\"horizontal\", extend=\"both\")\n\n# Set some suitable fixed \"logarithmic\" colourbar tick positions.\ntick_levels = [-3, -1, -0.3, 0.0, 0.3, 1, 3]\nbar.set_ticks(tick_levels)\n\n# Modify the tick labels so that the centre one shows \"+/-&lt;minumum-level&gt;\".\ntick_levels[3] = r\"$\\pm${:g}\".format(minimum_log_level)\nbar.set_ticklabels(tick_levels)\n\n# Label the colourbar to show the units.\nbar.set_label(\"[{}, log scale]\".format(anomaly.units))\n\n# Add coastlines and a title.\nplt.gca().coastlines()\nplt.title(plot_title)\n\n\nText(0.5, 1.0, 'Temperature anomaly\\n1982 differences from 1860-2099 average.')"
  },
  {
    "objectID": "index.html#list-of-projects",
    "href": "index.html#list-of-projects",
    "title": "Climate Analysis with ClimRR",
    "section": "3 List of Projects",
    "text": "3 List of Projects\n\n\n\nProject (and link project description)\nInstitution\nLead\nReviewers\n\n\n\n\nAI-Powered Equity Analysis of Renewable Energy Laws\nANL\nMurat Keceli\nScott Feister, Kellen Leland\n\n\nSolar Power for Affordable Housing through Computational Design of Low-Cost/High-Efficiency Solar Cells\nANL\nAlvaro Vazquez-Mayagoita\nDan Fulton, Helen He\n\n\nEnergy Justice Analysis of Climate Data\nANL\nSam Foreman\nSuzanne Parete-Koon, Scott Feister\n\n\nEnergy Cost for Disadvantaged Populations and Methods of Energy Efficiency and Energy Optimization in Computing Systems\nNERSC\nCharles Lively\nSam Foreman, Wilbur Ouma\n\n\nUnderstanding the Impact of HPC Center Energy Usage on Low-income and Minority Populations\nNERSC\nCharles Lively\nMurat Keceli, Subil Abraham\n\n\nPower Outages and Inequities in Energy Access for Medically Vulnerable Populations\nOLCF\nSubil Abraham\nCharles Lively, Lois McInnes\n\n\nSocioeconomics of Power Outages and Heatwaves\nOLCF\nSuzanne Parete-Koon\nAlvaro Vazquez-Mayagoitia, Lipi Gupta"
  },
  {
    "objectID": "index.html#climate-risk-resilience-portal-climrr",
    "href": "index.html#climate-risk-resilience-portal-climrr",
    "title": "Climate Analysis with ClimRR",
    "section": "1 Climate Risk & Resilience Portal: ClimRR",
    "text": "1 Climate Risk & Resilience Portal: ClimRR\n\n\n\nThe ClimRR Portal can be viewed online, and is a great resource for interactive exploration.\n\n\n\n\n\n\nAccessing Data\n\n\n\n\n\nThe data needed for running this notebook can be downloaded from the web at:\n\nClimRR Data Download (ANL)\nCounties - United States of America\n\n\n\n\n\n\n\n\n\n\nProject Description\n\n\n\n\n\n\n\n\nAre different populations unequally affected by climate change? This project will explore the intersection of climate data and energy justice, providing an introductory understanding of data science techniques in assessing disparate outcomes on vulnerable or underserved populations in the United States. By shedding light on energy disparities, the project aims to contribute to the ongoing discussions surrounding energy equity and inform policymakers and stakeholders for more inclusive energy initiatives. Energy justice refers to the equitable distribution of clean, affordable, and reliable energy resources among all communities, regardless of their socioeconomic status or demographic characteristics. This project will focus on the analysis of climate data and low-income energy affordability data across the United States. The analysis will focus on examining energy consumption patterns, renewable energy adoption rates, and energy affordability across different geographical regions and demographic groups. To assess disparate outcomes, the project will employ various statistical techniques to compare energy-related indicators among vulnerable populations. This work may involve analyzing energy access in low-income neighborhoods, evaluating the impact of energy policies on marginalized communities, or examining the correlation between energy affordability and socioeconomic factors.\nThe findings of the analysis will be interpreted to gain insights into the disparities in energy justice and its impact on vulnerable populations. The project aims to identify areas where energy inequalities exist and provide a data-driven foundation for advocating for equitable energy policies and programs.\n\n\n\n\n1.1 Additional Projects\n\n\n\nProject (and link project description)\nInstitution\nLead\nReviewers\n\n\n\n\nAI-Powered Equity Analysis of Renewable Energy Laws\nANL\nMurat Keceli\nScott Feister, Kellen Leland\n\n\nSolar Power for Affordable Housing through Computational Design of Low-Cost/High-Efficiency Solar Cells\nANL\nAlvaro Vazquez-Mayagoita\nDan Fulton, Helen He\n\n\nEnergy Justice Analysis of Climate Data\nANL\nSam Foreman\nSuzanne Parete-Koon, Scott Feister\n\n\nEnergy Cost for Disadvantaged Populations and Methods of Energy Efficiency and Energy Optimization in Computing Systems\nNERSC\nCharles Lively\nSam Foreman, Wilbur Ouma\n\n\nUnderstanding the Impact of HPC Center Energy Usage on Low-income and Minority Populations\nNERSC\nCharles Lively\nMurat Keceli, Subil Abraham\n\n\nPower Outages and Inequities in Energy Access for Medically Vulnerable Populations\nOLCF\nSubil Abraham\nCharles Lively, Lois McInnes\n\n\nSocioeconomics of Power Outages and Heatwaves\nOLCF\nSuzanne Parete-Koon\nAlvaro Vazquez-Mayagoitia, Lipi Gupta"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Climate Analysis with ClimRR",
    "section": "",
    "text": "Empowering individuals, governments, and organizations to examine simulated future climate conditions at mid- and end-of-century for a range of climate perils.\nThe ClimRR Portal can be viewed online, and is a great resource for interactive exploration.\nClimate change is increasing the complexity, intensity, and frequency of disasters.\nUnderstanding future climate conditions in cities and towns across the United States is necessary to prepare for future climate realities.\nTo address this requirement, ClimRR1 — the Climate Risk and Resilience Portal — empowers individuals, governments, and organizations to examine simulated future climate conditions at mid- and end-of-century for a range of climate perils."
  },
  {
    "objectID": "index.html#project-description",
    "href": "index.html#project-description",
    "title": "Climate Analysis with ClimRR",
    "section": "2 Project Description",
    "text": "2 Project Description\n\nProject Description  Are different populations unequally affected by climate change? This project will explore the intersection of climate data and energy justice, providing an introductory understanding of data science techniques in assessing disparate outcomes on vulnerable or underserved populations in the United States. By shedding light on energy disparities, the project aims to contribute to the ongoing discussions surrounding energy equity and inform policymakers and stakeholders for more inclusive energy initiatives. Energy justice refers to the equitable distribution of clean, affordable, and reliable energy resources among all communities, regardless of their socioeconomic status or demographic characteristics. This project will focus on the analysis of climate data and low-income energy affordability data across the United States. The analysis will focus on examining energy consumption patterns, renewable energy adoption rates, and energy affordability across different geographical regions and demographic groups. To assess disparate outcomes, the project will employ various statistical techniques to compare energy-related indicators among vulnerable populations. This work may involve analyzing energy access in low-income neighborhoods, evaluating the impact of energy policies on marginalized communities, or examining the correlation between energy affordability and socioeconomic factors.\nThe findings of the analysis will be interpreted to gain insights into the disparities in energy justice and its impact on vulnerable populations. The project aims to identify areas where energy inequalities exist and provide a data-driven foundation for advocating for equitable energy policies and programs.\n\n\n2.1 Additional Projects\n\n\n\nProject (and link project description)\nInstitution\nLead\nReviewers\n\n\n\n\nAI-Powered Equity Analysis of Renewable Energy Laws\nANL\nMurat Keceli\nScott Feister, Kellen Leland\n\n\nSolar Power for Affordable Housing through Computational Design of Low-Cost/High-Efficiency Solar Cells\nANL\nAlvaro Vazquez-Mayagoita\nDan Fulton, Helen He\n\n\nEnergy Justice Analysis of Climate Data\nANL\nSam Foreman\nSuzanne Parete-Koon, Scott Feister\n\n\nEnergy Cost for Disadvantaged Populations and Methods of Energy Efficiency and Energy Optimization in Computing Systems\nNERSC\nCharles Lively\nSam Foreman, Wilbur Ouma\n\n\nUnderstanding the Impact of HPC Center Energy Usage on Low-income and Minority Populations\nNERSC\nCharles Lively\nMurat Keceli, Subil Abraham\n\n\nPower Outages and Inequities in Energy Access for Medically Vulnerable Populations\nOLCF\nSubil Abraham\nCharles Lively, Lois McInnes\n\n\nSocioeconomics of Power Outages and Heatwaves\nOLCF\nSuzanne Parete-Koon\nAlvaro Vazquez-Mayagoitia, Lipi Gupta"
  },
  {
    "objectID": "qmd/intro.html",
    "href": "qmd/intro.html",
    "title": "Climate Risk & Resilience Portal",
    "section": "",
    "text": "For completeness, we include text below from (Burdi and Branham 2023)\nClimate scenarios are the set of conditions used to represent estimates of future greenhouse gas (GHG) concentrations in the atmosphere. Climate models then evaluate how these GHG concentrations affect future (projected) climate.\nThe data in ClimRR include model results from two future climate scenarios, called Representative Concentration Pathways (RCPs):\n\nRCP4.5: in this scenario, human GHG emissions peak around 2040, then decline\nRCP8.5: in this scenario, human GHG emissions continue to rise throughout the 21-st century\n\nEach RCP is modeled over a mid-century period (2045—2054) and end-of-century-period (2081 to 2094). A historical period (1995—2004) is also modeled using GHG concentrations during this period."
  },
  {
    "objectID": "qmd/intro.html#climate-scenarios",
    "href": "qmd/intro.html#climate-scenarios",
    "title": "Climate Risk & Resilience Portal",
    "section": "",
    "text": "For completeness, we include text below from (Burdi and Branham 2023)\nClimate scenarios are the set of conditions used to represent estimates of future greenhouse gas (GHG) concentrations in the atmosphere. Climate models then evaluate how these GHG concentrations affect future (projected) climate.\nThe data in ClimRR include model results from two future climate scenarios, called Representative Concentration Pathways (RCPs):\n\nRCP4.5: in this scenario, human GHG emissions peak around 2040, then decline\nRCP8.5: in this scenario, human GHG emissions continue to rise throughout the 21-st century\n\nEach RCP is modeled over a mid-century period (2045—2054) and end-of-century-period (2081 to 2094). A historical period (1995—2004) is also modeled using GHG concentrations during this period."
  },
  {
    "objectID": "qmd/intro.html#downscaled-climate-models",
    "href": "qmd/intro.html#downscaled-climate-models",
    "title": "Climate Risk & Resilience Portal",
    "section": "Downscaled Climate Models",
    "text": "Downscaled Climate Models\nA global climate model (GCM) is a complex mathematical representation of the major climate system components (atmosphere, land surface, ocean, and sea ice) and their interactions.\nThese models project climatic conditions at frequent intervals over long periods of time (e.g., every 3 hours for the next 50—100 years), often with the purpose of evaluating how one or more GHG scenarios will impact future climate.\nMost GCMs project patterns at relatively coarse spatial resolutions, using grid cells ranging from 100km to 200km.\nThe climate data presented in this portal has been downscaled to a higher spatial resolution (12km) to fill a growing need for risk analysis and resilience planning at the local level.\nWe use dynamical downscaling, which applies the outputs of a GCM as inputs to a separate, high-resolution regional climate model.\nDynamical downscaling accounts for the physical processes and natural features of a region, as well as the complex interaction between these elements and global dynamics under a climate scenario.\nArgonne’s dynamical downscaling uses the Weather Research and Forecasting (WRF) model, which is a regional weather model for North America developed by the National Center for Atmospheric Research.\nScientists at Argonne dynamically downscaled three different GCMs, including:\n\nCCSM: The Community Climate System Model (Version 4) is a coupled global climate model developed by the University Corporation for Atmospheric Research with funding from the National Science Foundation, the Department of Energy, and the National Aeronautics and Space Administration. It is comprised of atmospheric, land surface, and sea ice submodels that run simultaneously with a central coupler component.\nGFDL: The Geophysical Fluid Dynamics Laboratory at the National Oceanic and Atmospheric Administration developed the Earth System Model Version 2G (note: the general convention, which we use, is to use the Laboratory’s abbreviation to identify this model). It includes an atmospheric circulation model and an oceanic circulation model, and takes into account land, sea ice, and iceberg dynamics.\nHadGEM: The United Kingdom’s Met Office developed the Hadley Global Environment Model 2—Earth System. It is used for both operational weather forecasting and climate research, and includes coupled atmosphere‐ocean analysis and an earth system component that includes dynamic vegetation, ocean biology, and atmospheric chemistry."
  },
  {
    "objectID": "qmd/intro.html#ensemble-means",
    "href": "qmd/intro.html#ensemble-means",
    "title": "Climate Risk & Resilience Portal",
    "section": "Ensemble Means",
    "text": "Ensemble Means\nAll data layers in ClimRR represent a climate variable along with its associated time period and climate scenario (e.g. mid-century RCP4.5). Each time period comprises one decade’s worth of information:\n\nhistorical: (1995 — 2004)\nmid-century: (2045 — 2054)\nend-of-century: (2085 — 2094)\n\nFor each scenario, the WRF model is run with each of the three GCM outputs, producing three individual decades of weather data for each scenario.\nIn other words, 30 years of downscaled climate data is produced for each decadal scenario.\nBy using the outputs from three different GCMs, rather than a single model, Argonne’s climate projections better account for the internal uncertainty associated with any single model.\nEach year’s worth of data includes weather outputs for every 3 hours, or 8 modeled outputs per day.\nWhile this allows for a high degree of granularity in assessing future climate models, there are many different ways to analyze this data; however, there are several important common methodologies share across all variables presented in this portal.\nMost variables are presented as annual or seasonal averages of daily observations, yet each annual / seasonal average draws upon all three different climate model runs for that scenario and the ten years of data produced by each model.\n\n\n\n\n\n\nEnsemble Mean\n\n\n\n\n\nEach variable (e.g. total_annual_precipitation) for a given scenario (e.g. Mid-century RCP4.5) is produced by calculating an individual estimate for each of the 30 years of climate data associated with that scenario, and then taking the average of 30 estimates.\nThis result is what we term the ensemble mean."
  },
  {
    "objectID": "index.html#additional-projects",
    "href": "index.html#additional-projects",
    "title": "Climate Analysis with ClimRR",
    "section": "Additional Projects",
    "text": "Additional Projects\n\n\n\nProject (and link project description)\nInstitution\nLead\nReviewers\n\n\n\n\nAI-Powered Equity Analysis of Renewable Energy Laws\nANL\nMurat Keceli\nScott Feister, Kellen Leland\n\n\nSolar Power for Affordable Housing through Computational Design of Low-Cost/High-Efficiency Solar Cells\nANL\nAlvaro Vazquez-Mayagoita\nDan Fulton, Helen He\n\n\nEnergy Justice Analysis of Climate Data\nANL\nSam Foreman\nSuzanne Parete-Koon, Scott Feister\n\n\nEnergy Cost for Disadvantaged Populations and Methods of Energy Efficiency and Energy Optimization in Computing Systems\nNERSC\nCharles Lively\nSam Foreman, Wilbur Ouma\n\n\nUnderstanding the Impact of HPC Center Energy Usage on Low-income and Minority Populations\nNERSC\nCharles Lively\nMurat Keceli, Subil Abraham\n\n\nPower Outages and Inequities in Energy Access for Medically Vulnerable Populations\nOLCF\nSubil Abraham\nCharles Lively, Lois McInnes\n\n\nSocioeconomics of Power Outages and Heatwaves\nOLCF\nSuzanne Parete-Koon\nAlvaro Vazquez-Mayagoitia, Lipi Gupta"
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "Climate Analysis with ClimRR",
    "section": "1 Overview",
    "text": "1 Overview\n\n\nProject Description\n\nAre different populations unequally affected by climate change? This project will explore the intersection of climate data and energy justice, providing an introductory understanding of data science techniques in assessing disparate outcomes on vulnerable or underserved populations in the United States. By shedding light on energy disparities, the project aims to contribute to the ongoing discussions surrounding energy equity and inform policymakers and stakeholders for more inclusive energy initiatives. Energy justice refers to the equitable distribution of clean, affordable, and reliable energy resources among all communities, regardless of their socioeconomic status or demographic characteristics.\nThis project will focus on the analysis of climate data and low-income energy affordability data across the United States. The analysis will focus on examining energy consumption patterns, renewable energy adoption rates, and energy affordability across different geographical regions and demographic groups.\nTo assess disparate outcomes, the project will employ various statistical techniques to compare energy-related indicators among vulnerable populations.\nThis work may involve analyzing energy access in low-income neighborhoods, evaluating the impact of energy policies on marginalized communities, or examining the correlation between energy affordability and socioeconomic factors.\nThe findings of the analysis will be interpreted to gain insights into the disparities in energy justice and its impact on vulnerable populations. The project aims to identify areas where energy inequalities exist and provide a data-driven foundation for advocating for equitable energy policies and programs."
  },
  {
    "objectID": "qmd/illinois.html",
    "href": "qmd/illinois.html",
    "title": "Continued Analysis",
    "section": "",
    "text": "Code\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nfrom ClimRR import set_plot_style, get_logger\nset_plot_style()\nfrom enrich.style import STYLES\nfrom rich.theme import Theme\nfrom rich.console import Console\ntheme = Theme(STYLES)\nlog = get_logger('ClimRR')\nconsole = Console(theme=theme, log_path=False, markup=True)\n\n\nUsing updated plot style for matplotlib\n\n\n\n\n\nCode\nfrom ClimRR import load_shapefile, load_csvs, load_counties, load_chicago_data\nshape = load_shapefile()\ndata = load_csvs(shape)\nchidata = load_chicago_data(shape.crs)\n\n\ndata['FireWeatherIndex_Wildfire'].shape=(62834, 35)\n\n\n\ndata['HeatingDegreeDays'].shape=(62834, 10)\n\n\n\ndata['AnnualTemperatureMinimum'].shape=(62834, 18)\n\n\n\ndata['SeasonalTemperatureMaximum'].shape=(62834, 27)\n\n\n\ndata['ConsecutiveDayswithNoPrecipitation'].shape=(55896, 19)\n\n\n\ndata['SeasonalTemperatureMinimum'].shape=(62834, 27)\n\n\n\ndata['WindSpeed'].shape=(62834, 18)\n\n\n\ndata['AnnualTemperatureMaximum'].shape=(62834, 18)\n\n\n\ndata['Precipitation_inches_AnnualTotal'].shape=(55896, 18)\n\n\n\n\n\nCode\ncounties = load_counties(shape.crs)\n\n\n\n\nCode\nillinois = counties[counties[\"ste_name\"] == \"['Illinois']\"]\nwind_il = data[\"WindSpeed\"].overlay(illinois, how='intersection')\n\n\n\n\nCode\n%matplotlib inline\n\n\n\n\nCode\nfig, ax = plt.subplots(figsize=(10, 7))\nplt.show()\nwind_il.plot(ax=ax, column='hist', legend=True)\nax.set_axis_off()\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\n``eqaholnm\n\n\n\nCitationBibTeX citation:@misc{foreman2023,\n  author = {Foreman, Sam},\n  date = {2023-07-12},\n  url = {https://saforem2.github.io/climate-analysis},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nForeman, Sam. 2023. Intro to HPC: Climate Analysis with ClimRR.\nhttps://saforem2.github.io/climate-analysis."
  },
  {
    "objectID": "index.html#first-column",
    "href": "index.html#first-column",
    "title": "Climate Analysis with ClimRR",
    "section": "",
    "text": "I would like to have text here\n\n\n\n\n\n\nAccessing Data\n\n\n\n\n\nThe data needed for running this notebook can be downloaded from the web at:\n\nClimRR Data Download (ANL)\nCounties - United States of America"
  },
  {
    "objectID": "index.html#second-column",
    "href": "index.html#second-column",
    "title": "Climate Analysis with ClimRR",
    "section": "",
    "text": "and here\nMore text"
  },
  {
    "objectID": "qmd/intro.html#metadata",
    "href": "qmd/intro.html#metadata",
    "title": "Climate Risk & Resilience Portal",
    "section": "Metadata",
    "text": "Metadata\nThe links below direc to the REST service of the gridded data. Metadata, descriptions, and field names were last updated on 11/7/2022.\n\nTemperature Minimum – Annual\nTemperature Minimum – Seasonal\nTemperature Maximum – Annual\nTemperature Maximum – Seasonal\nPrecipitation – Annual Total\nPrecipitation None – Annual Average\nWind Speed – Annual Average\nCooling Degree Days – Annual Total\nHeating Degree Days – Annual Total"
  },
  {
    "objectID": "qmd/intro.html#temperature-annual",
    "href": "qmd/intro.html#temperature-annual",
    "title": "Climate Risk & Resilience Portal",
    "section": "Temperature (Annual)",
    "text": "Temperature (Annual)\nEach climate model generates temperature readings every 3 hours, or 8 temperature readings per day.\nThe maximum daily temperature refers to the highest of these 8 readings, which often occurs in the middle of the daytime and is comparable to the ‘high temperature’ in a daily weather forecast.\nSimilarly, the minimum daily temperature refers to the lowest of these 8 readings, which often occurs overnight and is comparable to the ‘low temperature’ in a daily weather forecast.\nArgonne calculated the annual average of both the maximum and minimum daily temperatures.\nThese daily high / low readings were then used to calculate the annual average maximum or minimum daily temperature for that scenario’s model year (e.g. the average max daily temperature for 2045 using the CCSM model under RCP4.5).\nThis process was repeated for each year within a given time period / scenario (e.g. 2046, 2047, and so forth) across all three climate models (CCSM, GFDL, and HadGEM).\nFinally, the 30 individual annual averatges for a given tim period/scenario were themselves averaged, producing a multi-model ensemble mean that represents the annual average of the maximum or minimum daily temperature for a given time period / scenario."
  },
  {
    "objectID": "qmd/ClimRR.html#mapping-the-globe",
    "href": "qmd/ClimRR.html#mapping-the-globe",
    "title": "Climate Analysis with ClimRR",
    "section": "1.2 Mapping the Globe",
    "text": "1.2 Mapping the Globe\nOur shapefile contains a grid of cells (12km x 12km) which tile the continental US.\nWe can inspect a single cell:\n\n\nCode\ncell = shape[shape[\"Crossmodel\"] == 'R146C497']\n\n\n\n\nCode\nax = cell.boundary.plot()\nax.set_axis_off()\n_ = ax.set_title('Grid from shapefile: 12 x 12 km')\n\n\n\n\n\n\n\nCode\ncell.explore()\n\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "qmd/ClimRR.html#dealing-with-geometry",
    "href": "qmd/ClimRR.html#dealing-with-geometry",
    "title": "Climate Analysis with ClimRR",
    "section": "Dealing with Geometry",
    "text": "Dealing with Geometry\nOur shapefile contains a grid of cells (12km x 12km) which tile the continental US.\nWe can inspect a single cell:\n\ncell = shape[shape[\"Crossmodel\"] == 'R146C497']\ncell.head()\n\n\n\n\n\n\n\n\nOBJECTID\nCrossmodel\nShape_Leng\nShape_Area\ngeometry\n\n\n\n\n4\n5\nR146C497\n60142.919468\n2.260731e+08\nPOLYGON ((-8733007.764 4224658.634, -8738250.3...\n\n\n\n\n\n\n\n\nax = cell.boundary.plot()\nax.set_axis_off()\n_ = ax.set_title('Grid from shapefile: 12 x 12 km')\nplt.tight_layout()\n\n\n\n\n\ncell.explore()\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  }
]