[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Intro to HPC: ClimRR",
    "section": "",
    "text": "Figure 1: ClimRR: Empowering individuals, governments, and organizations to examine simulated future climate conditions at mid- and end-of-century for a range of climate perils1"
  },
  {
    "objectID": "index.html#additional-projects",
    "href": "index.html#additional-projects",
    "title": "Intro to HPC: ClimRR",
    "section": "Additional Projects",
    "text": "Additional Projects\n\n\n\nProject (and link project description)\nInstitution\nLead\n\n\n\n\nAI-Powered Equity Analysis of Renewable Energy Laws\nANL\nMurat Keceli\n\n\nSolar Power for Affordable Housing through Computational Design of Low-Cost/High-Efficiency Solar Cells\nANL\nAlvaro Vazquez-Mayagoita\n\n\nEnergy Justice Analysis of Climate Data\nANL\nSam Foreman\n\n\nEnergy Cost for Disadvantaged Populations and Methods of Energy Efficiency and Energy Optimization in Computing Systems\nNERSC\nCharles Lively\n\n\nUnderstanding the Impact of HPC Center Energy Usage on Low-income and Minority Populations\nNERSC\nCharles Lively\n\n\nPower Outages and Inequities in Energy Access for Medically Vulnerable Populations\nOLCF\nSubil Abraham\n\n\nSocioeconomics of Power Outages and Heatwaves\nOLCF\nSuzanne Parete-Koon"
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Intro to HPC: ClimRR",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImage Source↩︎\nClimRR was developed by the Center for Climate Resilience and Decision Science (CCRDS) at Argonne National Laboratory in collaboration with AT&T and the United States Department of Homeland Security’s Federal Emergency Management Agency (FEMA). Climate change is increasing the complexity, intensity, and frequency of disasters. Understanding future climate conditions in cities and towns across the United States is necessary to prepare for future climate realities.↩︎"
  },
  {
    "objectID": "qmd/GettingStarted/setup.html",
    "href": "qmd/GettingStarted/setup.html",
    "title": "Getting Started",
    "section": "",
    "text": "We provide below a brief introduction to the project and how to get started using Jupyter @ NERSC\nOur project directory can be found at:\nAll of the data needed for this project has already been copied to the filesystem on NERSC."
  },
  {
    "objectID": "qmd/GettingStarted/setup.html#footnotes",
    "href": "qmd/GettingStarted/setup.html#footnotes",
    "title": "Getting Started",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe --system-site-packages flag tells python to include the libraries from our system-wide install in this venv↩︎\nInstallation options:\n\nthe -e flag tells python to perform an editable install (i.e. install package from its path, ., in this case)\nthe .[dev] option says to install the package located here (.), including the development extensions specified in the pyproject.toml file\n\n↩︎"
  },
  {
    "objectID": "qmd/GettingStarted/intro.html",
    "href": "qmd/GettingStarted/intro.html",
    "title": "Climate Analysis with ClimRR",
    "section": "",
    "text": "Useful links + References\n\n\n\n\n\n\nUseful links + References:\n\nGeopandas: An Introduction\nAn Introduction to Earth and Environmental Data Science\n\nFinal Projects (good examples)\nHands-On: Aggregating the Data\n\nUsing Weather Data and Climate Model Output in Economic Analyses of Climate Change\nOn the use and misuse of climate change projections in international development\n\n\n\n\n\n\n\n\n\n\n\nLearning Goals\n\n\n\n\n\nThe goal of this project is to teach students to1:\n\nUse Unix commands to work with files and navigate directories\nUse JupyterHub + basic familiarity with how to use Jupyter notebooks on HPC systems\nIdentify some of the common file types and data formats for geospatial data\n\n(+ common python libraries for geospatial data analysis)\n\nPerform exploratory data analysis on geospatial data\n\n(+ understand different operations for manipulating and interacting with this data)\ntabular vs. gridded data\n\nPerform simple visualizations in Python to display different types of data (e.g. maps, line charts, interactive visualizations, etc)\n\nusing figures to illustrate a point or idea\nknow what types of plots to use for which situations / data types\n\nUnderstand control flow / basic structure of a Python script\n\nusing Python in Jupyter2\nimport-ing libraries, etc\n\n\n\n\n\n\n\nWe use GeoPandas, an open source project to make working with geospatial data in python easier.\nGeoPandas extends the datatypes used by pandas to allow spatial operations on geometric types.\nGeometric operations are performed by shapely.\nGeoPandas further depends on fiona and matplotlib for plotting.\nGeoPandas can read almost any vector-based spatial data format including ESRI shapefile, GeoJSON files and more using the command\n\nimport geopandas as gpd\nimport geodatasets\ngdf = gpd.read_file(geodatasets.get_path(\"geoda.chicago_commpop\"))\ngdf.head(n=2)\n\n\n\n\n\n\n\n\ncommunity\nNID\nPOP2010\nPOP2000\nPOPCH\nPOPPERCH\npopplus\npopneg\ngeometry\n\n\n\n\n0\nDOUGLAS\n35\n18238\n26470\n-8232\n-31.099358\n0\n1\nMULTIPOLYGON (((-87.60914 41.84469, -87.60915 ...\n\n\n1\nOAKLAND\n36\n5918\n6110\n-192\n-3.142390\n0\n1\nMULTIPOLYGON (((-87.59215 41.81693, -87.59231 ...\n\n\n\n\n\n\n\nwhich returns a GeoDataFrame object.\nA GeoDataFrame is a tabular data structure that contains a GeoSeries.\nThe most important property of a GeoDataFrame is that it always has one GeoSeries column that holds a special status.\nThis GeoSeries is referred to as the GeoDataFrame’s “geometry”. When a spatial method is applied to a GeoDataFrame (or a spatial attribute like area is called), this commands will always act on the “geometry” column3.\n\n\n\nWe’ve prepared some useful functions in src/ClimRR/data.py to simplify the process of loading and working with our data.\n\n\n\n\n\n\n\n\n\nImports\nimport matplotlib_inline\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport warnings\n\nimport matplotlib.pyplot as plt\n\nfrom enrich.style import STYLES\nfrom rich.theme import Theme\nfrom rich.console import Console as Console\nfrom ClimRR import get_logger, set_plot_style\nfrom ClimRR.data import DATA_DIR\n\nmatplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n\nset_plot_style()\ntheme = Theme(STYLES)\nlog = get_logger()\nconsole = Console(\n    theme=Theme(STYLES),\n    log_path=False,\n    markup=True,\n    width=512\n)\n\n\nUsing updated plot style for matplotlib"
  },
  {
    "objectID": "qmd/GettingStarted/intro.html#getting-started",
    "href": "qmd/GettingStarted/intro.html#getting-started",
    "title": "Climate Analysis with ClimRR",
    "section": "",
    "text": "Useful links + References\n\n\n\n\n\n\nUseful links + References:\n\nGeopandas: An Introduction\nAn Introduction to Earth and Environmental Data Science\n\nFinal Projects (good examples)\nHands-On: Aggregating the Data\n\nUsing Weather Data and Climate Model Output in Economic Analyses of Climate Change\nOn the use and misuse of climate change projections in international development\n\n\n\n\n\n\n\n\n\n\n\nLearning Goals\n\n\n\n\n\nThe goal of this project is to teach students to1:\n\nUse Unix commands to work with files and navigate directories\nUse JupyterHub + basic familiarity with how to use Jupyter notebooks on HPC systems\nIdentify some of the common file types and data formats for geospatial data\n\n(+ common python libraries for geospatial data analysis)\n\nPerform exploratory data analysis on geospatial data\n\n(+ understand different operations for manipulating and interacting with this data)\ntabular vs. gridded data\n\nPerform simple visualizations in Python to display different types of data (e.g. maps, line charts, interactive visualizations, etc)\n\nusing figures to illustrate a point or idea\nknow what types of plots to use for which situations / data types\n\nUnderstand control flow / basic structure of a Python script\n\nusing Python in Jupyter2\nimport-ing libraries, etc\n\n\n\n\n\n\n\nWe use GeoPandas, an open source project to make working with geospatial data in python easier.\nGeoPandas extends the datatypes used by pandas to allow spatial operations on geometric types.\nGeometric operations are performed by shapely.\nGeoPandas further depends on fiona and matplotlib for plotting.\nGeoPandas can read almost any vector-based spatial data format including ESRI shapefile, GeoJSON files and more using the command\n\nimport geopandas as gpd\nimport geodatasets\ngdf = gpd.read_file(geodatasets.get_path(\"geoda.chicago_commpop\"))\ngdf.head(n=2)\n\n\n\n\n\n\n\n\ncommunity\nNID\nPOP2010\nPOP2000\nPOPCH\nPOPPERCH\npopplus\npopneg\ngeometry\n\n\n\n\n0\nDOUGLAS\n35\n18238\n26470\n-8232\n-31.099358\n0\n1\nMULTIPOLYGON (((-87.60914 41.84469, -87.60915 ...\n\n\n1\nOAKLAND\n36\n5918\n6110\n-192\n-3.142390\n0\n1\nMULTIPOLYGON (((-87.59215 41.81693, -87.59231 ...\n\n\n\n\n\n\n\nwhich returns a GeoDataFrame object.\nA GeoDataFrame is a tabular data structure that contains a GeoSeries.\nThe most important property of a GeoDataFrame is that it always has one GeoSeries column that holds a special status.\nThis GeoSeries is referred to as the GeoDataFrame’s “geometry”. When a spatial method is applied to a GeoDataFrame (or a spatial attribute like area is called), this commands will always act on the “geometry” column3.\n\n\n\nWe’ve prepared some useful functions in src/ClimRR/data.py to simplify the process of loading and working with our data.\n\n\n\n\n\n\n\n\n\nImports\nimport matplotlib_inline\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport warnings\n\nimport matplotlib.pyplot as plt\n\nfrom enrich.style import STYLES\nfrom rich.theme import Theme\nfrom rich.console import Console as Console\nfrom ClimRR import get_logger, set_plot_style\nfrom ClimRR.data import DATA_DIR\n\nmatplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n\nset_plot_style()\ntheme = Theme(STYLES)\nlog = get_logger()\nconsole = Console(\n    theme=Theme(STYLES),\n    log_path=False,\n    markup=True,\n    width=512\n)\n\n\nUsing updated plot style for matplotlib"
  },
  {
    "objectID": "qmd/GettingStarted/intro.html#load-shapefile-and-inspect",
    "href": "qmd/GettingStarted/intro.html#load-shapefile-and-inspect",
    "title": "Climate Analysis with ClimRR",
    "section": "Load Shapefile and inspect",
    "text": "Load Shapefile and inspect\nA shapefile is provided in the ClimRR Data Download (ANL) and can be loaded using geopandas.read_file(...) which will return a geopandas.GeoDataFrame:\n\nshpfile = DATA_DIR.joinpath(\n    \"GridCells2Shapefile/GridCellsShapefile/GridCells.shp\"\n)\nshape = gpd.read_file(shpfile)\n\nEach entry in this table defines a single grid cell (12km x 12 km) which collectively tile the United States.\nWe can get a better understanding of whats going on by looking at the first few entries:\n\nshape.head(n=2)\n\n\n\n\n\n\n\n\nOBJECTID\nCrossmodel\nShape_Leng\nShape_Area\ngeometry\n\n\n\n\n0\n1\nR161C438\n63614.764866\n2.529273e+08\nPOLYGON ((-9530601.177 4726046.614, -9534793.8...\n\n\n1\n2\nR125C222\n61384.219597\n2.355013e+08\nPOLYGON ((-12959076.287 4395610.472, -12974301...\n\n\n\n\n\n\n\nWe see that each row has the following columns: {OBJECTID, Crossmodel, Shape_Leng, Shape_Area, geometry}.\nIn particular, the Crossmodel5 column is a text ID that uniquely identifies an individual cell.\nTo be explicit, let’s look at the WindSpeed.csv file."
  },
  {
    "objectID": "qmd/GettingStarted/intro.html#dealing-with-geometry",
    "href": "qmd/GettingStarted/intro.html#dealing-with-geometry",
    "title": "Climate Analysis with ClimRR",
    "section": "Dealing with Geometry",
    "text": "Dealing with Geometry\nOur shapefile contains a grid of cells (12km x 12km) which tile the continental US.\nWe can inspect a single cell:\n\ncell = shape[shape[\"Crossmodel\"] == 'R146C497']\ncell.head()\n\n\n\n\n\n\n\n\nOBJECTID\nCrossmodel\nShape_Leng\nShape_Area\ngeometry\n\n\n\n\n4\n5\nR146C497\n60142.919468\n2.260731e+08\nPOLYGON ((-8733007.764 4224658.634, -8738250.3...\n\n\n\n\n\n\n\n\nax = cell.boundary.plot()\nax.set_axis_off()\n_ = ax.set_title('Grid from shapefile: 12 x 12 km')\nplt.tight_layout()\n\n\n\n\n\ncell.explore()\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "qmd/GettingStarted/intro.html#load-data-from-.csv-files",
    "href": "qmd/GettingStarted/intro.html#load-data-from-.csv-files",
    "title": "Climate Analysis with ClimRR",
    "section": "Load data from *.csv files",
    "text": "Load data from *.csv files\nEach entry (row) in the .csv has a Crossmodel column (e.g. R146C497) which corresponds to a row in our shapefile that uniquely determines its location on the Earth.\nWe can associate with each of the .csvs the geometry used in our shapefile to position our data on the globe.\n\nimport pandas as pd\ncsvs = [i for i in DATA_DIR.rglob('*.csv')]\ndata = {}\nfor f in csvs:\n    key = f.stem\n    tmp = pd.read_csv(f.as_posix())\n    gdf = shape.merge(tmp, on='Crossmodel')\n    gdf['boundary'] = gdf.boundary\n    gdf['centroid'] = gdf.centroid\n    data[key] = gdf\n    console.log(f\"data['{key}'].shape={data[key].shape}\")\n\n[22:54:57] data['FireWeatherIndex_Wildfire'].shape=(62834, 35)                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n\n\n\n           data['HeatingDegreeDays'].shape=(62834, 10)                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n\n\n\n[22:54:58] data['AnnualTemperatureMinimum'].shape=(62834, 18)                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n\n\n\n           data['SeasonalTemperatureMaximum'].shape=(62834, 27)                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n\n\n\n           data['ConsecutiveDayswithNoPrecipitation'].shape=(55896, 19)                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n\n\n\n           data['SeasonalTemperatureMinimum'].shape=(62834, 27)                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n\n\n\n           data['WindSpeed'].shape=(62834, 18)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n\n\n\n           data['AnnualTemperatureMaximum'].shape=(62834, 18)                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n\n\n\n[22:54:59] data['Precipitation_inches_AnnualTotal'].shape=(55896, 18)"
  },
  {
    "objectID": "qmd/GettingStarted/intro.html#look-at-the-windspeed-data",
    "href": "qmd/GettingStarted/intro.html#look-at-the-windspeed-data",
    "title": "Climate Analysis with ClimRR",
    "section": "Look at the WindSpeed data",
    "text": "Look at the WindSpeed data\nLets inspect one of the entries in our data[(...)] dictionary, WindSpeed, for example:\n\ndata[\"WindSpeed\"].head()\n\n\n\n\n\n\n\n\nOBJECTID\nCrossmodel\nShape_Leng\nShape_Area\ngeometry\nhist\nrcp45_midc\nrcp45_endc\nrcp85_midc\nrcp85_endc\nmid45_hist\nend45_hist\nmid85_hist\nend85_hist\nmid85_45\nend85_45\nboundary\ncentroid\n\n\n\n\n0\n1\nR161C438\n63614.764866\n2.529273e+08\nPOLYGON ((-9530601.177 4726046.614, -9534793.8...\n7.21540\n7.19415\n7.38917\n7.30470\n7.22690\n-0.021256\n0.173764\n0.089297\n0.011499\n0.110553\n-0.162264\nLINESTRING (-9530601.177 4726046.614, -9534793...\nPOINT (-9540369.710 4720470.575)\n\n\n1\n2\nR125C222\n61384.219597\n2.355013e+08\nPOLYGON ((-12959076.287 4395610.472, -12974301...\n8.32612\n8.11360\n8.26028\n8.17420\n8.02081\n-0.212523\n-0.065843\n-0.151919\n-0.305307\n0.060603\n-0.239465\nLINESTRING (-12959076.287 4395610.472, -129743...\nPOINT (-12967596.341 4402326.143)\n\n\n2\n3\nR121C235\n61111.892875\n2.334164e+08\nPOLYGON ((-12754805.395 4355815.951, -12770000...\n8.58573\n8.59828\n8.56058\n8.54483\n8.55421\n0.012547\n-0.025149\n-0.040898\n-0.031519\n-0.053446\n-0.006370\nLINESTRING (-12754805.395 4355815.951, -127700...\nPOINT (-12763132.114 4362694.465)\n\n\n3\n4\nR169C431\n64716.234995\n2.617618e+08\nPOLYGON ((-9605729.481 4879238.815, -9609863.1...\n9.17284\n9.21681\n9.44966\n9.26548\n9.14917\n0.043968\n0.276813\n0.092635\n-0.023674\n0.048667\n-0.300487\nLINESTRING (-9605729.481 4879238.815, -9609863...\nPOINT (-9615619.029 4873482.586)\n\n\n4\n5\nR146C497\n60142.919468\n2.260731e+08\nPOLYGON ((-8733007.764 4224658.634, -8738250.3...\n8.25430\n8.19130\n8.34417\n8.29698\n8.29411\n-0.062996\n0.089874\n0.042684\n0.039807\n0.105680\n-0.050067\nLINESTRING (-8733007.764 4224658.634, -8738250...\nPOINT (-8742676.917 4220233.536)\n\n\n\n\n\n\n\nWe see that each entry has a geometry column, as well as columns for {hist,rcp45_midc, rcp45_endc, rcp85_midc, rcp85_endc, ...} which contains the numerical value of the WindSpeed in each cell under different scenarios at different points in time.\n\nLet’s look at the WindSpeed for our individual cell:\n\ncell_wind = data[\"WindSpeed\"][data[\"WindSpeed\"][\"Crossmodel\"] == 'R146C497']\n\n\nax = cell_wind.plot(column='hist', legend=True)\nax.set_axis_off()\n_ = ax.set_title(\"WindSpeed [Hist] for CELL: R146C497\")"
  },
  {
    "objectID": "qmd/GettingStarted/intro.html#footnotes",
    "href": "qmd/GettingStarted/intro.html#footnotes",
    "title": "Climate Analysis with ClimRR",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nBuilding on ideas from Earth and Environmental Science↩︎\nGetting Python setup correctly can be surprisingly difficult↩︎\nThe “geometry” column – no matter its name – can be accessed through the geometry attribute (gdf.geometry), and the name of the geometry column can be found by typing gdf.geometry.name.↩︎\nMetadata↩︎\nTruncated name for “Crossmodel_CellName”.↩︎"
  },
  {
    "objectID": "qmd/ClimRR/analysis.html",
    "href": "qmd/ClimRR/analysis.html",
    "title": "Intro to HPC Bootcamp",
    "section": "",
    "text": "CitationBibTeX citation:@misc{foreman2023,\n  author = {Foreman, Sam},\n  date = {2023-08-01},\n  url = {https://saforem2.github.io/climate-analysis},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nForeman, Sam. 2023. Intro to HPC: Climate Analysis with ClimRR.\nhttps://saforem2.github.io/climate-analysis."
  },
  {
    "objectID": "qmd/GettingStarted/tree.html",
    "href": "qmd/GettingStarted/tree.html",
    "title": "",
    "section": "",
    "text": "📂 ClimRR Data Download/\n┣━━ 📂 GridCells2Shapefile/\n┃   ┣━━ 📄 GridCells2.cpg\n┃   ┣━━ 📄 GridCells2.dbf\n┃   ┣━━ 📄 GridCells2.prj\n┃   ┣━━ 📄 GridCells2.sbn\n┃   ┣━━ 📄 GridCells2.sbx\n┃   ┣━━ 📄 GridCells2.shp\n┃   ┣━━ 📄 GridCells2.shp.xml\n┃   ┗━━ 📄 GridCells2.shx\n┣━━ 📂 GridCellsShapefile/\n┃   ┣━━ 📄 GridCells.cpg\n┃   ┣━━ 📄 GridCells.dbf\n┃   ┣━━ 📄 GridCells.prj\n┃   ┣━━ 📄 GridCells.sbn\n┃   ┣━━ 📄 GridCells.sbx\n┃   ┣━━ 📄 GridCells.shp\n┃   ┣━━ 📄 GridCells.shp.xml\n┃   ┗━━ 📄 GridCells.shx\n┣━━ 📄 AnnualTemperatureMaximum.csv\n┣━━ 📄 AnnualTemperatureMinimum.csv\n┣━━ 📄 ClimRR Metadata and Data Dictionary.pdf\n┣━━ 📄 ConsecutiveDayswithNoPrecipitation.csv\n┣━━ 📄 FireWeatherIndex_Wildfire.csv\n┣━━ 📄 GridCells2Shapefile.zip\n┣━━ 📄 GridCellsShapefile.zip\n┣━━ 📄 HeatingDegreeDays.csv\n┣━━ 📄 Precipitation_inches_AnnualTotal.csv\n┣━━ 📄 README.txt\n┣━━ 📄 SeasonalTemperatureMaximum.csv\n┣━━ 📄 SeasonalTemperatureMinimum.csv\n┗━━ 📄 WindSpeed.csv\n\n\n\nCitationBibTeX citation:@misc{foreman2023,\n  author = {Foreman, Sam},\n  date = {2023-07-14},\n  url = {https://saforem2.github.io/climate-analysis},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nForeman, Sam. 2023. Intro to HPC: Climate Analysis with ClimRR.\nhttps://saforem2.github.io/climate-analysis."
  },
  {
    "objectID": "qmd/GettingStarted/chicago.html",
    "href": "qmd/GettingStarted/chicago.html",
    "title": "Chicago Analysis",
    "section": "",
    "text": "Imports\n%matplotlib inline\nimport matplotlib_inline\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport warnings\n\nimport matplotlib.pyplot as plt\n\n# from enrich.console import Console, get_theme\nmatplotlib_inline.backend_inline.set_matplotlib_formats('svg')\nfrom ClimRR import get_logger, DATA_DIR, set_plot_style\nset_plot_style()\nlog = get_logger('ClimRR')\nfrom rich.console import Console as rConsole\nfrom enrich.style import STYLES\nfrom rich.theme import Theme\n\ntheme = Theme(STYLES)\nlog = get_logger('ClimRR')\nconsole = rConsole(theme=theme, log_path=False, markup=True)\n\n\nUsing updated plot style for matplotlib\n\n\n\n\nfrom ClimRR import load_shapefile, load_csvs\n\nshape = load_shapefile()\ndata = load_csvs(shape)\n\ndata['FireWeatherIndex_Wildfire'].shape=(62834, 35)\n\n\n\ndata['HeatingDegreeDays'].shape=(62834, 10)\n\n\n\ndata['AnnualTemperatureMinimum'].shape=(62834, 18)\n\n\n\ndata['SeasonalTemperatureMaximum'].shape=(62834, 27)\n\n\n\ndata['ConsecutiveDayswithNoPrecipitation'].shape=(55896, 19)\n\n\n\ndata['SeasonalTemperatureMinimum'].shape=(62834, 27)\n\n\n\ndata['WindSpeed'].shape=(62834, 18)\n\n\n\ndata['AnnualTemperatureMaximum'].shape=(62834, 18)\n\n\n\ndata['Precipitation_inches_AnnualTotal'].shape=(55896, 18)\n\n\n\n\nsquare = shape[shape[\"Crossmodel\"] == 'R146C497']\nfig, ax = plt.subplots(figsize=(4, 3))\nax = square.boundary.plot(ax=ax)\nax.set_axis_off()\nplt.tight_layout()\n\n\n\n\n\nimport geopandas as gpd\nimport geodatasets\nchipop = gpd.read_file(\n    geodatasets.get_path('geoda.chicago_commpop')\n).to_crs(square.crs)\nchihealth = gpd.read_file(\n    geodatasets.get_path('geoda.chicago_health')\n).to_crs(square.crs)\nchigroc = gpd.read_file(\n    geodatasets.get_path('geoda.groceries')\n).to_crs(square.crs)\n\nWe can inspect this data, looking at the chipop.boundary for example\n\nchipop['boundary'] = chipop.boundary\n\n\nfig, ax = plt.subplots(figsize=(10, 7))\nax = chipop.boundary.plot(linewidth=0.8, color='#838383', ax=ax)\nax.set_axis_off()\n_ = ax.set_title('Chicago Neighborhoods')\n\n\n\n\nWhich we can use to plot the population (by neighborhood, in this case):\n\nfig, ax = plt.subplots(figsize=(10, 7))\nax = chipop.to_crs(square.crs).plot(column=\"POP2010\", legend=True, ax=ax)\nax.set_axis_off()\n_ = ax.set_title(f\"Chicago population by Neighborhood [2010]\")\n\n\n\n\n\nwtown = chipop[chipop[\"community\"] == 'WEST TOWN']\nhumboldt = chipop[chipop[\"community\"] == 'HUMBOLDT PARK']\n\n\nhumboldt.explore()\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\nfig, ax = plt.subplots(figsize=(10, 7))\nax = humboldt.overlay(shape, how='intersection').plot(ax=ax, legend=True)\nax = (\n    hp := chipop[chipop['community'] == 'HUMBOLDT PARK'].overlay(\n        shape,\n        how='intersection'\n    )\n).plot(ax=ax, legend=True)\nax = (\n    lp := chipop[chipop['community'] == 'LINCOLN PARK'].overlay(\n        shape,\n        how='intersection'\n    )\n).plot(ax=ax, legend=True)\nax = chipop.boundary.plot(ax=ax, color='#666666', linewidth=0.8)\nax = lp.boundary.plot(color='red', ax=ax)\nax = hp.boundary.plot(color='red', ax=ax)\nax.set_axis_off()\n_ = ax.set_title('Intersection of Humboldt Park & ClimRR data')\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(10, 7))\nchiwind = data['WindSpeed'].overlay(\n    chipop,\n    how='intersection'\n).overlay(chipop, how='union')\nax = chiwind.boundary.plot(ax=ax, color='#666666', linewidth=0.8)\nax.set_axis_off()\n\n\n\n\n\n_, ax = plt.subplots(figsize=(10, 7))\nax = chipop.boundary.plot(color='#666666', linewidth=0.8, ax=ax, alpha=0.2)\nax = chiwind.plot(column='hist', ax=ax, legend=True)\nax.set_axis_off()\nax.set_title('Historical Wind Data across Chicago Neighborhoods')\nplt.tight_layout()\n\n\n\n\n\nchiwind.explore(column='hist')\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n_, ax = plt.subplots()\nax = chiwind.plot(column='hist', scheme='quantiles', k=8, ax=ax)\n_ = ax.set_title('WindSpeed, historical')\nax.set_axis_off()\nplt.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots()\nax = chiwind.plot(column='rcp45_midc', scheme='quantiles', k=3, ax=ax)\nax.set_axis_off()\n_ = ax.set_title('WindSpeed, Mid-Century [RCP45]')\nplt.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots()\nax = chiwind.plot(column='rcp45_endc', scheme='quantiles', k=3, ax=ax)\n_ = ax.set_title('WindSpeed, End-Century [RCP45]')\nplt.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots(ncols=3, figsize=(16, 7))\nax0 = chiwind.plot('hist', ax=ax[0])\nax1 = chiwind.plot('rcp45_midc', ax=ax[1])\nax2 = chiwind.plot('rcp45_midc', ax=ax[2])\nax0.set_axis_off()\nax1.set_axis_off()\nax2.set_axis_off()\n\n\n\n\n\ndata['WindSpeed'].shape\n\n(62834, 18)\n\n\n\nselection = shape[0:5]\n\nfor index, row in selection.iterrows():\n    # get the area of the polygon\n    poly_area = row['geometry'].area\n    console.print(f\"Polygon area at {index} is {poly_area:.3f}\")\n\nPolygon area at 0 is 252927293.657\n\n\n\nPolygon area at 1 is 235501313.715\n\n\n\nPolygon area at 2 is 233416379.950\n\n\n\nPolygon area at 3 is 261761834.191\n\n\n\nPolygon area at 4 is 226073092.218\n\n\n\n\n\n\nCitationBibTeX citation:@misc{foreman2023,\n  author = {Foreman, Sam},\n  date = {2023-08-01},\n  url = {https://saforem2.github.io/climate-analysis},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nForeman, Sam. 2023. Intro to HPC: Climate Analysis with ClimRR.\nhttps://saforem2.github.io/climate-analysis."
  },
  {
    "objectID": "qmd/GettingStarted/example.html",
    "href": "qmd/GettingStarted/example.html",
    "title": "Example: Groceries in Chicago",
    "section": "",
    "text": "Using updated plot style for matplotlib\nWe will walk through an example that demonstrates how to clip geometries to the boundary of a polygon geometry using GeoPandas."
  },
  {
    "objectID": "qmd/GettingStarted/example.html#imports",
    "href": "qmd/GettingStarted/example.html#imports",
    "title": "Example: Groceries in Chicago",
    "section": "Imports",
    "text": "Imports\n\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nfrom shapely.geometry import box\nimport geodatasets"
  },
  {
    "objectID": "qmd/GettingStarted/example.html#get-or-create-example-data",
    "href": "qmd/GettingStarted/example.html#get-or-create-example-data",
    "title": "Example: Groceries in Chicago",
    "section": "Get or Create Example Data",
    "text": "Get or Create Example Data\nBelow, the example GeoPandas data is imported and opened as a GeoDataFrame.\nAdditionally, a polygon is created with shapely and then converted into a GeoDataFrame with the same CRS as the GeoPandas dataset\n\nimport geodatasets\nchicago = gpd.read_file(geodatasets.get_path(\"geoda.chicago_commpop\"))\ngroceries = gpd.read_file(geodatasets.get_path(\"geoda.groceries\")).to_crs(chicago.crs)\n\nCreate a subset of the chicago data that is just the near west side\n\nnear_west_side = chicago[chicago[\"community\"] == \"NEAR WEST SIDE\"]\nlincoln_park = chicago[chicago[\"community\"] == \"LINCOLN PARK\"]\nlogan_square = chicago[chicago[\"community\"] == \"LOGAN SQUARE\"]\n\nCreate a custom polygon\n\npolygon = box(-87.8, 41.9, -87.5, 42)\npoly_gdf = gpd.GeoDataFrame([1], geometry=[polygon], crs=chicago.crs)"
  },
  {
    "objectID": "qmd/GettingStarted/example.html#plot-the-unclipped-data",
    "href": "qmd/GettingStarted/example.html#plot-the-unclipped-data",
    "title": "Example: Groceries in Chicago",
    "section": "Plot the Unclipped Data",
    "text": "Plot the Unclipped Data\n\nfig, (ax1, ax2) = plt.subplots(figsize=(14, 6), ncols=2, sharey='col')\npoly_gdf.boundary.plot(ax=ax1, color=COLORS['red'])\nchicago.boundary.plot(ax=ax1, color=COLORS['grey060'], linewidth=0.6, zorder=-1)\n# near_west_side.boundary.plot(ax=ax2, color=COLORS['red'])\n# near_west_side.plot(ax=ax2, color=COLORS['green'], alpha=0.3)\n# west_town.plot(ax=ax2, color=COLORS['green'], alpha=0.3)\nchicago.plot(ax=ax1, alpha=0.4)\npoly_gdf.boundary.plot(ax=ax2, color=COLORS['red'])\nchicago.boundary.plot(ax=ax2, color=COLORS['grey060'], linewidth=0.6, zorder=-1)\ngroceries.plot(ax=ax2, color=COLORS['blue'], zorder=1, marker='.', alpha=0.66)\nax1.set_title(\"All Unclipped Chicago Communities\", fontsize=20)\nax2.set_title(\"All Unclipped Groceries\", fontsize=20)\nax1.set_axis_off()\nax2.set_axis_off()\nplt.tight_layout()"
  },
  {
    "objectID": "qmd/GettingStarted/example.html#clip-the-data",
    "href": "qmd/GettingStarted/example.html#clip-the-data",
    "title": "Example: Groceries in Chicago",
    "section": "Clip the Data",
    "text": "Clip the Data\nThe object on which you call clip is the object that will be clipped.\nThe object you pass is the clip extent.\nThe returned output will be a new clipped GeoDataFrame. All of the attributes for each returned geometry will be retained when you clip.\n\n\n\n\n\n\nCoordinate Reference System\n\n\n\n\n\nRecall that the data must be in the same CRS in order to use the clip method.\nIf the data is not in the same CRS, be sure to use the GeoDataFrame.to_crs method to ensure both datasets are in the same CRS."
  },
  {
    "objectID": "qmd/GettingStarted/example.html#clip-the-chicago-data",
    "href": "qmd/GettingStarted/example.html#clip-the-chicago-data",
    "title": "Example: Groceries in Chicago",
    "section": "Clip the Chicago Data",
    "text": "Clip the Chicago Data\n\nchicago_clipped = chicago.clip(polygon)\ngroceries_clipped = groceries.clip(polygon)\n# plot the clipped data\nfig, ax = plt.subplots(figsize=(14, 6), ncols=2)\nax0 = chicago_clipped.plot(ax=ax[0], color='C0', alpha=0.66)\nax0 = chicago.boundary.plot(ax=ax[0], color=COLORS['grey060'], zorder=-1, linewidth=0.6)\nax0 = poly_gdf.boundary.plot(ax=ax[0], color=COLORS['red'])\n\nax1 = groceries_clipped.plot(ax=ax[1], color='C1', alpha=0.66, zorder=10, marker='.')\n# chicago.boundary.plot(ax=ax[1], color='#444444')\nax1 = chicago.boundary.plot(ax=ax[1], color=COLORS['grey060'], zorder=-1, linewidth=0.6)\nax1 = poly_gdf.boundary.plot(ax=ax[1], color=COLORS['red'])\n\nax0.set_title(\"Chicago Clipped\", fontsize=20)\nax0.set_axis_off()\nax1.set_title(\"Groceries Clipped\", fontsize=20)\nax1.set_axis_off()\nplt.tight_layout()"
  },
  {
    "objectID": "qmd/ClimRR/ClimRR.html",
    "href": "qmd/ClimRR/ClimRR.html",
    "title": "Climate Risk & Resilience Portal",
    "section": "",
    "text": "For completeness, we include text below from (Burdi and Branham 2023)\nClimate scenarios are the set of conditions used to represent estimates of future greenhouse gas (GHG) concentrations in the atmosphere. Climate models then evaluate how these GHG concentrations affect future (projected) climate.\nThe data in ClimRR include model results from two future climate scenarios, called Representative Concentration Pathways (RCPs):\n\nRCP4.5: in this scenario, human GHG emissions peak around 2040, then decline\nRCP8.5: in this scenario, human GHG emissions continue to rise throughout the 21-st century\n\nEach RCP is modeled over a mid-century period (2045—2054) and end-of-century-period (2081 to 2094). A historical period (1995—2004) is also modeled using GHG concentrations during this period."
  },
  {
    "objectID": "qmd/ClimRR/ClimRR.html#climate-scenarios",
    "href": "qmd/ClimRR/ClimRR.html#climate-scenarios",
    "title": "Climate Risk & Resilience Portal",
    "section": "",
    "text": "For completeness, we include text below from (Burdi and Branham 2023)\nClimate scenarios are the set of conditions used to represent estimates of future greenhouse gas (GHG) concentrations in the atmosphere. Climate models then evaluate how these GHG concentrations affect future (projected) climate.\nThe data in ClimRR include model results from two future climate scenarios, called Representative Concentration Pathways (RCPs):\n\nRCP4.5: in this scenario, human GHG emissions peak around 2040, then decline\nRCP8.5: in this scenario, human GHG emissions continue to rise throughout the 21-st century\n\nEach RCP is modeled over a mid-century period (2045—2054) and end-of-century-period (2081 to 2094). A historical period (1995—2004) is also modeled using GHG concentrations during this period."
  },
  {
    "objectID": "qmd/ClimRR/ClimRR.html#downscaled-climate-models",
    "href": "qmd/ClimRR/ClimRR.html#downscaled-climate-models",
    "title": "Climate Risk & Resilience Portal",
    "section": "Downscaled Climate Models",
    "text": "Downscaled Climate Models\nA global climate model (GCM) is a complex mathematical representation of the major climate system components (atmosphere, land surface, ocean, and sea ice) and their interactions.\nThese models project climatic conditions at frequent intervals over long periods of time (e.g., every 3 hours for the next 50—100 years), often with the purpose of evaluating how one or more GHG scenarios will impact future climate.\nMost GCMs project patterns at relatively coarse spatial resolutions, using grid cells ranging from 100km to 200km.\nThe climate data presented in this portal has been downscaled to a higher spatial resolution (12km) to fill a growing need for risk analysis and resilience planning at the local level.\nWe use dynamical downscaling, which applies the outputs of a GCM as inputs to a separate, high-resolution regional climate model.\nDynamical downscaling accounts for the physical processes and natural features of a region, as well as the complex interaction between these elements and global dynamics under a climate scenario.\nArgonne’s dynamical downscaling uses the Weather Research and Forecasting (WRF) model, which is a regional weather model for North America developed by the National Center for Atmospheric Research.\nScientists at Argonne dynamically downscaled three different GCMs, including:\n\nCCSM: The Community Climate System Model (Version 4) is a coupled global climate model developed by the University Corporation for Atmospheric Research with funding from the National Science Foundation, the Department of Energy, and the National Aeronautics and Space Administration. It is comprised of atmospheric, land surface, and sea ice sub-models that run simultaneously with a central coupler component.\nGFDL: The Geophysical Fluid Dynamics Laboratory at the National Oceanic and Atmospheric Administration developed the Earth System Model Version 2G (note: the general convention, which we use, is to use the Laboratory’s abbreviation to identify this model). It includes an atmospheric circulation model and an oceanic circulation model, and takes into account land, sea ice, and iceberg dynamics.\nHadGEM: The United Kingdom’s Met Office developed the Hadley Global Environment Model 2—Earth System. It is used for both operational weather forecasting and climate research, and includes coupled atmosphere‐ocean analysis and an earth system component that includes dynamic vegetation, ocean biology, and atmospheric chemistry."
  },
  {
    "objectID": "qmd/ClimRR/ClimRR.html#ensemble-means",
    "href": "qmd/ClimRR/ClimRR.html#ensemble-means",
    "title": "Climate Risk & Resilience Portal",
    "section": "Ensemble Means",
    "text": "Ensemble Means\nAll data layers in ClimRR represent a climate variable along with its associated time period and climate scenario (e.g. mid-century RCP4.5). Each time period comprises one decade’s worth of information:\n\nhistorical: (1995 — 2004)\nmid-century: (2045 — 2054)\nend-of-century: (2085 — 2094)\n\nFor each scenario, the WRF model is run with each of the three GCM outputs, producing three individual decades of weather data for each scenario.\nIn other words, 30 years of downscaled climate data is produced for each decadal scenario.\nBy using the outputs from three different GCMs, rather than a single model, Argonne’s climate projections better account for the internal uncertainty associated with any single model.\nEach year’s worth of data includes weather outputs for every 3 hours, or 8 modeled outputs per day.\nWhile this allows for a high degree of granularity in assessing future climate models, there are many different ways to analyze this data; however, there are several important common methodologies share across all variables presented in this portal.\nMost variables are presented as annual or seasonal averages of daily observations, yet each annual / seasonal average draws upon all three different climate model runs for that scenario and the ten years of data produced by each model.\n\n\n\n\n\n\nEnsemble Mean\n\n\n\n\n\nEach variable (e.g. total_annual_precipitation) for a given scenario (e.g. Mid-century RCP4.5) is produced by calculating an individual estimate for each of the 30 years of climate data associated with that scenario, and then taking the average of 30 estimates.\nThis result is what we term the ensemble mean."
  },
  {
    "objectID": "qmd/ClimRR/ClimRR.html#metadata",
    "href": "qmd/ClimRR/ClimRR.html#metadata",
    "title": "Climate Risk & Resilience Portal",
    "section": "Metadata",
    "text": "Metadata\nThe links below direct to the REST service of the gridded data. Metadata, descriptions, and field names were last updated on 11/7/2022.\n\nTemperature Minimum – Annual\nTemperature Minimum – Seasonal\nTemperature Maximum – Annual\nTemperature Maximum – Seasonal\nPrecipitation – Annual Total\nPrecipitation None – Annual Average\nWind Speed – Annual Average\nCooling Degree Days – Annual Total\nHeating Degree Days – Annual Total\n\nThe definitions for each of these terms can be found here."
  },
  {
    "objectID": "qmd/ClimRR/ClimRR.html#temperature-annual",
    "href": "qmd/ClimRR/ClimRR.html#temperature-annual",
    "title": "Climate Risk & Resilience Portal",
    "section": "Temperature (Annual)",
    "text": "Temperature (Annual)\nEach climate model generates temperature readings every 3 hours, or 8 temperature readings per day.\nThe maximum daily temperature refers to the highest of these 8 readings, which often occurs in the middle of the daytime and is comparable to the ‘high temperature’ in a daily weather forecast.\nSimilarly, the minimum daily temperature refers to the lowest of these 8 readings, which often occurs overnight and is comparable to the ‘low temperature’ in a daily weather forecast.\nArgonne calculated the annual average of both the maximum and minimum daily temperatures.\nThese daily high / low readings were then used to calculate the annual average maximum or minimum daily temperature for that scenario’s model year (e.g. the average max daily temperature for 2045 using the CCSM model under RCP4.5).\nThis process was repeated for each year within a given time period / scenario (e.g. 2046, 2047, and so forth) across all three climate models (CCSM, GFDL, and HadGEM).\nFinally, the 30 individual annual averages for a given time period/scenario were themselves averaged, producing a multi-model ensemble mean that represents the annual average of the maximum or minimum daily temperature for a given time period / scenario."
  },
  {
    "objectID": "qmd/GettingStarted/setup.html#download-the-data",
    "href": "qmd/GettingStarted/setup.html#download-the-data",
    "title": "Getting Started",
    "section": "Download the Data",
    "text": "Download the Data\nThe data is available as a *.zip file with everything you will need to get started.\n\n\n\n\n\n\nFinding the data\n\n\n\n\n\n\nThe data needed for this project has already been copied to the NERSC systems and can be found at:\n\n$ ls /global/cfs/cdirs/m4388/Project2-ClimRR/data/ClimRR/\n AnnualTemperatureMaximum.csv  'ClimRR Metadata and Data Dictionary.pdf'   FireWeatherIndex_Wildfire.csv   GridCellsShapefile.zip   Precipitation_inches_AnnualTotal.csv   SeasonalTemperatureMaximum.csv   WindSpeed.csv\n AnnualTemperatureMinimum.csv   ConsecutiveDayswithNoPrecipitation.csv     GridCells2Shapefile.zip         HeatingDegreeDays.csv    README.txt                             SeasonalTemperatureMinimum.csv\nthe data is also available online and can be downloaded from ClimRR Data Download (ANL)\n\n\n\n\nClone the Github repo\ngit clone https://github.com/saforem2/climate-analysis\ncd ./climate-analysis/\nCreate a virtual environment (venv)1 and install ClimRR into it2:\n# ------------------------------------------------------------\n# 1. Make a directory where the venv will live\nmkdir -p ./venvs/ClimRR\n# 2. Create a virtual environment with `python3 -m venv`\npython3 -m venv ./venvs/ClimRR --system-site-packages\n# 3. Install the python package as an editable install (`-e`)\n# ------------------------------------------------------------\npython3 -m pip install -e \".[dev]\"\n# 4. Verify the package was installed correctly\npython3 -c 'import ClimRR ; print(ClimRR.__file__)'\n# should print something like:\n# /Users/samforeman/projects/saforem2/climate-analysis/src/ClimRR/__init__.py"
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "Climate Analysis with ClimRR",
    "section": "",
    "text": "Figure 1: Image Source\n\n\n\nEmpowering individuals, governments, and organizations to examine simulated future climate conditions at mid- and end-of-century for a range of climate perils.\n\nThe ClimRR Portal can be viewed online, and is a great resource for interactive exploration.\nClimate change is increasing the complexity, intensity, and frequency of disasters.\nUnderstanding future climate conditions in cities and towns across the United States is necessary to prepare for future climate realities.\nTo address this requirement, ClimRR1 — the Climate Risk and Resilience Portal — empowers individuals, governments, and organizations to examine simulated future climate conditions at mid- and end-of-century for a range of climate perils.\n\n\n\n\n\n\n\nDownload Data\n\n\n\n\n\n\nClimRR Data Download (ANL)\nCounties - United States of America\n\n\n\n\n\n\nProject Description\n\nAre different populations unequally affected by climate change? This project will explore the intersection of climate data and energy justice, providing an introductory understanding of data science techniques in assessing disparate outcomes on vulnerable or underserved populations in the United States. By shedding light on energy disparities, the project aims to contribute to the ongoing discussions surrounding energy equity and inform policymakers and stakeholders for more inclusive energy initiatives. Energy justice refers to the equitable distribution of clean, affordable, and reliable energy resources among all communities, regardless of their socioeconomic status or demographic characteristics.\nThis project will focus on the analysis of climate data and low-income energy affordability data across the United States. The analysis will focus on examining energy consumption patterns, renewable energy adoption rates, and energy affordability across different geographical regions and demographic groups.\nTo assess disparate outcomes, the project will employ various statistical techniques to compare energy-related indicators among vulnerable populations.\nThis work may involve analyzing energy access in low-income neighborhoods, evaluating the impact of energy policies on marginalized communities, or examining the correlation between energy affordability and socioeconomic factors.\nThe findings of the analysis will be interpreted to gain insights into the disparities in energy justice and its impact on vulnerable populations. The project aims to identify areas where energy inequalities exist and provide a data-driven foundation for advocating for equitable energy policies and programs."
  },
  {
    "objectID": "index.html#climate-risk-resilience-portal-climrr",
    "href": "index.html#climate-risk-resilience-portal-climrr",
    "title": "Intro to HPC: ClimRR",
    "section": "Climate Risk & Resilience Portal (ClimRR)",
    "text": "Climate Risk & Resilience Portal (ClimRR)\nThe ClimRR Portal can be viewed online, and is a great resource for interactive exploration.\nClimate change is increasing the complexity, intensity, and frequency of disasters.\nUnderstanding future climate conditions in cities and towns across the United States is necessary to prepare for future climate realities.\nTo address this requirement, ClimRR2 — the Climate Risk and Resilience Portal — empowers individuals, governments, and organizations to examine simulated future climate conditions at mid- and end-of-century for a range of climate perils.\n\n\n\n\n\n\n\nFinding the data\n\n\n\n\n\n\nThe data needed for this project has already been copied to the NERSC systems and can be found at:\n\n$ ls /global/cfs/cdirs/m4388/Project2-ClimRR/data/ClimRR/\n AnnualTemperatureMaximum.csv  'ClimRR Metadata and Data Dictionary.pdf'   FireWeatherIndex_Wildfire.csv   GridCellsShapefile.zip   Precipitation_inches_AnnualTotal.csv   SeasonalTemperatureMaximum.csv   WindSpeed.csv\n AnnualTemperatureMinimum.csv   ConsecutiveDayswithNoPrecipitation.csv     GridCells2Shapefile.zip         HeatingDegreeDays.csv    README.txt                             SeasonalTemperatureMinimum.csv\nthe data is also available online and can be downloaded from ClimRR Data Download (ANL)\n\n\n\n\n\n \n\n\nProject Description\n\nAre different populations unequally affected by climate change? This project will explore the intersection of climate data and energy justice, providing an introductory understanding of data science techniques in assessing disparate outcomes on vulnerable or underserved populations in the United States. By shedding light on energy disparities, the project aims to contribute to the ongoing discussions surrounding energy equity and inform policymakers and stakeholders for more inclusive energy initiatives. Energy justice refers to the equitable distribution of clean, affordable, and reliable energy resources among all communities, regardless of their socioeconomic status or demographic characteristics.\nThis project will focus on the analysis of climate data and low-income energy affordability data across the United States. The analysis will focus on examining energy consumption patterns, renewable energy adoption rates, and energy affordability across different geographical regions and demographic groups.\nTo assess disparate outcomes, the project will employ various statistical techniques to compare energy-related indicators among vulnerable populations.\nThis work may involve analyzing energy access in low-income neighborhoods, evaluating the impact of energy policies on marginalized communities, or examining the correlation between energy affordability and socioeconomic factors.\nThe findings of the analysis will be interpreted to gain insights into the disparities in energy justice and its impact on vulnerable populations. The project aims to identify areas where energy inequalities exist and provide a data-driven foundation for advocating for equitable energy policies and programs."
  },
  {
    "objectID": "qmd/GettingStarted/example.html#clip-the-groceries-data",
    "href": "qmd/GettingStarted/example.html#clip-the-groceries-data",
    "title": "Example: Groceries in Chicago",
    "section": "Clip the Groceries Data",
    "text": "Clip the Groceries Data\nNext we’ll look at the distribution of grocery stores in two different communities.\n\nfig, (ax1, ax2) = plt.subplots(figsize=(14, 6), ncols=2, sharey='col')\nchicago.boundary.plot(ax=ax1, color=COLORS['grey060'], linewidth=0.6, zorder=-1)\nnear_west_side.boundary.plot(ax=ax2, color=COLORS['red'])\nnear_west_side.plot(ax=ax2, color=COLORS['green'], alpha=0.3)\n\nlogan_square.boundary.plot(ax=ax2, color=COLORS['red'])\nlogan_square.plot(ax=ax2, color=COLORS['green'], alpha=0.3)\n# west_town.plot(ax=ax2, color=COLORS['green'], alpha=0.3)\nchicago.plot(ax=ax1, alpha=0.4)\nchicago.boundary.plot(ax=ax2, color=COLORS['grey060'], linewidth=0.6, zorder=-1)\ngroceries.plot(ax=ax2, color=COLORS['blue'], zorder=1, marker='.', alpha=0.66)\nax1.set_title(\"All Unclipped Chicago Communities\", fontsize=20)\nax2.set_title(\"All Unclipped Groceries\", fontsize=20)\nax1.set_axis_off()\nax2.set_axis_off()\nplt.tight_layout()"
  },
  {
    "objectID": "qmd/GettingStarted/intro.html#visualizing-our-data",
    "href": "qmd/GettingStarted/intro.html#visualizing-our-data",
    "title": "Climate Analysis with ClimRR",
    "section": "Visualizing our Data",
    "text": "Visualizing our Data\nLets inspect the first few entries from our Shapefile:\n\n\n\n\nCode\nfig, ax = plt.subplots(\n    figsize=(12, 3.5),\n    nrows=1,\n    ncols=3,\n    sharey='row'\n)\nax = ax.flatten()\npairs = {\n    '1k': list(range(1000)),\n    '5k': list(range(5000)),\n    '20k': list(range(20000)),\n}\nfor idx, (key, val) in enumerate(pairs.items()):\n    ax[idx] = shape.loc[val, :].plot(ax=ax[idx])\n    ax[idx].set_axis_off()\n    _ = ax[idx].set_title(f\"First {key} cells\")\nplt.tight_layout()\n\n\n\n\n\nFigure 2: As we include more cells, we see the outline of the US beginning to take shape."
  },
  {
    "objectID": "qmd/GettingStarted/example.html#groceries-in-near-west-side",
    "href": "qmd/GettingStarted/example.html#groceries-in-near-west-side",
    "title": "Example: Groceries in Chicago",
    "section": "Groceries in Near West Side",
    "text": "Groceries in Near West Side\n\ngroceries_west_side = groceries.clip(near_west_side)\nfig, ax = plt.subplots(figsize=(14,6))\ngroceries_west_side.plot(ax=ax, color='C2', marker='.', alpha=0.6)\nchicago.boundary.plot(ax=ax, color=COLORS['grey060'], linewidth=0.6, zorder=-1)\nnear_west_side.boundary.plot(ax=ax, color='#444444')\nnear_west_side.boundary.plot(ax=ax, color=COLORS['red'])\nnear_west_side.plot(ax=ax, color=COLORS['green'], alpha=0.3)\nax.set_title(\"Groceries in the Near West Side\")\nax.set_axis_off()"
  },
  {
    "objectID": "qmd/GettingStarted/example.html#groceries-in-logan-square",
    "href": "qmd/GettingStarted/example.html#groceries-in-logan-square",
    "title": "Example: Groceries in Chicago",
    "section": "Groceries in Logan Square",
    "text": "Groceries in Logan Square\n\ngroceries_logan_square = groceries.clip(logan_square)\nfig, ax = plt.subplots(figsize=(14,6))\ngroceries_logan_square.plot(ax=ax, color='C2', marker='.', alpha=0.6)\nchicago.boundary.plot(ax=ax, color=COLORS['grey060'], linewidth=0.6, zorder=-1)\nlogan_square.boundary.plot(ax=ax, color='#444444')\nlogan_square.boundary.plot(ax=ax, color=COLORS['red'])\nlogan_square.plot(ax=ax, color=COLORS['green'], alpha=0.3)\nax.set_title(\"Groceries in Logan Square\")\nax.set_axis_off()"
  },
  {
    "objectID": "qmd/GettingStarted/example.html#groceries-in-lincoln-park",
    "href": "qmd/GettingStarted/example.html#groceries-in-lincoln-park",
    "title": "Example: Groceries in Chicago",
    "section": "Groceries in Lincoln Park",
    "text": "Groceries in Lincoln Park\n\ngroceries_lp = groceries.clip(lincoln_park)\nfig, ax = plt.subplots(figsize=(14,6))\ngroceries_lp.plot(ax=ax, color='C2')\nchicago.boundary.plot(ax=ax, color=COLORS['grey060'], linewidth=0.6, zorder=-1)\nlincoln_park.boundary.plot(ax=ax, color='#444444')\nlincoln_park.boundary.plot(ax=ax, color=COLORS['red'])\nlincoln_park.plot(ax=ax, color=COLORS['green'], alpha=0.3)\nax.set_title(\"Groceries in Lincoln Park\")\nax.set_axis_off()"
  },
  {
    "objectID": "qmd/GettingStarted/example.html#additional-questions",
    "href": "qmd/GettingStarted/example.html#additional-questions",
    "title": "Example: Groceries in Chicago",
    "section": "Additional Questions",
    "text": "Additional Questions\n\nCan you identify which neighborhoods have the most grocery stores? How many?\n\nWhich have the least? How many?"
  },
  {
    "objectID": "qmd/GettingStarted/example.html#reference",
    "href": "qmd/GettingStarted/example.html#reference",
    "title": "Example: Groceries in Chicago",
    "section": "Reference",
    "text": "Reference\nGeoPandas: Clip Vector Data"
  },
  {
    "objectID": "qmd/ClimRR/ClimRR.html#temperature-seasonal",
    "href": "qmd/ClimRR/ClimRR.html#temperature-seasonal",
    "title": "Climate Risk & Resilience Portal",
    "section": "Temperature (Seasonal)",
    "text": "Temperature (Seasonal)\nEach climate model generates temperature readings every 3 hours, or 8 temperature readings per day.\nThe maximum daily temperature refers to the highest of these 8 readings, which often occurs in the middle of the daytime and is comparable to the ‘high temperature’ in a daily weather forecast.\nSimilarly, the minimum daily temperature refers to the lowest of these 8 readings, which often occurs overnight and is comparable to the ‘low temperature’ in a daily weather forecast.\nArgonne calculated the seasonal average of both the maximum and minimum daily temperatures; the seasons are segmented as\n\nWinter (Dec, Jan, Feb)\nSpring (March, April, May)\nSummer (June, July, Aug)\nAutumn (Sep, Oct, Nov)\n\nThese calculations involved extracting the highest temperature reading and lowest temperature reading for each individual day of a year (e.g. 2045) within a given time period / scenario (e.g. mid-century RCP4.5) and for a given climate model (e.g. CCSM).\nThese daily high / low readings were then classified by season and used to calculate the seasonal average maximum or minimum daily temperature for that scenario’s model year (e.g. the average daily max temperature for summer of 2045 using the CCSM model under RCP4.5).\nThis process was repeated for each year within a given time period / scenario (e.g. 2046, 2047, and so forth) across all three climate models (CCSM, GFDL, and HadGEM).\nFinally, the 30 individual seasonal averages for a given time period / scenario were themselves averaged, producing a multi-modal ensemble mean that represents the seasonal average of the maximum or minimum daily temperature for a given time period / scenario."
  },
  {
    "objectID": "qmd/ClimRR/ClimRR.html#precipitation",
    "href": "qmd/ClimRR/ClimRR.html#precipitation",
    "title": "Climate Risk & Resilience Portal",
    "section": "Precipitation",
    "text": "Precipitation\nEach climate model estimates an amount of precipitation (whether rain, snow, sleet, or ice) that occurs every 3 hours across the entire modeled time period (i.e. every 3 hours, of every day, for all modeled years).\nThese 3-hour precipitation estimates can be used to calculate the total precipitation over a designated period of time, ranging from daily to annually.\nArgonne calculated total annual precipitation by adding all 3-hour precipitation estimates for a given year (e.g. 2045) within a given time period / scenario (e.g. mid-century RCP4.5) and for a given climate model (e.g. CCSM), which produced the total annual precipitation for that scenario’s model year, such as CCSM’s estimate of annual precipitation in 2045 under climate scenario RCP4.5.\nThis process was repeated for each year within a given time period / scenario (e.g. 2046, 2047, and so forth) and across all three climate models (CCSM, GFDL, and HadGEM), producing a total of 30 estimates of total annual precipitation for a given time period / scenario.\nThe average of these values was taken to produce the ensemble mean of the total annual precipitation (in inches) for each time period / scenario."
  },
  {
    "objectID": "qmd/ClimRR/ClimRR.html#wind-speed",
    "href": "qmd/ClimRR/ClimRR.html#wind-speed",
    "title": "Climate Risk & Resilience Portal",
    "section": "Wind Speed",
    "text": "Wind Speed\nEach climate model generates estimated wind speed readings (in miles per hour, or mph) every 3 hours, or 8 wind speed readings per day.\nThese values are irrespective of wind direction and only represent the magnitude of wind speed.\nUsing these readings, Argonne calculated the average daily wind speed (the average of each day’s 8 wind speed readings) for every day within a given time period / scenario (e.g. mid-century RCP4.5) and for each climate model (CCSM, GFDL, and HadGEM).\nArgonne then took the average of each daily average wind speed for a given year (e.g. 2045) and within a given time period / scenario (e.g. mid-century RCP4.5) and for a given climate model (e.g. CCSM), which produced the annual average wind speed for that scenario’s model year, such as CCSM’s estimate of annual average wind speeds in 2045 under climate scenario RCP4.5.\nThis process was repeated for each year within a given time period / scenario.\nThe average of these values was taken to produce the ensemble mean of the annual average wind speed (in mph) for each time period / scenario."
  },
  {
    "objectID": "qmd/ClimRR/ClimRR.html#consecutive-days-with-no-precipitation",
    "href": "qmd/ClimRR/ClimRR.html#consecutive-days-with-no-precipitation",
    "title": "Climate Risk & Resilience Portal",
    "section": "Consecutive Days With No Precipitation",
    "text": "Consecutive Days With No Precipitation\nEach climate model estimates an amount of precipitation (whether rain, snow, sleet, or ice) that occurs every 3 hours across the entire modeled time period (i.e. every 3 hours, of every day, for all modeled years).\nThese 3-hour precipitation estimates were used to calculate the daily precipitation quantities by adding all 8 precipitation readings for each day of a given year (e.g. 2045) within a given time period / scenario (e.g. mid-century RCP4.5) and for a given climate model (e.g. CCSM).\nThis process produced the total daily precipitation for every day in a scenario’s model year, such as CCSM’s daily estimates of total precipitation for the year 2045 under climate scenario RCP4.5.\nUsing this information, Argonne identified the greatest number of consecutive days in which no precipitation occurred (i.e. the total daily precipitation quantity equaled zero) for that scenario’s model year (e.g. for the year 2045 under scenario RCP4.5, the highest number of consecutive days without any precipitation was X).\nThis process was repeated for each year within a given time period / scenario (e.g. 2046, 2047 and so forth) across all three climate models (CCSM, GFDL, and HadGEM) producing 10 yearly values for each model, with each value representing the longest consecutive span with no precipitation for that year.\nOf the 10 yearly values for each climate model, the maximum value was selected (e.g. the decadal maximum). This resulted in 3 values for each climate model’s 10 years of data.\nThe average of these maximum of the maxima was then taken to produce the ensemble mean of the decade’s highest number of consecutive days without precipitation in a single year."
  },
  {
    "objectID": "qmd/ClimRR/definitions.html",
    "href": "qmd/ClimRR/definitions.html",
    "title": "Climate Variables",
    "section": "",
    "text": "Each climate model generates temperature readings every 3 hours, or 8 temperature readings per day.\nThe maximum daily temperature refers to the highest of these 8 readings, which often occurs in the middle of the daytime and is comparable to the ‘high temperature’ in a daily weather forecast.\nSimilarly, the minimum daily temperature refers to the lowest of these 8 readings, which often occurs overnight and is comparable to the ‘low temperature’ in a daily weather forecast.\nArgonne calculated the annual average of both the maximum and minimum daily temperatures.\nThese daily high / low readings were then used to calculate the annual average maximum or minimum daily temperature for that scenario’s model year (e.g. the average max daily temperature for 2045 using the CCSM model under RCP4.5).\nThis process was repeated for each year within a given time period / scenario (e.g. 2046, 2047, and so forth) across all three climate models (CCSM, GFDL, and HadGEM).\nFinally, the 30 individual annual averages for a given time period/scenario were themselves averaged, producing a multi-model ensemble mean that represents the annual average of the maximum or minimum daily temperature for a given time period / scenario."
  },
  {
    "objectID": "qmd/ClimRR/definitions.html#temperature-seasonal",
    "href": "qmd/ClimRR/definitions.html#temperature-seasonal",
    "title": "Climate Variables",
    "section": "Temperature (Seasonal)",
    "text": "Temperature (Seasonal)\nEach climate model generates temperature readings every 3 hours, or 8 temperature readings per day.\nThe maximum daily temperature refers to the highest of these 8 readings, which often occurs in the middle of the daytime and is comparable to the ‘high temperature’ in a daily weather forecast.\nSimilarly, the minimum daily temperature refers to the lowest of these 8 readings, which often occurs overnight and is comparable to the ‘low temperature’ in a daily weather forecast.\nArgonne calculated the seasonal average of both the maximum and minimum daily temperatures; the seasons are segmented as\n\nWinter (Dec, Jan, Feb)\nSpring (March, April, May)\nSummer (June, July, Aug)\nAutumn (Sep, Oct, Nov)\n\nThese calculations involved extracting the highest temperature reading and lowest temperature reading for each individual day of a year (e.g. 2045) within a given time period / scenario (e.g. mid-century RCP4.5) and for a given climate model (e.g. CCSM).\nThese daily high / low readings were then classified by season and used to calculate the seasonal average maximum or minimum daily temperature for that scenario’s model year (e.g. the average daily max temperature for summer of 2045 using the CCSM model under RCP4.5).\nThis process was repeated for each year within a given time period / scenario (e.g. 2046, 2047, and so forth) across all three climate models (CCSM, GFDL, and HadGEM).\nFinally, the 30 individual seasonal averages for a given time period / scenario were themselves averaged, producing a multi-modal ensemble mean that represents the seasonal average of the maximum or minimum daily temperature for a given time period / scenario."
  },
  {
    "objectID": "qmd/ClimRR/definitions.html#precipitation",
    "href": "qmd/ClimRR/definitions.html#precipitation",
    "title": "Climate Variables",
    "section": "Precipitation",
    "text": "Precipitation\nEach climate model estimates an amount of precipitation (whether rain, snow, sleet, or ice) that occurs every 3 hours across the entire modeled time period (i.e. every 3 hours, of every day, for all modeled years).\nThese 3-hour precipitation estimates can be used to calculate the total precipitation over a designated period of time, ranging from daily to annually.\nArgonne calculated total annual precipitation by adding all 3-hour precipitation estimates for a given year (e.g. 2045) within a given time period / scenario (e.g. mid-century RCP4.5) and for a given climate model (e.g. CCSM), which produced the total annual precipitation for that scenario’s model year, such as CCSM’s estimate of annual precipitation in 2045 under climate scenario RCP4.5.\nThis process was repeated for each year within a given time period / scenario (e.g. 2046, 2047, and so forth) and across all three climate models (CCSM, GFDL, and HadGEM), producing a total of 30 estimates of total annual precipitation for a given time period / scenario.\nThe average of these values was taken to produce the ensemble mean of the total annual precipitation (in inches) for each time period / scenario."
  },
  {
    "objectID": "qmd/ClimRR/definitions.html#wind-speed",
    "href": "qmd/ClimRR/definitions.html#wind-speed",
    "title": "Climate Variables",
    "section": "Wind Speed",
    "text": "Wind Speed\nEach climate model generates estimated wind speed readings (in miles per hour, or mph) every 3 hours, or 8 wind speed readings per day.\nThese values are irrespective of wind direction and only represent the magnitude of wind speed.\nUsing these readings, Argonne calculated the average daily wind speed (the average of each day’s 8 wind speed readings) for every day within a given time period / scenario (e.g. mid-century RCP4.5) and for each climate model (CCSM, GFDL, and HadGEM).\nArgonne then took the average of each daily average wind speed for a given year (e.g. 2045) and within a given time period / scenario (e.g. mid-century RCP4.5) and for a given climate model (e.g. CCSM), which produced the annual average wind speed for that scenario’s model year, such as CCSM’s estimate of annual average wind speeds in 2045 under climate scenario RCP4.5.\nThis process was repeated for each year within a given time period / scenario.\nThe average of these values was taken to produce the ensemble mean of the annual average wind speed (in mph) for each time period / scenario."
  },
  {
    "objectID": "qmd/ClimRR/definitions.html#consecutive-days-with-no-precipitation",
    "href": "qmd/ClimRR/definitions.html#consecutive-days-with-no-precipitation",
    "title": "Climate Variables",
    "section": "Consecutive Days With No Precipitation",
    "text": "Consecutive Days With No Precipitation\nEach climate model estimates an amount of precipitation (whether rain, snow, sleet, or ice) that occurs every 3 hours across the entire modeled time period (i.e. every 3 hours, of every day, for all modeled years).\nThese 3-hour precipitation estimates were used to calculate the daily precipitation quantities by adding all 8 precipitation readings for each day of a given year (e.g. 2045) within a given time period / scenario (e.g. mid-century RCP4.5) and for a given climate model (e.g. CCSM).\nThis process produced the total daily precipitation for every day in a scenario’s model year, such as CCSM’s daily estimates of total precipitation for the year 2045 under climate scenario RCP4.5.\nUsing this information, Argonne identified the greatest number of consecutive days in which no precipitation occurred (i.e. the total daily precipitation quantity equaled zero) for that scenario’s model year (e.g. for the year 2045 under scenario RCP4.5, the highest number of consecutive days without any precipitation was X).\nThis process was repeated for each year within a given time period / scenario (e.g. 2046, 2047 and so forth) across all three climate models (CCSM, GFDL, and HadGEM) producing 10 yearly values for each model, with each value representing the longest consecutive span with no precipitation for that year.\nOf the 10 yearly values for each climate model, the maximum value was selected (e.g. the decadal maximum). This resulted in 3 values for each climate model’s 10 years of data.\nThe average of these maximum of the maxima was then taken to produce the ensemble mean of the decade’s highest number of consecutive days without precipitation in a single year."
  },
  {
    "objectID": "qmd/ClimRR/definitions.html#degree-days",
    "href": "qmd/ClimRR/definitions.html#degree-days",
    "title": "Climate Variables",
    "section": "Degree Days",
    "text": "Degree Days"
  },
  {
    "objectID": "qmd/ClimRR/definitions.html#temperature-annual",
    "href": "qmd/ClimRR/definitions.html#temperature-annual",
    "title": "Climate Variables",
    "section": "",
    "text": "Each climate model generates temperature readings every 3 hours, or 8 temperature readings per day.\nThe maximum daily temperature refers to the highest of these 8 readings, which often occurs in the middle of the daytime and is comparable to the ‘high temperature’ in a daily weather forecast.\nSimilarly, the minimum daily temperature refers to the lowest of these 8 readings, which often occurs overnight and is comparable to the ‘low temperature’ in a daily weather forecast.\nArgonne calculated the annual average of both the maximum and minimum daily temperatures.\nThese daily high / low readings were then used to calculate the annual average maximum or minimum daily temperature for that scenario’s model year (e.g. the average max daily temperature for 2045 using the CCSM model under RCP4.5).\nThis process was repeated for each year within a given time period / scenario (e.g. 2046, 2047, and so forth) across all three climate models (CCSM, GFDL, and HadGEM).\nFinally, the 30 individual annual averages for a given time period/scenario were themselves averaged, producing a multi-model ensemble mean that represents the annual average of the maximum or minimum daily temperature for a given time period / scenario."
  },
  {
    "objectID": "qmd/ClimRR/chicago-temp.html",
    "href": "qmd/ClimRR/chicago-temp.html",
    "title": "Chicago Temperature Analysis",
    "section": "",
    "text": "Target Goals\n\n\n\n\n\n\nRepeat this analysis with:\n\nDifferent climate variables\nAnother state / geographic area\nAnother climate scenario\n\nAny interesting trends or insights to be drawn from the data\n\n\n\n\n\n\nImports\n%matplotlib inline\nimport matplotlib_inline\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport warnings\n\nimport matplotlib.pyplot as plt\n\n# from enrich.console import Console, get_theme\nmatplotlib_inline.backend_inline.set_matplotlib_formats('svg')\nfrom ClimRR.data import DATA_DIR\nfrom ClimRR import get_logger, set_plot_style\nset_plot_style()\nlog = get_logger('ClimRR')\nfrom rich.console import Console as rConsole\nfrom enrich.style import STYLES\nfrom rich.theme import Theme\n\ntheme = Theme(STYLES)\nlog = get_logger('ClimRR')\nconsole = rConsole(theme=theme, log_path=False, markup=True)\n\n\nUsing updated plot style for matplotlib\n\n\n\n\nfrom ClimRR.data import load_shapefile, load_csvs\n\nshape = load_shapefile()\ndata = load_csvs(shape)\n\ndata['FireWeatherIndex_Wildfire'].shape=(62834, 35)\n\n\n\ndata['HeatingDegreeDays'].shape=(62834, 10)\n\n\n\ndata['AnnualTemperatureMinimum'].shape=(62834, 18)\n\n\n\ndata['SeasonalTemperatureMaximum'].shape=(62834, 27)\n\n\n\ndata['ConsecutiveDayswithNoPrecipitation'].shape=(55896, 19)\n\n\n\ndata['SeasonalTemperatureMinimum'].shape=(62834, 27)\n\n\n\ndata['WindSpeed'].shape=(62834, 18)\n\n\n\ndata['AnnualTemperatureMaximum'].shape=(62834, 18)\n\n\n\ndata['Precipitation_inches_AnnualTotal'].shape=(55896, 18)\n\n\n\n\nconsole.print(\"Data: \\n\" + f\"\\n\".join(list(data.keys())))\n\nData: \nFireWeatherIndex_Wildfire\nHeatingDegreeDays\nAnnualTemperatureMinimum\nSeasonalTemperatureMaximum\nConsecutiveDayswithNoPrecipitation\nSeasonalTemperatureMinimum\nWindSpeed\nAnnualTemperatureMaximum\nPrecipitation_inches_AnnualTotal\n\n\n\n\n# counties = gpd.read_file(\n#     'https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/georef-united-states-of-america-county/exports/shp?lang=en&timezone=America%2FChicago'\n# )\nfrom ClimRR.data import load_counties\ncounties = load_counties(crs=shape.crs)\n\n\ncounties.head(n=5)\n\n\n\n\n\n\n\n\nyear\nste_code\nste_name\ncoty_code\ncoty_name\ncoty_area_\ncoty_type\ncoty_name_\ncoty_fp_co\ncoty_gnis_\ngeometry\n\n\n\n\n0\n2022\n['29']\n['Missouri']\n['29081']\n['Harrison']\nUSA\ncounty\n['Harrison County']\n081\n00758495\nPOLYGON ((-10489884.973 4949400.757, -10487772...\n\n\n1\n2022\n['29']\n['Missouri']\n['29099']\n['Jefferson']\nUSA\ncounty\n['Jefferson County']\n099\n00758504\nPOLYGON ((-10089996.419 4590245.129, -10090028...\n\n\n2\n2022\n['29']\n['Missouri']\n['29145']\n['Newton']\nUSA\ncounty\n['Newton County']\n145\n00758527\nPOLYGON ((-10470623.473 4445817.195, -10470640...\n\n\n3\n2022\n['29']\n['Missouri']\n['29223']\n['Wayne']\nUSA\ncounty\n['Wayne County']\n223\n00758564\nPOLYGON ((-10105533.614 4446123.627, -10105492...\n\n\n4\n2022\n['30']\n['Montana']\n['30053']\n['Lincoln']\nUSA\ncounty\n['Lincoln County']\n053\n01720038\nPOLYGON ((-12771356.786 6274948.609, -12771395...\n\n\n\n\n\n\n\n\nillinois = counties[counties['ste_name'] == \"['Illinois']\"]\nconsole.log(f\"illinois.shape={illinois.shape}\")\nillinois.head(n=5)\n\n[19:31:26] illinois.shape=(102, 11)                                                          \n\n\n\n\n\n\n\n\n\n\nyear\nste_code\nste_name\ncoty_code\ncoty_name\ncoty_area_\ncoty_type\ncoty_name_\ncoty_fp_co\ncoty_gnis_\ngeometry\n\n\n\n\n31\n2022\n['17']\n['Illinois']\n['17025']\n['Clay']\nUSA\ncounty\n['Clay County']\n025\n00424214\nPOLYGON ((-9873318.708 4709448.559, -9873005.6...\n\n\n32\n2022\n['17']\n['Illinois']\n['17065']\n['Hamilton']\nUSA\ncounty\n['Hamilton County']\n065\n00424234\nPOLYGON ((-9874775.991 4566267.709, -9874777.2...\n\n\n33\n2022\n['17']\n['Illinois']\n['17077']\n['Jackson']\nUSA\ncounty\n['Jackson County']\n077\n00424240\nPOLYGON ((-9927204.688 4572408.800, -9925575.1...\n\n\n97\n2022\n['17']\n['Illinois']\n['17001']\n['Adams']\nUSA\ncounty\n['Adams County']\n001\n00424202\nPOLYGON ((-10120274.096 4894041.102, -10120277...\n\n\n98\n2022\n['17']\n['Illinois']\n['17067']\n['Hancock']\nUSA\ncounty\n['Hancock County']\n067\n00424235\nPOLYGON ((-10120274.096 4894041.102, -10120442...\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(10, 7))\nax = illinois.boundary.plot(ax=ax, color='#666666', linewidth=0.8)\nax.set_axis_off()\n\n\n\n\n\nillinois_hdd = data[\"HeatingDegreeDays\"].clip(illinois)\nillinois_hdd.head(n=2)\n\n\n\n\n\n\n\n\nOBJECTID\nCrossmodel\nShape_Leng\nShape_Area\ngeometry\nhist\nrcp85_midc\nmid85_hist\nboundary\ncentroid\n\n\n\n\n21130\n21131\nR137C419\n61562.240069\n2.368692e+08\nPOLYGON ((-9925519.402 4437348.204, -9922237.2...\n5618.240234\n5188.899902\n-429.347992\nLINESTRING (-9910499.397 4433932.370, -9913921...\nPOINT (-9919714.441 4428138.497)\n\n\n15883\n15884\nR137C418\n61585.714048\n2.370499e+08\nMULTIPOLYGON (((-9940550.883 4440740.008, -993...\n5668.370117\n5196.740234\n-471.623993\nLINESTRING (-9943924.960 4425714.844, -9940550...\nPOINT (-9934728.187 4431536.593)\n\n\n\n\n\n\n\n\n_, ax = plt.subplots(figsize=(10, 7))\nax = illinois_hdd.boundary.plot(color='#666666', linewidth=0.8, ax=ax, alpha=0.2)\nax = illinois_hdd.plot(column='hist', ax=ax, legend=True)\nax.set_axis_off()\nax.set_title('Historical Heating Degree Days across Illinois')\nplt.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots(ncols=3, figsize=(16, 7), sharey='row')\nax0 = illinois_hdd.plot('hist', ax=ax[0], legend=True)\nax1 = illinois_hdd.plot('rcp85_midc', ax=ax[1], legend=True)\nax2 = illinois_hdd.plot('mid85_hist', ax=ax[2], legend=True)\nax0.set_title(\"HDD: Historical\")\nax1.set_title(\"HDD: Mid-Century RCP8.5\")\nax2.set_title(\"HDD: (Mid-Century - Historical) RCP8.5\")\nax0.set_axis_off()\nax1.set_axis_off()\nax2.set_axis_off()\nplt.tight_layout()\n\n\n\n\n\n_, ax = plt.subplots(figsize=(10, 7))\nax = illinois_hdd.boundary.plot(color='#666666', linewidth=0.8, ax=ax, alpha=0.2)\nax = illinois_hdd.plot(column='rcp85_midc', ax=ax, legend=True)\nax.set_axis_off()\nax.set_title('RCP8.5 Mid-Century Heating Degree Days across Illinois')\nplt.tight_layout()\n\n\n\n\n\n_, ax = plt.subplots(figsize=(10, 7))\nax = illinois_hdd.boundary.plot(color='#666666', linewidth=0.8, ax=ax, alpha=0.2)\nax = illinois_hdd.plot(column='mid85_hist', ax=ax, legend=True)\nax.set_axis_off()\nax.set_title('RCP8.5 End-Century Heating Degree Days across Illinois')\nplt.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(10, 7))\nwind_il = data['WindSpeed'].clip(\n    illinois,\n    # how='intersection'\n)\n# ax = wind_il.boundary.plot(ax=ax, color='#666666', linewidth=0.8)\nax = wind_il.plot(column='hist', ax=ax, linewidth=0.8, legend=True)\nax.set_axis_off()\n\n\n\n\n\n_, ax = plt.subplots(figsize=(10, 7))\nax = wind_il.boundary.plot(color='#666666', linewidth=0.8, ax=ax, alpha=0.2)\nax = wind_il.plot(column='hist', ax=ax, legend=True)\nax.set_axis_off()\nax.set_title('Historical Wind Data across Illinois')\nplt.tight_layout()\n\n\n\n\n\n# wind_il.explore(column='hist')\nwind_il.head(n=2)\n\n\n\n\n\n\n\n\nOBJECTID\nCrossmodel\nShape_Leng\nShape_Area\ngeometry\nhist\nrcp45_midc\nrcp45_endc\nrcp85_midc\nrcp85_endc\nmid45_hist\nend45_hist\nmid85_hist\nend85_hist\nmid85_45\nend85_45\nboundary\ncentroid\n\n\n\n\n21130\n21131\nR137C419\n61562.240069\n2.368692e+08\nPOLYGON ((-9925519.402 4437348.204, -9922237.2...\n7.36933\n7.40137\n7.53169\n7.46885\n7.43563\n0.032043\n0.162359\n0.099523\n0.066305\n0.067481\n-0.096054\nLINESTRING (-9910499.397 4433932.370, -9913921...\nPOINT (-9919714.441 4428138.497)\n\n\n15883\n15884\nR137C418\n61585.714048\n2.370499e+08\nMULTIPOLYGON (((-9940550.883 4440740.008, -993...\n7.76390\n7.78540\n7.90540\n7.86042\n7.82429\n0.021496\n0.141499\n0.096518\n0.060394\n0.075023\n-0.081105\nLINESTRING (-9943924.960 4425714.844, -9940550...\nPOINT (-9934728.187 4431536.593)\n\n\n\n\n\n\n\n\n_, ax = plt.subplots()\nax = wind_il.plot(column='hist', ax=ax, legend=True)\n_ = ax.set_title('WindSpeed, historical')\nax.set_axis_off()\n\n\n\n\n\nfig, ax = plt.subplots()\nax = wind_il.plot(column='rcp45_midc', ax=ax, legend=True)\nax.set_axis_off()\n_ = ax.set_title('WindSpeed, Mid-Century [RCP45]')\n\n\n\n\n\nfig, ax = plt.subplots()\n_ = ax.set_title('WindSpeed, End-Century [RCP45]')\n# _ = ax.legend(loc='best')\nax = wind_il.plot(column='rcp45_endc', ax=ax, legend=True)\nax.set_axis_off()\n\n\n\n\n\nfig, ax = plt.subplots(ncols=3, figsize=(16, 7))\nax0 = wind_il.plot('hist', ax=ax[0], legend=True)\nax1 = wind_il.plot('rcp45_midc', ax=ax[1], legend=True)\nax2 = wind_il.plot('rcp45_endc', ax=ax[2], legend=True)\nax0.set_title(\"Wind Speed: Historical\")\nax1.set_title(\"Wind Speed: Mid-Century RCP4.5\")\nax2.set_title(\"Wind Speed: End-Century RCP4.5\")\nax0.set_axis_off()\nax1.set_axis_off()\nax2.set_axis_off()\nplt.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots(ncols=3, figsize=(16, 7))\nax0 = wind_il.plot('hist', ax=ax[0], legend=True)\nax1 = wind_il.plot('rcp85_midc', ax=ax[1], legend=True)\nax2 = wind_il.plot('rcp85_endc', ax=ax[2], legend=True)\nax0.set_title(\"Wind Speed: Historical\")\nax1.set_title(\"Wind Speed: Mid-Century RCP8.5\")\nax2.set_title(\"Wind Speed: End-Century RCP8.5\")\nax0.set_axis_off()\nax1.set_axis_off()\nax2.set_axis_off()\nplt.tight_layout()\n\n\n\n\n\ndata['WindSpeed'].shape\n\n(62834, 18)\n\n\n\nselection = shape[0:5]\n\nfor index, row in selection.iterrows():\n    # get the area of the polygon\n    poly_area = row['geometry'].area\n    console.print(f\"Polygon area at {index} is {poly_area:.3f}\")\n\nPolygon area at 0 is 252927293.657\n\n\n\nPolygon area at 1 is 235501313.715\n\n\n\nPolygon area at 2 is 233416379.950\n\n\n\nPolygon area at 3 is 261761834.191\n\n\n\nPolygon area at 4 is 226073092.218\n\n\n\n\n\n\nCitationBibTeX citation:@misc{foreman2023,\n  author = {Foreman, Sam},\n  date = {2023-08-01},\n  url = {https://saforem2.github.io/climate-analysis},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nForeman, Sam. 2023. Intro to HPC: Climate Analysis with ClimRR.\nhttps://saforem2.github.io/climate-analysis."
  },
  {
    "objectID": "qmd/GettingStarted/setup.html#setup",
    "href": "qmd/GettingStarted/setup.html#setup",
    "title": "Getting Started",
    "section": "Setup",
    "text": "Setup\nTo get started, we will need to:\n\nCreate a symlink from the project directory, /global/cfs/cdirs/m4388/Project2-ClimRR/ into your $HOME directory\nln -s /global/cfs/cdirs/m4388/Project2-ClimRR/ $HOME/Project2-ClimRR\nNavigate into here and create your personal directory (where you will store and work on your project):\ncd $HOME/Project2-ClimRR/\nmkdir $USER\ncd $USER\nClone the  GitHub repo\ngit clone https://github.com/saforem2/climate-analysis"
  },
  {
    "objectID": "qmd/GettingStarted/intro.html#types-of-data",
    "href": "qmd/GettingStarted/intro.html#types-of-data",
    "title": "Climate Analysis with ClimRR",
    "section": "Types of Data",
    "text": "Types of Data\n\n\n\nFigure 1: (Image credit: National Ecological Observatory Network (NEON))\n\n\nOne of the most common file formats for vector data is the ESRI shapefile, which is what we will be working with in be working with in this project.\n\nMetadata\nMetadata is “data about the data”4 and is (by design) meant to give additional information or provide context about a dataset.\nExamples might include:\n\nWhen was this data created?\n\nBy who? For what? Where at? When? Why??\n\nHow is this data licensed?\nIs there a reference for this data? (DOI ? URL ? etc.)\nWhat variables or fields are contained in this data?\n\nWhat do they represent? Are there units?\n\nIf the data is geospatial, what geographical or temporal area is included?\nAdditional (often contextual) information about the data\n\ne.g. “this data was created to inform a population about upcoming weather events” or similar\n\n\nMetadata is often expected to be of a certain form, or to follow specific conventions / guidelines.\nThis is important to keep in mind and will allow others to understand your data without needing an explanation (e.g. “what does this abbreviation mean?”, “how is this variable defined?”, etc.)\nSome common metadata conventions for GIS data include:\n\nClimate and Forecast (CF) Conventions\nAttribute Convention for Data Discovery\n\nSchema.org is another useful reference and provides a general framework for dealing with metadata."
  },
  {
    "objectID": "qmd/GettingStarted/intro.html#fair-data",
    "href": "qmd/GettingStarted/intro.html#fair-data",
    "title": "Climate Analysis with ClimRR",
    "section": "FAIR Data",
    "text": "FAIR Data\nFAIR stands for “Findable, Accessible, Interoperable, Reusable”, and provides a set of guidelines for data sharing.\nIn the age of “big data”, its important that we use (and promote!) tools that facilitate the effective sharing of data.\nIdeally, our data would be completely self-contained and provide, via metadata, all of the information required to understand and work with it."
  },
  {
    "objectID": "qmd/GettingStarted/python.html",
    "href": "qmd/GettingStarted/python.html",
    "title": "Overview of Python",
    "section": "",
    "text": "Reference\n\n\n\n\n\nMaterial below modified from1: Python Fundamentals"
  },
  {
    "objectID": "qmd/GettingStarted/python.html#footnotes",
    "href": "qmd/GettingStarted/python.html#footnotes",
    "title": "Overview of Python",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWhich itself is modified from the official python tutorial↩︎"
  },
  {
    "objectID": "qmd/GettingStarted/python.html#invoking-python",
    "href": "qmd/GettingStarted/python.html#invoking-python",
    "title": "Overview of Python",
    "section": "Invoking Python",
    "text": "Invoking Python\nThere are three main ways to use Python:\n\nRunning / executing a Python file, e.g. python filename.py\n\nthis will launch python, execute (line by line) the contents of filename.py, and return\n\nInteractively, either through:\n\na console (e.g. the Python interpreter python or an IPython shell ipython)\na notebook (e.g. Jupyter notebook)*\n\n\n*we will (mostly) focus on using Jupyter notebooks for this project."
  },
  {
    "objectID": "qmd/extras/illinois.html",
    "href": "qmd/extras/illinois.html",
    "title": "Continued Analysis",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport geopandas as gpd\n\nfrom typing import Optional\nfrom enrich.style import STYLES\nfrom rich.theme import Theme\nfrom rich.console import Console\n\nfrom ClimRR import (\n    set_plot_style,\n    get_logger,\n    DEFAULT_CRS,\n)\nfrom ClimRR.data import (\n    load_shapefile,\n    load_csvs,\n    load_counties,\n    load_chicago_data\n)\n\nset_plot_style()\ntheme = Theme(STYLES)\nlog = get_logger('ClimRR')\nconsole = Console(theme=theme, log_path=False, markup=True)\n\nUsing updated plot style for matplotlib\n\n\n\n\nshape = load_shapefile()\ndata = load_csvs(shape)\nchidata = load_chicago_data(shape.crs)\n\ndata['FireWeatherIndex_Wildfire'].shape=(62834, 35)\n\n\n\ndata['HeatingDegreeDays'].shape=(62834, 10)\n\n\n\ndata['AnnualTemperatureMinimum'].shape=(62834, 18)\n\n\n\ndata['SeasonalTemperatureMaximum'].shape=(62834, 27)\n\n\n\ndata['ConsecutiveDayswithNoPrecipitation'].shape=(55896, 19)\n\n\n\ndata['SeasonalTemperatureMinimum'].shape=(62834, 27)\n\n\n\ndata['WindSpeed'].shape=(62834, 18)\n\n\n\ndata['AnnualTemperatureMaximum'].shape=(62834, 18)\n\n\n\ndata['Precipitation_inches_AnnualTotal'].shape=(55896, 18)\n\n\n\n\ncounties = load_counties(shape.crs)\n\n\nillinois = counties[counties[\"ste_name\"] == \"['Illinois']\"]\nwind_il = data[\"WindSpeed\"].overlay(illinois, how='intersection')\n\n\nfig, ax = plt.subplots(figsize=(10, 7))\nwind_il.plot(ax=ax, column='hist', legend=True)\nax.set_axis_off()\nplt.show()\n\n\n\n\n\nconsole.log(\"\\n\".join(list(data.keys())))\n\n[14:02:17] FireWeatherIndex_Wildfire                                                         \n           HeatingDegreeDays                                                                 \n           AnnualTemperatureMinimum                                                          \n           SeasonalTemperatureMaximum                                                        \n           ConsecutiveDayswithNoPrecipitation                                                \n           SeasonalTemperatureMinimum                                                        \n           WindSpeed                                                                         \n           AnnualTemperatureMaximum                                                          \n           Precipitation_inches_AnnualTotal                                                  \n\n\n\n\ndef get_state(\n        state: str,\n        counties: Optional[gpd.GeoDataFrame] = None,\n) -&gt; gpd.GeoDataFrame:\n    counties = load_counties(DEFAULT_CRS) if counties is None else counties\n    assert counties is not None and isinstance(counties, gpd.GeoDataFrame)\n    assert counties.crs == DEFAULT_CRS\n    return counties[counties[\"ste_name\"] == f\"['{state}']\"]\n\n\ndef get_variable_for_state(\n        data: gpd.GeoDataFrame,\n        state: gpd.GeoDataFrame,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Returns `data.overlay(state, how='intersection')`\"\"\"\n    return data.overlay(state, how='intersection')\n\n\ncalifornia = get_state('California', counties=counties)\n\n\nfig, ax = plt.subplots(figsize=(10, 7))\nax = california.plot(ax=ax)\nax.set_axis_off()\n\n\n\n\n\ncali_temp_max = get_variable_for_state(\n    data[\"SeasonalTemperatureMaximum\"],\n    california\n)\n\n\nfig, ax = plt.subplots(figsize=(16, 7), nrows=2, ncols=3, sharey='row', sharex='col')\nax = ax.flatten()\nax0 = cali_temp_max.plot(ax=ax[0], column='hist_winter', legend=True)\nax0.set_title('Winter [Historical]')\nax0.set_axis_off()\nax1 = cali_temp_max.plot(ax=ax[1], column='rcp85_midc_winter', legend=True)\nax1.set_axis_off()\nax1.set_title('Winter [RCP85: Mid-Century]')\nax2 = cali_temp_max.plot(ax=ax[2], column='rcp85_endc_winter', legend=True)\nax2.set_axis_off()\nax2.set_title('Winter [RCP85: End-Century]')\n\nax3 = cali_temp_max.plot(ax=ax[3], column='hist_summer', legend=True)\nax3.set_title('Summer [Historical]')\nax3.set_axis_off()\nax4 = cali_temp_max.plot(ax=ax[4], column='rcp85_mid_summer', legend=True)\nax4.set_axis_off()\nax4.set_title('Summer [RCP85: Mid-Century]')\nax5 = cali_temp_max.plot(ax=ax[5], column='rcp85_end_summer', legend=True)\nax5.set_axis_off()\nax5.set_title('Summer [RCP85: End-Century]')\nplt.tight_layout()\n\n\n\n\n\n\n\nCitationBibTeX citation:@misc{foreman2023,\n  author = {Foreman, Sam},\n  date = {2023-08-01},\n  url = {https://saforem2.github.io/climate-analysis},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nForeman, Sam. 2023. Intro to HPC: Climate Analysis with ClimRR.\nhttps://saforem2.github.io/climate-analysis."
  },
  {
    "objectID": "qmd/extras/iris.html",
    "href": "qmd/extras/iris.html",
    "title": "Mapping and Plotting Tools with GeoPandas",
    "section": "",
    "text": "import geodatasets\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n\nchicago = gpd.read_file(geodatasets.get_path('geoda.chicago_commpop'))\ngroceries = gpd.read_file(geodatasets.get_path('geoda.groceries'))\nchicago.head()\n\n\n\n\n\n\n\n\ncommunity\nNID\nPOP2010\nPOP2000\nPOPCH\nPOPPERCH\npopplus\npopneg\ngeometry\n\n\n\n\n0\nDOUGLAS\n35\n18238\n26470\n-8232\n-31.099358\n0\n1\nMULTIPOLYGON (((-87.60914 41.84469, -87.60915 ...\n\n\n1\nOAKLAND\n36\n5918\n6110\n-192\n-3.142390\n0\n1\nMULTIPOLYGON (((-87.59215 41.81693, -87.59231 ...\n\n\n2\nFULLER PARK\n37\n2876\n3420\n-544\n-15.906433\n0\n1\nMULTIPOLYGON (((-87.62880 41.80189, -87.62879 ...\n\n\n3\nGRAND BOULEVARD\n38\n21929\n28006\n-6077\n-21.698922\n0\n1\nMULTIPOLYGON (((-87.60671 41.81681, -87.60670 ...\n\n\n4\nKENWOOD\n39\n17841\n18363\n-522\n-2.842673\n0\n1\nMULTIPOLYGON (((-87.59215 41.81693, -87.59215 ...\nax = chicago.plot()\nax.set_axis_off()\n\nax = chicago.plot(\n    column='POP2010',\n    legend=True,\n    legend_kwds={\n        'label': 'Population in 2010',\n        'orientation': 'vertical',\n    }\n)\nplt.tight_layout()\nax.set_axis_off()\nax = chicago.boundary.plot()\nax.set_axis_off()\nax = groceries.plot(marker='.', color='red', markersize=5)\ngroceries = groceries.to_crs(chicago.crs)\nimport geopandas\nimport geodatasets\n\nnybb = geopandas.read_file(geodatasets.get_path(\"nybb\"))\nchicago = geopandas.read_file(geodatasets.get_path(\"geoda.chicago_commpop\"))\ngroceries = geopandas.read_file(\n    geodatasets.get_path(\"geoda.groceries\")\n).explode(ignore_index=True)"
  },
  {
    "objectID": "qmd/extras/iris.html#climate-plots-using-iris",
    "href": "qmd/extras/iris.html#climate-plots-using-iris",
    "title": "Mapping and Plotting Tools with GeoPandas",
    "section": "Climate Plots using Iris",
    "text": "Climate Plots using Iris\nIris: A powerful, format-agnostic, community-drive Python package for analysing and visualizing Earth science data.\n\n\n\n\n\n\nNote\n\n\n\nThe plots below are just for testing functionality, WIP to replace with ClimRR data\n\n\n\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport warnings\n\nimport cartopy.crs as ccrs\nimport matplotlib.pyplot as plt\n\nimport iris\nimport iris.plot as iplt\nimport iris.quickplot as qplt\n\nwarnings.filterwarnings('ignore')\n# testing comment\n%matplotlib inline\nimport matplotlib_inline\nmatplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n\nfrom pathlib import Path\n\nfrom ClimRR import DATA_DIR\nplt.rcParams.update({\n    'axes.facecolor': 'none',\n    'figure.facecolor': 'none',\n    'savefig.facecolor': 'none',\n    'savefig.format': 'svg',\n    'axes.edgecolor': 'none',\n    'axes.grid': True,\n    'axes.labelcolor': '#666',\n    'axes.titlecolor': '#666',\n    'grid.color': '#666',\n    'text.color': '#666',\n    'grid.linestyle': '--',\n    'grid.linewidth': 0.5,\n    'grid.alpha': 0.4,\n    'xtick.color': 'none',\n    'ytick.color': 'none',\n    'xtick.labelcolor': '#666',\n    'legend.edgecolor': 'none',\n    'ytick.labelcolor': '#666',\n    'savefig.transparent': True,\n    'figure.figsize': (12.4, 4.8),\n})\n\n\nshape = gpd.read_file(\n    DATA_DIR.joinpath(\n        \"GridCellsShapefile/GridCells.shp\"\n    )\n)\nprint(f\"shape: {shape}\")\n\nshape:        OBJECTID Crossmodel    Shape_Leng    Shape_Area  \\\n0             1   R161C438  63614.764866  2.529273e+08   \n1             2   R125C222  61384.219597  2.355013e+08   \n2             3   R121C235  61111.892875  2.334164e+08   \n3             4   R169C431  64716.234995  2.617618e+08   \n4             5   R146C497  60142.919468  2.260731e+08   \n...         ...        ...           ...           ...   \n62829     62830   R055C359  54822.101620  1.878414e+08   \n62830     62831   R072C387  55964.448729  1.957512e+08   \n62831     62832   R085C337  57646.273207  2.076932e+08   \n62832     62833   R082C288  57528.265213  2.068438e+08   \n62833     62834   R088C416  56916.790562  2.024700e+08   \n\n                                                geometry  \n0      POLYGON ((-9530601.177 4726046.614, -9534793.8...  \n1      POLYGON ((-12959076.287 4395610.472, -12974301...  \n2      POLYGON ((-12754805.395 4355815.951, -12770000...  \n3      POLYGON ((-9605729.481 4879238.815, -9609863.1...  \n4      POLYGON ((-8733007.764 4224658.634, -8738250.3...  \n...                                                  ...  \n62829  POLYGON ((-10965528.715 3400674.224, -10966978...  \n62830  POLYGON ((-10550370.700 3584259.218, -10552496...  \n62831  POLYGON ((-11249641.912 3850046.022, -11235259...  \n62832  POLYGON ((-11942487.554 3816894.598, -11956857...  \n62833  POLYGON ((-10110300.079 3720413.967, -10124231...  \n\n[62834 rows x 5 columns]\n\n\n\nshape.plot()\n\n&lt;Axes: &gt;\n\n\n\n\n\n\nimport cartopy.crs as ccrs\nimport matplotlib.pyplot as plt\n\nimport iris\nimport iris.analysis.cartography\nimport iris.plot as iplt\nimport iris.quickplot as qplt\n\n# Load some test data.\nfname = iris.sample_data_path(\"rotated_pole.nc\")\nair_pressure = iris.load_cube(fname)\n\n# Plot #1: Point plot showing data values & a colorbar\n# plt.figure()\nfig, ax = plt.subplots()\npoints = qplt.points(air_pressure, c=air_pressure.data)\ncb = plt.colorbar(points, orientation=\"horizontal\")\ncb.set_label(air_pressure.units)\nplt.gca().coastlines()\n\n# Plot #2: Contourf of the point based data\nplt.figure()\nqplt.contourf(air_pressure, 15)\nplt.gca().coastlines()\n# iplt.show()\n\n# Plot #3: Contourf overlaid by coloured point data\nplt.figure()\nqplt.contourf(air_pressure)\niplt.points(air_pressure, c=air_pressure.data)\nplt.gca().coastlines()\n\n# For the purposes of this example, add some bounds to the latitude\n# and longitude\nair_pressure.coord(\"grid_latitude\").guess_bounds()\nair_pressure.coord(\"grid_longitude\").guess_bounds()\n\n# Plot #4: Block plot\nplt.figure()\n# fig, ax = plt.subplots()\nplt.axes(projection=ccrs.PlateCarree())\niplt.pcolormesh(air_pressure)\nplt.gca().stock_img()\nplt.gca().coastlines()\n\n&lt;cartopy.mpl.feature_artist.FeatureArtist at 0x2b88c7790&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfname = iris.sample_data_path(\"air_temp.pp\")\ntemperature = iris.load_cube(fname)\n\nfig, ax = plt.subplots()\n\n# Plot #1: contourf with axes longitude from -180 to 180\n#plt.figure(figsize=(8, 5))\nplt.subplot(121)\nqplt.contourf(temperature, 15)\nfig.gca().coastlines()\n\n# Plot #2: contourf with axes longitude from 0 to 360\nproj = ccrs.PlateCarree(central_longitude=-180.0)\nplt.subplot(122, projection=proj)\nqplt.contourf(temperature, 15)\nfig.gca().coastlines()\n\n&lt;cartopy.mpl.feature_artist.FeatureArtist at 0x2b8cf3750&gt;\n\n\n\n\n\n\nfname = iris.sample_data_path(\"air_temp.pp\")\n\nfig, ax = plt.subplots()\n# Load exactly one cube from the given file.\ntemperature = iris.load_cube(fname)\n# We only want a small number of latitudes, so filter some out\n# using \"extract\".\ntemperature = temperature.extract(\n    iris.Constraint(latitude=lambda cell: 68 &lt;= cell &lt; 78)\n)\n\nfor cube in temperature.slices(\"longitude\"):\n    # Create a string label to identify this cube (i.e. latitude: value).\n    cube_label = \"latitude: %s\" % cube.coord(\"latitude\").points[0]\n\n    # Plot the cube, and associate it with a label.\n    qplt.plot(cube, label=cube_label)\n\n# Add the legend with 2 columns.\nax.legend(ncol=2)\n# Put a grid on the plot.\nax.grid(True)\n# Tell matplotlib not to extend the plot axes range to nicely\n# rounded numbers.\nplt.axis(\"tight\")\n\n(-17.81249542236328, 374.0624038696289, 253.4506408691406, 277.34959106445314)"
  },
  {
    "objectID": "qmd/extras/iris.html#test-data-showing-inset-plots",
    "href": "qmd/extras/iris.html#test-data-showing-inset-plots",
    "title": "Mapping and Plotting Tools with GeoPandas",
    "section": "Test Data Showing Inset Plots",
    "text": "Test Data Showing Inset Plots\nThis example demonstrates the use of a single 3D data cube with time, latitude and longitude dimensions to plot a temperature series for a single latitude coordinate, with an inset plot of the data region.\n\nimport numpy as np\ncube1 = iris.load_cube(iris.sample_data_path(\"ostia_monthly.nc\"))\n# Slice into cube to retrieve data for the inset map showing the\n# data region\nregion = cube1[-1, :, :]\n# Average over latitude to reduce cube to 1 dimension\nplot_line = region.collapsed(\"latitude\", iris.analysis.MEAN)\n\n# Open a window for plotting\nfig = plt.figure()\n# Add a single subplot (axes). Could also use \"ax_main = plt.subplot()\"\nax_main = fig.add_subplot(1, 1, 1)\n# Produce a quick plot of the 1D cube\nqplt.plot(plot_line)\n\n# Set x limits to match the data\nax_main.set_xlim(0, plot_line.coord(\"longitude\").points.max())\n# Adjust the y limits so that the inset map won't clash with main plot\nax_main.set_ylim(294, 310)\nax_main.set_title(\"Meridional Mean Temperature\")\n# Add grid lines\nax_main.grid()\n\n# Add a second set of axes specifying the fractional coordinates within\n# the figure with bottom left corner at x=0.55, y=0.58 with width\n# 0.3 and height 0.25.\n# Also specify the projection\nax_sub = fig.add_axes(\n  [0.55, 0.58, 0.3, 0.25],\n  projection=ccrs.Mollweide(central_longitude=180),\n)\n\n# Use iris.plot (iplt) here so colour bar properties can be specified\n# Also use a sequential colour scheme to reduce confusion for those with\n# colour-blindness\niplt.pcolormesh(region, cmap=\"Blues\")\n# Manually set the orientation and tick marks on your colour bar\nticklist = np.linspace(np.min(region.data), np.max(region.data), 4)\nplt.colorbar(orientation=\"horizontal\", ticks=ticklist)\nax_sub.set_title(\"Data Region\")\n# Add coastlines\nax_sub.coastlines()\n# request to show entire map, using the colour mesh on the data region only\nax_sub.set_global()\n\n\n\n\n\nimport iris\n\nimport numpy as np\nimport iris.plot as iplt\nimport iris.quickplot as qplt\n\nfrom iris.analysis import MEAN\n\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\n\n# Loads air_temp.pp and \"collapses\" longitude into a single, average value.\nfname = iris.sample_data_path(\"air_temp.pp\")\ntemperature = iris.load_cube(fname)\ncollapsed_temp = temperature.collapsed(\"longitude\", MEAN)\n\n\n# Set y-axes with -90 and 90 limits and steps of 15 per tick.\nstart, stop, step = -90, 90, 15\nyticks = np.arange(start, stop + step, step)\nylim = [start, stop]\n\n# Plot \"temperature\" on a cartographic plot and set the ticks and titles\n# on the axes.\nfig = plt.figure(figsize=[12, 8])\n#fig, ax = plt.subplots()\n\nax1 = fig.add_subplot(111, projection=ccrs.PlateCarree())\nim = iplt.contourf(temperature, cmap=\"RdYlBu_r\")\nax1.coastlines()\nax1.gridlines()\nax1.set_xticks([-180, -90, 0, 90, 180])\nax1.set_yticks(yticks)\nax1.set_title(\"Air Temperature\")\nax1.set_ylabel(f\"Latitude / {temperature.coord('latitude').units}\")\nax1.set_xlabel(f\"Longitude / {temperature.coord('longitude').units}\")\nax1.set_ylim(*ylim)\n\n# Create a Matplotlib AxesDivider object to allow alignment of other\n# Axes objects.\ndivider = make_axes_locatable(ax1)\n\n# Gives the air temperature bar size, colour and a title.\nax2 = divider.new_vertical(\n    size=\"5%\", pad=0.5, axes_class=plt.Axes, pack_start=True\n)  # creates 2nd axis\nfig.add_axes(ax2)\ncbar = plt.colorbar(\n    im, cax=ax2, orientation=\"horizontal\"\n)  # puts colour bar on second axis\ncbar.ax.set_xlabel(f\"{temperature.units}\")  # labels colour bar\n\n# Plot \"collapsed_temp\" on the mean graph and set the ticks and titles\n# on the axes.\nax3 = divider.new_horizontal(\n    size=\"30%\", pad=0.4, axes_class=plt.Axes\n)  # create 3rd axis\nfig.add_axes(ax3)\nqplt.plot(\n    collapsed_temp, collapsed_temp.coord(\"latitude\")\n)  # plots temperature collapsed over longitude against latitude\nax3.axhline(0, color=\"k\", linewidth=0.5)\n\n# Creates zonal mean details\nax3.set_title(\"Zonal Mean\")\nax3.yaxis.set_label_position(\"right\")\nax3.yaxis.tick_right()\nax3.set_yticks(yticks)\nax3.grid()\n\n# Round each tick for the third ax to the nearest 20 (ready for use).\ndata_max = collapsed_temp.data.max()\nx_max = data_max - data_max % -20\ndata_min = collapsed_temp.data.min()\nx_min = data_min - data_min % 20\nax3.set_xlim(x_min, x_max)\nax3.set_ylim(*ylim)\nplt.tight_layout()\n\n\n\n\n\nfname = iris.sample_data_path(\"air_temp.pp\")\n\n# Load exactly one cube from the given file.\ntemperature = iris.load_cube(fname)\n\n# We only want a small number of latitudes, so filter some out\n# using \"extract\".\ntemperature = temperature.extract(\n    iris.Constraint(latitude=lambda cell: 68 &lt;= cell &lt; 78)\n)\n\nfig, ax = plt.subplots()\n\nfor cube in temperature.slices(\"longitude\"):\n    # Create a string label to identify this cube (i.e. latitude: value).\n    cube_label = \"latitude: %s\" % cube.coord(\"latitude\").points[0]\n\n    # Plot the cube, and associate it with a label.\n    qplt.plot(cube, label=cube_label)\n\n# Add the legend with 2 columns.\nax.legend(ncol=2)\n\n# Put a grid on the plot.\nax.grid(True)\n\n# Tell matplotlib not to extend the plot axes range to nicely\n# rounded numbers.\nplt.axis(\"tight\")\n\n(-17.81249542236328, 374.0624038696289, 253.4506408691406, 277.34959106445314)\n\n\n\n\n\n\nimport iris.coord_categorisation\nimport matplotlib.colors as mcols\n\n\nfig, ax = plt.subplots()\n# Load a sample air temperatures sequence.\nfile_path = iris.sample_data_path(\"E1_north_america.nc\")\ntemperatures = iris.load_cube(file_path)\n\n# Create a year-number coordinate from the time information.\niris.coord_categorisation.add_year(temperatures, \"time\")\n\n# Create a sample anomaly field for one chosen year, by extracting that\n# year and subtracting the time mean.\nsample_year = 1982\nyear_temperature = temperatures.extract(iris.Constraint(year=sample_year))\ntime_mean = temperatures.collapsed(\"time\", iris.analysis.MEAN)\nanomaly = year_temperature - time_mean\n\n# Construct a plot title string explaining which years are involved.\nyears = temperatures.coord(\"year\").points\nplot_title = \"Temperature anomaly\"\nplot_title += \"\\n{} differences from {}-{} average.\".format(\n    sample_year, years[0], years[-1]\n)\n\n# Define scaling levels for the logarithmic colouring.\nminimum_log_level = 0.1\nmaximum_scale_level = 3.0\n\n# Use a standard colour map which varies blue-white-red.\n# For suitable options, see the 'Diverging colormaps' section in:\n# http://matplotlib.org/stable/gallery/color/colormap_reference.html\nanom_cmap = \"bwr\"\n\n# Create a 'logarithmic' data normalization.\nanom_norm = mcols.SymLogNorm(\n    linthresh=minimum_log_level,\n    linscale=0.01,\n    vmin=-maximum_scale_level,\n    vmax=maximum_scale_level,\n)\n# Setting \"linthresh=minimum_log_level\" makes its non-logarithmic\n# data range equal to our 'zero band'.\n# Setting \"linscale=0.01\" maps the whole zero band to the middle colour value\n# (i.e., 0.5), which is the neutral point of a \"diverging\" style colormap.\n\n# Create an Axes, specifying the map projection.\nplt.axes(projection=ccrs.LambertConformal())\n\n# Make a pseudocolour plot using this colour scheme.\nmesh = iplt.pcolormesh(anomaly, cmap=anom_cmap, norm=anom_norm)\n\n# Add a colourbar, with extensions to show handling of out-of-range values.\nbar = plt.colorbar(mesh, orientation=\"horizontal\", extend=\"both\")\n\n# Set some suitable fixed \"logarithmic\" colourbar tick positions.\ntick_levels = [-3, -1, -0.3, 0.0, 0.3, 1, 3]\nbar.set_ticks(tick_levels)\n\n# Modify the tick labels so that the centre one shows \"+/-&lt;minumum-level&gt;\".\ntick_levels[3] = r\"$\\pm${:g}\".format(minimum_log_level)\nbar.set_ticklabels(tick_levels)\n\n# Label the colourbar to show the units.\nbar.set_label(\"[{}, log scale]\".format(anomaly.units))\n\n# Add coastlines and a title.\nplt.gca().coastlines()\nplt.title(plot_title)\n\nText(0.5, 1.0, 'Temperature anomaly\\n1982 differences from 1860-2099 average.')"
  },
  {
    "objectID": "qmd/01-ClimRR/3-analysis.html",
    "href": "qmd/01-ClimRR/3-analysis.html",
    "title": "Intro to HPC Bootcamp",
    "section": "",
    "text": "CitationBibTeX citation:@misc{foreman2023,\n  author = {Foreman, Sam},\n  date = {2023-08-02},\n  url = {https://saforem2.github.io/climate-analysis},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nForeman, Sam. 2023. Intro to HPC: Climate Analysis with ClimRR.\nhttps://saforem2.github.io/climate-analysis."
  },
  {
    "objectID": "qmd/01-ClimRR/1-definitions.html",
    "href": "qmd/01-ClimRR/1-definitions.html",
    "title": "Climate Variables",
    "section": "",
    "text": "Each climate model generates temperature readings every 3 hours, or 8 temperature readings per day.\nThe maximum daily temperature refers to the highest of these 8 readings, which often occurs in the middle of the daytime and is comparable to the ‘high temperature’ in a daily weather forecast.\nSimilarly, the minimum daily temperature refers to the lowest of these 8 readings, which often occurs overnight and is comparable to the ‘low temperature’ in a daily weather forecast.\nArgonne calculated the annual average of both the maximum and minimum daily temperatures.\nThese daily high / low readings were then used to calculate the annual average maximum or minimum daily temperature for that scenario’s model year (e.g. the average max daily temperature for 2045 using the CCSM model under RCP4.5).\nThis process was repeated for each year within a given time period / scenario (e.g. 2046, 2047, and so forth) across all three climate models (CCSM, GFDL, and HadGEM).\nFinally, the 30 individual annual averages for a given time period/scenario were themselves averaged, producing a multi-model ensemble mean that represents the annual average of the maximum or minimum daily temperature for a given time period / scenario."
  },
  {
    "objectID": "qmd/01-ClimRR/1-definitions.html#temperature-annual",
    "href": "qmd/01-ClimRR/1-definitions.html#temperature-annual",
    "title": "Climate Variables",
    "section": "",
    "text": "Each climate model generates temperature readings every 3 hours, or 8 temperature readings per day.\nThe maximum daily temperature refers to the highest of these 8 readings, which often occurs in the middle of the daytime and is comparable to the ‘high temperature’ in a daily weather forecast.\nSimilarly, the minimum daily temperature refers to the lowest of these 8 readings, which often occurs overnight and is comparable to the ‘low temperature’ in a daily weather forecast.\nArgonne calculated the annual average of both the maximum and minimum daily temperatures.\nThese daily high / low readings were then used to calculate the annual average maximum or minimum daily temperature for that scenario’s model year (e.g. the average max daily temperature for 2045 using the CCSM model under RCP4.5).\nThis process was repeated for each year within a given time period / scenario (e.g. 2046, 2047, and so forth) across all three climate models (CCSM, GFDL, and HadGEM).\nFinally, the 30 individual annual averages for a given time period/scenario were themselves averaged, producing a multi-model ensemble mean that represents the annual average of the maximum or minimum daily temperature for a given time period / scenario."
  },
  {
    "objectID": "qmd/01-ClimRR/1-definitions.html#temperature-seasonal",
    "href": "qmd/01-ClimRR/1-definitions.html#temperature-seasonal",
    "title": "Climate Variables",
    "section": "Temperature (Seasonal)",
    "text": "Temperature (Seasonal)\nEach climate model generates temperature readings every 3 hours, or 8 temperature readings per day.\nThe maximum daily temperature refers to the highest of these 8 readings, which often occurs in the middle of the daytime and is comparable to the ‘high temperature’ in a daily weather forecast.\nSimilarly, the minimum daily temperature refers to the lowest of these 8 readings, which often occurs overnight and is comparable to the ‘low temperature’ in a daily weather forecast.\nArgonne calculated the seasonal average of both the maximum and minimum daily temperatures; the seasons are segmented as\n\nWinter (Dec, Jan, Feb)\nSpring (March, April, May)\nSummer (June, July, Aug)\nAutumn (Sep, Oct, Nov)\n\nThese calculations involved extracting the highest temperature reading and lowest temperature reading for each individual day of a year (e.g. 2045) within a given time period / scenario (e.g. mid-century RCP4.5) and for a given climate model (e.g. CCSM).\nThese daily high / low readings were then classified by season and used to calculate the seasonal average maximum or minimum daily temperature for that scenario’s model year (e.g. the average daily max temperature for summer of 2045 using the CCSM model under RCP4.5).\nThis process was repeated for each year within a given time period / scenario (e.g. 2046, 2047, and so forth) across all three climate models (CCSM, GFDL, and HadGEM).\nFinally, the 30 individual seasonal averages for a given time period / scenario were themselves averaged, producing a multi-modal ensemble mean that represents the seasonal average of the maximum or minimum daily temperature for a given time period / scenario."
  },
  {
    "objectID": "qmd/01-ClimRR/1-definitions.html#precipitation",
    "href": "qmd/01-ClimRR/1-definitions.html#precipitation",
    "title": "Climate Variables",
    "section": "Precipitation",
    "text": "Precipitation\nEach climate model estimates an amount of precipitation (whether rain, snow, sleet, or ice) that occurs every 3 hours across the entire modeled time period (i.e. every 3 hours, of every day, for all modeled years).\nThese 3-hour precipitation estimates can be used to calculate the total precipitation over a designated period of time, ranging from daily to annually.\nArgonne calculated total annual precipitation by adding all 3-hour precipitation estimates for a given year (e.g. 2045) within a given time period / scenario (e.g. mid-century RCP4.5) and for a given climate model (e.g. CCSM), which produced the total annual precipitation for that scenario’s model year, such as CCSM’s estimate of annual precipitation in 2045 under climate scenario RCP4.5.\nThis process was repeated for each year within a given time period / scenario (e.g. 2046, 2047, and so forth) and across all three climate models (CCSM, GFDL, and HadGEM), producing a total of 30 estimates of total annual precipitation for a given time period / scenario.\nThe average of these values was taken to produce the ensemble mean of the total annual precipitation (in inches) for each time period / scenario."
  },
  {
    "objectID": "qmd/01-ClimRR/1-definitions.html#wind-speed",
    "href": "qmd/01-ClimRR/1-definitions.html#wind-speed",
    "title": "Climate Variables",
    "section": "Wind Speed",
    "text": "Wind Speed\nEach climate model generates estimated wind speed readings (in miles per hour, or mph) every 3 hours, or 8 wind speed readings per day.\nThese values are irrespective of wind direction and only represent the magnitude of wind speed.\nUsing these readings, Argonne calculated the average daily wind speed (the average of each day’s 8 wind speed readings) for every day within a given time period / scenario (e.g. mid-century RCP4.5) and for each climate model (CCSM, GFDL, and HadGEM).\nArgonne then took the average of each daily average wind speed for a given year (e.g. 2045) and within a given time period / scenario (e.g. mid-century RCP4.5) and for a given climate model (e.g. CCSM), which produced the annual average wind speed for that scenario’s model year, such as CCSM’s estimate of annual average wind speeds in 2045 under climate scenario RCP4.5.\nThis process was repeated for each year within a given time period / scenario.\nThe average of these values was taken to produce the ensemble mean of the annual average wind speed (in mph) for each time period / scenario."
  },
  {
    "objectID": "qmd/01-ClimRR/1-definitions.html#consecutive-days-with-no-precipitation",
    "href": "qmd/01-ClimRR/1-definitions.html#consecutive-days-with-no-precipitation",
    "title": "Climate Variables",
    "section": "Consecutive Days With No Precipitation",
    "text": "Consecutive Days With No Precipitation\nEach climate model estimates an amount of precipitation (whether rain, snow, sleet, or ice) that occurs every 3 hours across the entire modeled time period (i.e. every 3 hours, of every day, for all modeled years).\nThese 3-hour precipitation estimates were used to calculate the daily precipitation quantities by adding all 8 precipitation readings for each day of a given year (e.g. 2045) within a given time period / scenario (e.g. mid-century RCP4.5) and for a given climate model (e.g. CCSM).\nThis process produced the total daily precipitation for every day in a scenario’s model year, such as CCSM’s daily estimates of total precipitation for the year 2045 under climate scenario RCP4.5.\nUsing this information, Argonne identified the greatest number of consecutive days in which no precipitation occurred (i.e. the total daily precipitation quantity equaled zero) for that scenario’s model year (e.g. for the year 2045 under scenario RCP4.5, the highest number of consecutive days without any precipitation was X).\nThis process was repeated for each year within a given time period / scenario (e.g. 2046, 2047 and so forth) across all three climate models (CCSM, GFDL, and HadGEM) producing 10 yearly values for each model, with each value representing the longest consecutive span with no precipitation for that year.\nOf the 10 yearly values for each climate model, the maximum value was selected (e.g. the decadal maximum). This resulted in 3 values for each climate model’s 10 years of data.\nThe average of these maximum of the maxima was then taken to produce the ensemble mean of the decade’s highest number of consecutive days without precipitation in a single year."
  },
  {
    "objectID": "qmd/01-ClimRR/1-definitions.html#degree-days",
    "href": "qmd/01-ClimRR/1-definitions.html#degree-days",
    "title": "Climate Variables",
    "section": "Degree Days",
    "text": "Degree Days"
  },
  {
    "objectID": "qmd/00-GettingStarted/4-chicago.html",
    "href": "qmd/00-GettingStarted/4-chicago.html",
    "title": "Chicago Analysis",
    "section": "",
    "text": "Imports\n%matplotlib inline\nimport matplotlib_inline\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport warnings\n\nimport matplotlib.pyplot as plt\n\n# from enrich.console import Console, get_theme\nmatplotlib_inline.backend_inline.set_matplotlib_formats('svg')\nfrom ClimRR import get_logger, set_plot_style\nfrom ClimRR.data import DATA_DIR\nset_plot_style()\nlog = get_logger('ClimRR')\nfrom rich.console import Console as rConsole\nfrom enrich.style import STYLES\nfrom rich.theme import Theme\n\ntheme = Theme(STYLES)\nlog = get_logger('ClimRR')\nconsole = rConsole(theme=theme, log_path=False, markup=True)\n\n\nUsing updated plot style for matplotlib\n\n\n\n\nfrom ClimRR.data import load_shapefile, load_csvs\n\nshape = load_shapefile()\ndata = load_csvs(shape)\n\ndata['FireWeatherIndex_Wildfire'].shape=(62834, 35)\n\n\n\ndata['HeatingDegreeDays'].shape=(62834, 10)\n\n\n\ndata['AnnualTemperatureMinimum'].shape=(62834, 18)\n\n\n\ndata['SeasonalTemperatureMaximum'].shape=(62834, 27)\n\n\n\ndata['ConsecutiveDayswithNoPrecipitation'].shape=(55896, 19)\n\n\n\ndata['SeasonalTemperatureMinimum'].shape=(62834, 27)\n\n\n\ndata['WindSpeed'].shape=(62834, 18)\n\n\n\ndata['AnnualTemperatureMaximum'].shape=(62834, 18)\n\n\n\ndata['Precipitation_inches_AnnualTotal'].shape=(55896, 18)\n\n\n\n\nsquare = shape[shape[\"Crossmodel\"] == 'R146C497']\nfig, ax = plt.subplots(figsize=(4, 3))\nax = square.boundary.plot(ax=ax)\nax.set_axis_off()\nplt.tight_layout()\n\n\n\n\n\nimport geopandas as gpd\nimport geodatasets\nchipop = gpd.read_file(\n    geodatasets.get_path('geoda.chicago_commpop')\n).to_crs(square.crs)\nchihealth = gpd.read_file(\n    geodatasets.get_path('geoda.chicago_health')\n).to_crs(square.crs)\nchigroc = gpd.read_file(\n    geodatasets.get_path('geoda.groceries')\n).to_crs(square.crs)\n\nWe can inspect this data, looking at the chipop.boundary for example\n\nchipop['boundary'] = chipop.boundary\n\n\nfig, ax = plt.subplots(figsize=(10, 7))\nax = chipop.boundary.plot(linewidth=0.8, color='#838383', ax=ax)\nax.set_axis_off()\n_ = ax.set_title('Chicago Neighborhoods')\n\n\n\n\nWhich we can use to plot the population (by neighborhood, in this case):\n\nfig, ax = plt.subplots(figsize=(10, 7))\nax = chipop.to_crs(square.crs).plot(column=\"POP2010\", legend=True, ax=ax)\nax.set_axis_off()\n_ = ax.set_title(f\"Chicago population by Neighborhood [2010]\")\n\n\n\n\n\nwtown = chipop[chipop[\"community\"] == 'WEST TOWN']\nhumboldt = chipop[chipop[\"community\"] == 'HUMBOLDT PARK']\n\n\nhumboldt.explore()\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\nfig, ax = plt.subplots(figsize=(10, 7))\nax = humboldt.overlay(shape, how='intersection').plot(ax=ax, legend=True)\nax = (\n    hp := chipop[chipop['community'] == 'HUMBOLDT PARK'].overlay(\n        shape,\n        how='intersection'\n    )\n).plot(ax=ax, legend=True)\nax = (\n    lp := chipop[chipop['community'] == 'LINCOLN PARK'].overlay(\n        shape,\n        how='intersection'\n    )\n).plot(ax=ax, legend=True)\nax = chipop.boundary.plot(ax=ax, color='#666666', linewidth=0.8)\nax = lp.boundary.plot(color='red', ax=ax)\nax = hp.boundary.plot(color='red', ax=ax)\nax.set_axis_off()\n_ = ax.set_title('Intersection of Humboldt Park & ClimRR data')\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(10, 7))\nchiwind = data['WindSpeed'].overlay(\n    chipop,\n    how='intersection'\n).overlay(chipop, how='union')\nax = chiwind.boundary.plot(ax=ax, color='#666666', linewidth=0.8)\nax.set_axis_off()\n\n\n\n\n\n_, ax = plt.subplots(figsize=(10, 7))\nax = chipop.boundary.plot(color='#666666', linewidth=0.8, ax=ax, alpha=0.2)\nax = chiwind.plot(column='hist', ax=ax, legend=True)\nax.set_axis_off()\nax.set_title('Historical Wind Data across Chicago Neighborhoods')\nplt.tight_layout()\n\n\n\n\n\nchiwind.explore(column='hist')\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n_, ax = plt.subplots()\nax = chiwind.plot(column='hist', scheme='quantiles', k=8, ax=ax)\n_ = ax.set_title('WindSpeed, historical')\nax.set_axis_off()\nplt.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots()\nax = chiwind.plot(column='rcp45_midc', scheme='quantiles', k=3, ax=ax)\nax.set_axis_off()\n_ = ax.set_title('WindSpeed, Mid-Century [RCP45]')\nplt.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots()\nax = chiwind.plot(column='rcp45_endc', scheme='quantiles', k=3, ax=ax)\n_ = ax.set_title('WindSpeed, End-Century [RCP45]')\nplt.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots(ncols=3, figsize=(16, 7))\nax0 = chiwind.plot('hist', ax=ax[0])\nax1 = chiwind.plot('rcp45_midc', ax=ax[1])\nax2 = chiwind.plot('rcp45_midc', ax=ax[2])\nax0.set_axis_off()\nax1.set_axis_off()\nax2.set_axis_off()\n\n\n\n\n\ndata['WindSpeed'].shape\n\n(62834, 18)\n\n\n\nselection = shape[0:5]\n\nfor index, row in selection.iterrows():\n    # get the area of the polygon\n    poly_area = row['geometry'].area\n    console.print(f\"Polygon area at {index} is {poly_area:.3f}\")\n\nPolygon area at 0 is 252927293.657\n\n\n\nPolygon area at 1 is 235501313.715\n\n\n\nPolygon area at 2 is 233416379.950\n\n\n\nPolygon area at 3 is 261761834.191\n\n\n\nPolygon area at 4 is 226073092.218\n\n\n\n\n\n\nCitationBibTeX citation:@misc{foreman2023,\n  author = {Foreman, Sam},\n  date = {2023-08-02},\n  url = {https://saforem2.github.io/climate-analysis},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nForeman, Sam. 2023. Intro to HPC: Climate Analysis with ClimRR.\nhttps://saforem2.github.io/climate-analysis."
  },
  {
    "objectID": "qmd/00-GettingStarted/2-intro.html",
    "href": "qmd/00-GettingStarted/2-intro.html",
    "title": "Climate Analysis with ClimRR",
    "section": "",
    "text": "Useful links + References\n\n\n\n\n\n\nUseful links + References:\n\nGeopandas: An Introduction\nAn Introduction to Earth and Environmental Data Science\n\nFinal Projects (good examples)\nHands-On: Aggregating the Data\n\nUsing Weather Data and Climate Model Output in Economic Analyses of Climate Change\nOn the use and misuse of climate change projections in international development\n\n\n\n\n\n\n\n\n\n\n\nLearning Goals\n\n\n\n\n\nThe goal of this project is to teach students to1:\n\nUse Unix commands to work with files and navigate directories\nUse JupyterHub + basic familiarity with how to use Jupyter notebooks on HPC systems\nIdentify some of the common file types and data formats for geospatial data\n\n(+ common python libraries for geospatial data analysis)\n\nPerform exploratory data analysis on geospatial data\n\n(+ understand different operations for manipulating and interacting with this data)\ntabular vs. gridded data\n\nPerform simple visualizations in Python to display different types of data (e.g. maps, line charts, interactive visualizations, etc)\n\nusing figures to illustrate a point or idea\nknow what types of plots to use for which situations / data types\n\nUnderstand control flow / basic structure of a Python script\n\nusing Python in Jupyter2\nimport-ing libraries, etc\n\n\n\n\n\n\n\nWe use GeoPandas, an open source project to make working with geospatial data in python easier.\nGeoPandas extends the datatypes used by pandas to allow spatial operations on geometric types.\nGeometric operations are performed by shapely.\nGeoPandas further depends on fiona and matplotlib for plotting.\nGeoPandas can read almost any vector-based spatial data format including ESRI shapefile, GeoJSON files and more using the command\n\nimport geopandas as gpd\nimport geodatasets\ngdf = gpd.read_file(geodatasets.get_path(\"geoda.chicago_commpop\"))\ngdf.head(n=2)\n\n\n\n\n\n\n\n\ncommunity\nNID\nPOP2010\nPOP2000\nPOPCH\nPOPPERCH\npopplus\npopneg\ngeometry\n\n\n\n\n0\nDOUGLAS\n35\n18238\n26470\n-8232\n-31.099358\n0\n1\nMULTIPOLYGON (((-87.60914 41.84469, -87.60915 ...\n\n\n1\nOAKLAND\n36\n5918\n6110\n-192\n-3.142390\n0\n1\nMULTIPOLYGON (((-87.59215 41.81693, -87.59231 ...\n\n\n\n\n\n\n\nwhich returns a GeoDataFrame object.\nA GeoDataFrame is a tabular data structure that contains a GeoSeries.\nThe most important property of a GeoDataFrame is that it always has one GeoSeries column that holds a special status.\nThis GeoSeries is referred to as the GeoDataFrame’s “geometry”. When a spatial method is applied to a GeoDataFrame (or a spatial attribute like area is called), this commands will always act on the “geometry” column3.\n\n\n\nWe’ve prepared some useful functions in src/ClimRR/data.py to simplify the process of loading and working with our data.\n\n\n\n\n\n\n\n\n\nImports\nimport matplotlib_inline\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport warnings\n\nimport matplotlib.pyplot as plt\n\nfrom enrich.style import STYLES\nfrom rich.theme import Theme\nfrom rich.console import Console as Console\nfrom ClimRR import get_logger, set_plot_style\nfrom ClimRR.data import DATA_DIR\n\nmatplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n\nset_plot_style()\ntheme = Theme(STYLES)\nlog = get_logger()\nconsole = Console(\n    theme=Theme(STYLES),\n    log_path=False,\n    markup=True,\n    width=512\n)\n\n\nUsing updated plot style for matplotlib"
  },
  {
    "objectID": "qmd/00-GettingStarted/2-intro.html#getting-started",
    "href": "qmd/00-GettingStarted/2-intro.html#getting-started",
    "title": "Climate Analysis with ClimRR",
    "section": "",
    "text": "Useful links + References\n\n\n\n\n\n\nUseful links + References:\n\nGeopandas: An Introduction\nAn Introduction to Earth and Environmental Data Science\n\nFinal Projects (good examples)\nHands-On: Aggregating the Data\n\nUsing Weather Data and Climate Model Output in Economic Analyses of Climate Change\nOn the use and misuse of climate change projections in international development\n\n\n\n\n\n\n\n\n\n\n\nLearning Goals\n\n\n\n\n\nThe goal of this project is to teach students to1:\n\nUse Unix commands to work with files and navigate directories\nUse JupyterHub + basic familiarity with how to use Jupyter notebooks on HPC systems\nIdentify some of the common file types and data formats for geospatial data\n\n(+ common python libraries for geospatial data analysis)\n\nPerform exploratory data analysis on geospatial data\n\n(+ understand different operations for manipulating and interacting with this data)\ntabular vs. gridded data\n\nPerform simple visualizations in Python to display different types of data (e.g. maps, line charts, interactive visualizations, etc)\n\nusing figures to illustrate a point or idea\nknow what types of plots to use for which situations / data types\n\nUnderstand control flow / basic structure of a Python script\n\nusing Python in Jupyter2\nimport-ing libraries, etc\n\n\n\n\n\n\n\nWe use GeoPandas, an open source project to make working with geospatial data in python easier.\nGeoPandas extends the datatypes used by pandas to allow spatial operations on geometric types.\nGeometric operations are performed by shapely.\nGeoPandas further depends on fiona and matplotlib for plotting.\nGeoPandas can read almost any vector-based spatial data format including ESRI shapefile, GeoJSON files and more using the command\n\nimport geopandas as gpd\nimport geodatasets\ngdf = gpd.read_file(geodatasets.get_path(\"geoda.chicago_commpop\"))\ngdf.head(n=2)\n\n\n\n\n\n\n\n\ncommunity\nNID\nPOP2010\nPOP2000\nPOPCH\nPOPPERCH\npopplus\npopneg\ngeometry\n\n\n\n\n0\nDOUGLAS\n35\n18238\n26470\n-8232\n-31.099358\n0\n1\nMULTIPOLYGON (((-87.60914 41.84469, -87.60915 ...\n\n\n1\nOAKLAND\n36\n5918\n6110\n-192\n-3.142390\n0\n1\nMULTIPOLYGON (((-87.59215 41.81693, -87.59231 ...\n\n\n\n\n\n\n\nwhich returns a GeoDataFrame object.\nA GeoDataFrame is a tabular data structure that contains a GeoSeries.\nThe most important property of a GeoDataFrame is that it always has one GeoSeries column that holds a special status.\nThis GeoSeries is referred to as the GeoDataFrame’s “geometry”. When a spatial method is applied to a GeoDataFrame (or a spatial attribute like area is called), this commands will always act on the “geometry” column3.\n\n\n\nWe’ve prepared some useful functions in src/ClimRR/data.py to simplify the process of loading and working with our data.\n\n\n\n\n\n\n\n\n\nImports\nimport matplotlib_inline\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport warnings\n\nimport matplotlib.pyplot as plt\n\nfrom enrich.style import STYLES\nfrom rich.theme import Theme\nfrom rich.console import Console as Console\nfrom ClimRR import get_logger, set_plot_style\nfrom ClimRR.data import DATA_DIR\n\nmatplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n\nset_plot_style()\ntheme = Theme(STYLES)\nlog = get_logger()\nconsole = Console(\n    theme=Theme(STYLES),\n    log_path=False,\n    markup=True,\n    width=512\n)\n\n\nUsing updated plot style for matplotlib"
  },
  {
    "objectID": "qmd/00-GettingStarted/2-intro.html#types-of-data",
    "href": "qmd/00-GettingStarted/2-intro.html#types-of-data",
    "title": "Climate Analysis with ClimRR",
    "section": "Types of Data",
    "text": "Types of Data\n\n\n\nFigure 1: (Image credit: National Ecological Observatory Network (NEON))\n\n\nOne of the most common file formats for vector data is the ESRI shapefile, which is what we will be working with in be working with in this project.\n\nMetadata\nMetadata is “data about the data”4 and is (by design) meant to give additional information or provide context about a dataset.\nExamples might include:\n\nWhen was this data created?\n\nBy who? For what? Where at? When? Why??\n\nHow is this data licensed?\nIs there a reference for this data? (DOI ? URL ? etc.)\nWhat variables or fields are contained in this data?\n\nWhat do they represent? Are there units?\n\nIf the data is geospatial, what geographical or temporal area is included?\nAdditional (often contextual) information about the data\n\ne.g. “this data was created to inform a population about upcoming weather events” or similar\n\n\nMetadata is often expected to be of a certain form, or to follow specific conventions / guidelines.\nThis is important to keep in mind and will allow others to understand your data without needing an explanation (e.g. “what does this abbreviation mean?”, “how is this variable defined?”, etc.)\nSome common metadata conventions for GIS data include:\n\nClimate and Forecast (CF) Conventions\nAttribute Convention for Data Discovery\n\nSchema.org is another useful reference and provides a general framework for dealing with metadata."
  },
  {
    "objectID": "qmd/00-GettingStarted/2-intro.html#fair-data",
    "href": "qmd/00-GettingStarted/2-intro.html#fair-data",
    "title": "Climate Analysis with ClimRR",
    "section": "FAIR Data",
    "text": "FAIR Data\nFAIR stands for “Findable, Accessible, Interoperable, Reusable”, and provides a set of guidelines for data sharing.\nIn the age of “big data”, its important that we use (and promote!) tools that facilitate the effective sharing of data.\nIdeally, our data would be completely self-contained and provide, via metadata, all of the information required to understand and work with it."
  },
  {
    "objectID": "qmd/00-GettingStarted/2-intro.html#load-shapefile-and-inspect",
    "href": "qmd/00-GettingStarted/2-intro.html#load-shapefile-and-inspect",
    "title": "Climate Analysis with ClimRR",
    "section": "Load Shapefile and inspect",
    "text": "Load Shapefile and inspect\nA shapefile is provided in the ClimRR Data Download (ANL) and can be loaded using geopandas.read_file(...) which will return a geopandas.GeoDataFrame:\n\nshpfile = DATA_DIR.joinpath(\n    \"GridCellsShapefile/GridCells.shp\"\n)\nshape = gpd.read_file(shpfile)\n\nEach entry in this table defines a single grid cell (12km x 12 km) which collectively tile the United States.\nWe can get a better understanding of whats going on by looking at the first few entries:\n\nshape.head(n=2)\n\n\n\n\n\n\n\n\nOBJECTID\nCrossmodel\nShape_Leng\nShape_Area\ngeometry\n\n\n\n\n0\n1\nR161C438\n63614.764866\n2.529273e+08\nPOLYGON ((-9530601.177 4726046.614, -9534793.8...\n\n\n1\n2\nR125C222\n61384.219597\n2.355013e+08\nPOLYGON ((-12959076.287 4395610.472, -12974301...\n\n\n\n\n\n\n\nWe see that each row has the following columns: {OBJECTID, Crossmodel, Shape_Leng, Shape_Area, geometry}.\nIn particular, the Crossmodel5 column is a text ID that uniquely identifies an individual cell.\nTo be explicit, let’s look at the WindSpeed.csv file."
  },
  {
    "objectID": "qmd/00-GettingStarted/2-intro.html#dealing-with-geometry",
    "href": "qmd/00-GettingStarted/2-intro.html#dealing-with-geometry",
    "title": "Climate Analysis with ClimRR",
    "section": "Dealing with Geometry",
    "text": "Dealing with Geometry\nOur shapefile contains a grid of cells (12km x 12km) which tile the continental US.\nWe can inspect a single cell:\n\ncell = shape[shape[\"Crossmodel\"] == 'R146C497']\ncell.head()\n\n\n\n\n\n\n\n\nOBJECTID\nCrossmodel\nShape_Leng\nShape_Area\ngeometry\n\n\n\n\n4\n5\nR146C497\n60142.919468\n2.260731e+08\nPOLYGON ((-8733007.764 4224658.634, -8738250.3...\n\n\n\n\n\n\n\n\nax = cell.boundary.plot()\nax.set_axis_off()\n_ = ax.set_title('Grid from shapefile: 12 x 12 km')\nplt.tight_layout()\n\n\n\n\n\ncell.explore()\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "qmd/00-GettingStarted/2-intro.html#load-data-from-.csv-files",
    "href": "qmd/00-GettingStarted/2-intro.html#load-data-from-.csv-files",
    "title": "Climate Analysis with ClimRR",
    "section": "Load data from *.csv files",
    "text": "Load data from *.csv files\nEach entry (row) in the .csv has a Crossmodel column (e.g. R146C497) which corresponds to a row in our shapefile that uniquely determines its location on the Earth.\nWe can associate with each of the .csvs the geometry used in our shapefile to position our data on the globe.\n\nimport pandas as pd\ncsvs = [i for i in DATA_DIR.rglob('*.csv')]\ndata = {}\nfor f in csvs:\n    key = f.stem\n    tmp = pd.read_csv(f.as_posix())\n    gdf = shape.merge(tmp, on='Crossmodel')\n    gdf['boundary'] = gdf.boundary\n    gdf['centroid'] = gdf.centroid\n    data[key] = gdf\n    console.log(f\"data['{key}'].shape={data[key].shape}\")\n\n[07:47:08] data['FireWeatherIndex_Wildfire'].shape=(62834, 35)                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n\n\n\n[07:47:09] data['HeatingDegreeDays'].shape=(62834, 10)                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n\n\n\n           data['AnnualTemperatureMinimum'].shape=(62834, 18)                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n\n\n\n           data['SeasonalTemperatureMaximum'].shape=(62834, 27)                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n\n\n\n           data['ConsecutiveDayswithNoPrecipitation'].shape=(55896, 19)                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n\n\n\n           data['SeasonalTemperatureMinimum'].shape=(62834, 27)                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n\n\n\n           data['WindSpeed'].shape=(62834, 18)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n\n\n\n           data['AnnualTemperatureMaximum'].shape=(62834, 18)                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n\n\n\n[07:47:10] data['Precipitation_inches_AnnualTotal'].shape=(55896, 18)"
  },
  {
    "objectID": "qmd/00-GettingStarted/2-intro.html#look-at-the-windspeed-data",
    "href": "qmd/00-GettingStarted/2-intro.html#look-at-the-windspeed-data",
    "title": "Climate Analysis with ClimRR",
    "section": "Look at the WindSpeed data",
    "text": "Look at the WindSpeed data\nLets inspect one of the entries in our data[(...)] dictionary, WindSpeed, for example:\n\ndata[\"WindSpeed\"].head()\n\n\n\n\n\n\n\n\nOBJECTID\nCrossmodel\nShape_Leng\nShape_Area\ngeometry\nhist\nrcp45_midc\nrcp45_endc\nrcp85_midc\nrcp85_endc\nmid45_hist\nend45_hist\nmid85_hist\nend85_hist\nmid85_45\nend85_45\nboundary\ncentroid\n\n\n\n\n0\n1\nR161C438\n63614.764866\n2.529273e+08\nPOLYGON ((-9530601.177 4726046.614, -9534793.8...\n7.21540\n7.19415\n7.38917\n7.30470\n7.22690\n-0.021256\n0.173764\n0.089297\n0.011499\n0.110553\n-0.162264\nLINESTRING (-9530601.177 4726046.614, -9534793...\nPOINT (-9540369.710 4720470.575)\n\n\n1\n2\nR125C222\n61384.219597\n2.355013e+08\nPOLYGON ((-12959076.287 4395610.472, -12974301...\n8.32612\n8.11360\n8.26028\n8.17420\n8.02081\n-0.212523\n-0.065843\n-0.151919\n-0.305307\n0.060603\n-0.239465\nLINESTRING (-12959076.287 4395610.472, -129743...\nPOINT (-12967596.341 4402326.143)\n\n\n2\n3\nR121C235\n61111.892875\n2.334164e+08\nPOLYGON ((-12754805.395 4355815.951, -12770000...\n8.58573\n8.59828\n8.56058\n8.54483\n8.55421\n0.012547\n-0.025149\n-0.040898\n-0.031519\n-0.053446\n-0.006370\nLINESTRING (-12754805.395 4355815.951, -127700...\nPOINT (-12763132.114 4362694.465)\n\n\n3\n4\nR169C431\n64716.234995\n2.617618e+08\nPOLYGON ((-9605729.481 4879238.815, -9609863.1...\n9.17284\n9.21681\n9.44966\n9.26548\n9.14917\n0.043968\n0.276813\n0.092635\n-0.023674\n0.048667\n-0.300487\nLINESTRING (-9605729.481 4879238.815, -9609863...\nPOINT (-9615619.029 4873482.586)\n\n\n4\n5\nR146C497\n60142.919468\n2.260731e+08\nPOLYGON ((-8733007.764 4224658.634, -8738250.3...\n8.25430\n8.19130\n8.34417\n8.29698\n8.29411\n-0.062996\n0.089874\n0.042684\n0.039807\n0.105680\n-0.050067\nLINESTRING (-8733007.764 4224658.634, -8738250...\nPOINT (-8742676.917 4220233.536)\n\n\n\n\n\n\n\nWe see that each entry has a geometry column, as well as columns for {hist,rcp45_midc, rcp45_endc, rcp85_midc, rcp85_endc, ...} which contains the numerical value of the WindSpeed in each cell under different scenarios at different points in time.\n\nLet’s look at the WindSpeed for our individual cell:\n\ncell_wind = data[\"WindSpeed\"][data[\"WindSpeed\"][\"Crossmodel\"] == 'R146C497']\n\n\nax = cell_wind.plot(column='hist', legend=True)\nax.set_axis_off()\n_ = ax.set_title(\"WindSpeed [Hist] for CELL: R146C497\")"
  },
  {
    "objectID": "qmd/00-GettingStarted/2-intro.html#visualizing-our-data",
    "href": "qmd/00-GettingStarted/2-intro.html#visualizing-our-data",
    "title": "Climate Analysis with ClimRR",
    "section": "Visualizing our Data",
    "text": "Visualizing our Data\nLets inspect the first few entries from our Shapefile:\n\n\n\n\nCode\nfig, ax = plt.subplots(\n    figsize=(12, 3.5),\n    nrows=1,\n    ncols=3,\n    sharey='row'\n)\nax = ax.flatten()\npairs = {\n    '1k': list(range(1000)),\n    '5k': list(range(5000)),\n    '20k': list(range(20000)),\n}\nfor idx, (key, val) in enumerate(pairs.items()):\n    ax[idx] = shape.loc[val, :].plot(ax=ax[idx])\n    ax[idx].set_axis_off()\n    _ = ax[idx].set_title(f\"First {key} cells\")\nplt.tight_layout()\n\n\n\n\n\nFigure 2: As we include more cells, we see the outline of the US beginning to take shape."
  },
  {
    "objectID": "qmd/00-GettingStarted/2-intro.html#footnotes",
    "href": "qmd/00-GettingStarted/2-intro.html#footnotes",
    "title": "Climate Analysis with ClimRR",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nBuilding on ideas from Earth and Environmental Science↩︎\nGetting Python setup correctly can be surprisingly difficult↩︎\nThe “geometry” column – no matter its name – can be accessed through the geometry attribute (gdf.geometry), and the name of the geometry column can be found by typing gdf.geometry.name.↩︎\nMetadata↩︎\nTruncated name for “Crossmodel_CellName”.↩︎"
  },
  {
    "objectID": "qmd/00-GettingStarted/1-setup.html",
    "href": "qmd/00-GettingStarted/1-setup.html",
    "title": "Getting Started",
    "section": "",
    "text": "We provide below a brief introduction to the project and how to get started using Jupyter @ NERSC\nOur project directory can be found at:\nAll of the data needed for this project has already been copied to the filesystem on NERSC."
  },
  {
    "objectID": "qmd/00-GettingStarted/1-setup.html#setup",
    "href": "qmd/00-GettingStarted/1-setup.html#setup",
    "title": "Getting Started",
    "section": "Setup",
    "text": "Setup\nTo get started, we will need to:\n\nCreate a symlink from the project directory, /global/cfs/cdirs/m4388/Project2-ClimRR/ into your $HOME directory\nln -s /global/cfs/cdirs/m4388/Project2-ClimRR/ $HOME/Project2-ClimRR\nNavigate into here and create your personal directory (where you will store and work on your project):\ncd $HOME/Project2-ClimRR/\nmkdir $USER\ncd $USER\nClone the  GitHub repo\ngit clone https://github.com/saforem2/climate-analysis"
  },
  {
    "objectID": "qmd/00-GettingStarted/3-example.html",
    "href": "qmd/00-GettingStarted/3-example.html",
    "title": "Example: Groceries in Chicago",
    "section": "",
    "text": "Using updated plot style for matplotlib\nWe will walk through an example that demonstrates how to clip geometries to the boundary of a polygon geometry using GeoPandas."
  },
  {
    "objectID": "qmd/00-GettingStarted/3-example.html#imports",
    "href": "qmd/00-GettingStarted/3-example.html#imports",
    "title": "Example: Groceries in Chicago",
    "section": "Imports",
    "text": "Imports\n\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nfrom shapely.geometry import box\nimport geodatasets"
  },
  {
    "objectID": "qmd/00-GettingStarted/3-example.html#get-or-create-example-data",
    "href": "qmd/00-GettingStarted/3-example.html#get-or-create-example-data",
    "title": "Example: Groceries in Chicago",
    "section": "Get or Create Example Data",
    "text": "Get or Create Example Data\nBelow, the example GeoPandas data is imported and opened as a GeoDataFrame.\nAdditionally, a polygon is created with shapely and then converted into a GeoDataFrame with the same CRS as the GeoPandas dataset\n\nimport geodatasets\nchicago = gpd.read_file(geodatasets.get_path(\"geoda.chicago_commpop\"))\ngroceries = gpd.read_file(geodatasets.get_path(\"geoda.groceries\")).to_crs(chicago.crs)\n\nCreate a subset of the chicago data that is just the near west side\n\nnear_west_side = chicago[chicago[\"community\"] == \"NEAR WEST SIDE\"]\nlincoln_park = chicago[chicago[\"community\"] == \"LINCOLN PARK\"]\nlogan_square = chicago[chicago[\"community\"] == \"LOGAN SQUARE\"]\n\nCreate a custom polygon\n\npolygon = box(-87.8, 41.9, -87.5, 42)\npoly_gdf = gpd.GeoDataFrame([1], geometry=[polygon], crs=chicago.crs)"
  },
  {
    "objectID": "qmd/00-GettingStarted/3-example.html#plot-the-unclipped-data",
    "href": "qmd/00-GettingStarted/3-example.html#plot-the-unclipped-data",
    "title": "Example: Groceries in Chicago",
    "section": "Plot the Unclipped Data",
    "text": "Plot the Unclipped Data\n\nfig, (ax1, ax2) = plt.subplots(figsize=(14, 6), ncols=2, sharey='col')\npoly_gdf.boundary.plot(ax=ax1, color=COLORS['red'])\nchicago.boundary.plot(ax=ax1, color=COLORS['grey060'], linewidth=0.6, zorder=-1)\n# near_west_side.boundary.plot(ax=ax2, color=COLORS['red'])\n# near_west_side.plot(ax=ax2, color=COLORS['green'], alpha=0.3)\n# west_town.plot(ax=ax2, color=COLORS['green'], alpha=0.3)\nchicago.plot(ax=ax1, alpha=0.4)\npoly_gdf.boundary.plot(ax=ax2, color=COLORS['red'])\nchicago.boundary.plot(ax=ax2, color=COLORS['grey060'], linewidth=0.6, zorder=-1)\ngroceries.plot(ax=ax2, color=COLORS['blue'], zorder=1, marker='.', alpha=0.66)\nax1.set_title(\"All Unclipped Chicago Communities\", fontsize=20)\nax2.set_title(\"All Unclipped Groceries\", fontsize=20)\nax1.set_axis_off()\nax2.set_axis_off()\nplt.tight_layout()"
  },
  {
    "objectID": "qmd/00-GettingStarted/3-example.html#clip-the-data",
    "href": "qmd/00-GettingStarted/3-example.html#clip-the-data",
    "title": "Example: Groceries in Chicago",
    "section": "Clip the Data",
    "text": "Clip the Data\nThe object on which you call clip is the object that will be clipped.\nThe object you pass is the clip extent.\nThe returned output will be a new clipped GeoDataFrame. All of the attributes for each returned geometry will be retained when you clip.\n\n\n\n\n\n\nCoordinate Reference System\n\n\n\n\n\nRecall that the data must be in the same CRS in order to use the clip method.\nIf the data is not in the same CRS, be sure to use the GeoDataFrame.to_crs method to ensure both datasets are in the same CRS."
  },
  {
    "objectID": "qmd/00-GettingStarted/3-example.html#clip-the-chicago-data",
    "href": "qmd/00-GettingStarted/3-example.html#clip-the-chicago-data",
    "title": "Example: Groceries in Chicago",
    "section": "Clip the Chicago Data",
    "text": "Clip the Chicago Data\n\nchicago_clipped = chicago.clip(polygon)\ngroceries_clipped = groceries.clip(polygon)\n# plot the clipped data\nfig, ax = plt.subplots(figsize=(14, 6), ncols=2)\nax0 = chicago_clipped.plot(ax=ax[0], color='C0', alpha=0.66)\nax0 = chicago.boundary.plot(ax=ax[0], color=COLORS['grey060'], zorder=-1, linewidth=0.6)\nax0 = poly_gdf.boundary.plot(ax=ax[0], color=COLORS['red'])\n\nax1 = groceries_clipped.plot(ax=ax[1], color='C1', alpha=0.66, zorder=10, marker='.')\n# chicago.boundary.plot(ax=ax[1], color='#444444')\nax1 = chicago.boundary.plot(ax=ax[1], color=COLORS['grey060'], zorder=-1, linewidth=0.6)\nax1 = poly_gdf.boundary.plot(ax=ax[1], color=COLORS['red'])\n\nax0.set_title(\"Chicago Clipped\", fontsize=20)\nax0.set_axis_off()\nax1.set_title(\"Groceries Clipped\", fontsize=20)\nax1.set_axis_off()\nplt.tight_layout()"
  },
  {
    "objectID": "qmd/00-GettingStarted/3-example.html#clip-the-groceries-data",
    "href": "qmd/00-GettingStarted/3-example.html#clip-the-groceries-data",
    "title": "Example: Groceries in Chicago",
    "section": "Clip the Groceries Data",
    "text": "Clip the Groceries Data\nNext we’ll look at the distribution of grocery stores in two different communities.\n\nfig, (ax1, ax2) = plt.subplots(figsize=(14, 6), ncols=2, sharey='col')\nchicago.boundary.plot(ax=ax1, color=COLORS['grey060'], linewidth=0.6, zorder=-1)\nnear_west_side.boundary.plot(ax=ax2, color=COLORS['red'])\nnear_west_side.plot(ax=ax2, color=COLORS['green'], alpha=0.3)\n\nlogan_square.boundary.plot(ax=ax2, color=COLORS['red'])\nlogan_square.plot(ax=ax2, color=COLORS['green'], alpha=0.3)\n# west_town.plot(ax=ax2, color=COLORS['green'], alpha=0.3)\nchicago.plot(ax=ax1, alpha=0.4)\nchicago.boundary.plot(ax=ax2, color=COLORS['grey060'], linewidth=0.6, zorder=-1)\ngroceries.plot(ax=ax2, color=COLORS['blue'], zorder=1, marker='.', alpha=0.66)\nax1.set_title(\"All Unclipped Chicago Communities\", fontsize=20)\nax2.set_title(\"All Unclipped Groceries\", fontsize=20)\nax1.set_axis_off()\nax2.set_axis_off()\nplt.tight_layout()"
  },
  {
    "objectID": "qmd/00-GettingStarted/3-example.html#groceries-in-near-west-side",
    "href": "qmd/00-GettingStarted/3-example.html#groceries-in-near-west-side",
    "title": "Example: Groceries in Chicago",
    "section": "Groceries in Near West Side",
    "text": "Groceries in Near West Side\n\ngroceries_west_side = groceries.clip(near_west_side)\nfig, ax = plt.subplots(figsize=(14,6))\ngroceries_west_side.plot(ax=ax, color='C2', marker='.', alpha=0.6)\nchicago.boundary.plot(ax=ax, color=COLORS['grey060'], linewidth=0.6, zorder=-1)\nnear_west_side.boundary.plot(ax=ax, color='#444444')\nnear_west_side.boundary.plot(ax=ax, color=COLORS['red'])\nnear_west_side.plot(ax=ax, color=COLORS['green'], alpha=0.3)\nax.set_title(\"Groceries in the Near West Side\")\nax.set_axis_off()"
  },
  {
    "objectID": "qmd/00-GettingStarted/3-example.html#groceries-in-logan-square",
    "href": "qmd/00-GettingStarted/3-example.html#groceries-in-logan-square",
    "title": "Example: Groceries in Chicago",
    "section": "Groceries in Logan Square",
    "text": "Groceries in Logan Square\n\ngroceries_logan_square = groceries.clip(logan_square)\nfig, ax = plt.subplots(figsize=(14,6))\ngroceries_logan_square.plot(ax=ax, color='C2', marker='.', alpha=0.6)\nchicago.boundary.plot(ax=ax, color=COLORS['grey060'], linewidth=0.6, zorder=-1)\nlogan_square.boundary.plot(ax=ax, color='#444444')\nlogan_square.boundary.plot(ax=ax, color=COLORS['red'])\nlogan_square.plot(ax=ax, color=COLORS['green'], alpha=0.3)\nax.set_title(\"Groceries in Logan Square\")\nax.set_axis_off()"
  },
  {
    "objectID": "qmd/00-GettingStarted/3-example.html#groceries-in-lincoln-park",
    "href": "qmd/00-GettingStarted/3-example.html#groceries-in-lincoln-park",
    "title": "Example: Groceries in Chicago",
    "section": "Groceries in Lincoln Park",
    "text": "Groceries in Lincoln Park\n\ngroceries_lp = groceries.clip(lincoln_park)\nfig, ax = plt.subplots(figsize=(14,6))\ngroceries_lp.plot(ax=ax, color='C2')\nchicago.boundary.plot(ax=ax, color=COLORS['grey060'], linewidth=0.6, zorder=-1)\nlincoln_park.boundary.plot(ax=ax, color='#444444')\nlincoln_park.boundary.plot(ax=ax, color=COLORS['red'])\nlincoln_park.plot(ax=ax, color=COLORS['green'], alpha=0.3)\nax.set_title(\"Groceries in Lincoln Park\")\nax.set_axis_off()"
  },
  {
    "objectID": "qmd/00-GettingStarted/3-example.html#additional-questions",
    "href": "qmd/00-GettingStarted/3-example.html#additional-questions",
    "title": "Example: Groceries in Chicago",
    "section": "Additional Questions",
    "text": "Additional Questions\n\nCan you identify which neighborhoods have the most grocery stores? How many?\n\nWhich have the least? How many?"
  },
  {
    "objectID": "qmd/00-GettingStarted/3-example.html#reference",
    "href": "qmd/00-GettingStarted/3-example.html#reference",
    "title": "Example: Groceries in Chicago",
    "section": "Reference",
    "text": "Reference\nGeoPandas: Clip Vector Data"
  },
  {
    "objectID": "qmd/01-ClimRR/0-ClimRR.html",
    "href": "qmd/01-ClimRR/0-ClimRR.html",
    "title": "Climate Risk & Resilience Portal",
    "section": "",
    "text": "For completeness, we include text below from (Burdi and Branham 2023)\nClimate scenarios are the set of conditions used to represent estimates of future greenhouse gas (GHG) concentrations in the atmosphere. Climate models then evaluate how these GHG concentrations affect future (projected) climate.\nThe data in ClimRR include model results from two future climate scenarios, called Representative Concentration Pathways (RCPs):\n\nRCP4.5: in this scenario, human GHG emissions peak around 2040, then decline\nRCP8.5: in this scenario, human GHG emissions continue to rise throughout the 21-st century\n\nEach RCP is modeled over a mid-century period (2045—2054) and end-of-century-period (2081 to 2094). A historical period (1995—2004) is also modeled using GHG concentrations during this period."
  },
  {
    "objectID": "qmd/01-ClimRR/0-ClimRR.html#climate-scenarios",
    "href": "qmd/01-ClimRR/0-ClimRR.html#climate-scenarios",
    "title": "Climate Risk & Resilience Portal",
    "section": "",
    "text": "For completeness, we include text below from (Burdi and Branham 2023)\nClimate scenarios are the set of conditions used to represent estimates of future greenhouse gas (GHG) concentrations in the atmosphere. Climate models then evaluate how these GHG concentrations affect future (projected) climate.\nThe data in ClimRR include model results from two future climate scenarios, called Representative Concentration Pathways (RCPs):\n\nRCP4.5: in this scenario, human GHG emissions peak around 2040, then decline\nRCP8.5: in this scenario, human GHG emissions continue to rise throughout the 21-st century\n\nEach RCP is modeled over a mid-century period (2045—2054) and end-of-century-period (2081 to 2094). A historical period (1995—2004) is also modeled using GHG concentrations during this period."
  },
  {
    "objectID": "qmd/01-ClimRR/0-ClimRR.html#downscaled-climate-models",
    "href": "qmd/01-ClimRR/0-ClimRR.html#downscaled-climate-models",
    "title": "Climate Risk & Resilience Portal",
    "section": "Downscaled Climate Models",
    "text": "Downscaled Climate Models\nA global climate model (GCM) is a complex mathematical representation of the major climate system components (atmosphere, land surface, ocean, and sea ice) and their interactions.\nThese models project climatic conditions at frequent intervals over long periods of time (e.g., every 3 hours for the next 50—100 years), often with the purpose of evaluating how one or more GHG scenarios will impact future climate.\nMost GCMs project patterns at relatively coarse spatial resolutions, using grid cells ranging from 100km to 200km.\nThe climate data presented in this portal has been downscaled to a higher spatial resolution (12km) to fill a growing need for risk analysis and resilience planning at the local level.\nWe use dynamical downscaling, which applies the outputs of a GCM as inputs to a separate, high-resolution regional climate model.\nDynamical downscaling accounts for the physical processes and natural features of a region, as well as the complex interaction between these elements and global dynamics under a climate scenario.\nArgonne’s dynamical downscaling uses the Weather Research and Forecasting (WRF) model, which is a regional weather model for North America developed by the National Center for Atmospheric Research.\nScientists at Argonne dynamically downscaled three different GCMs, including:\n\nCCSM: The Community Climate System Model (Version 4) is a coupled global climate model developed by the University Corporation for Atmospheric Research with funding from the National Science Foundation, the Department of Energy, and the National Aeronautics and Space Administration. It is comprised of atmospheric, land surface, and sea ice sub-models that run simultaneously with a central coupler component.\nGFDL: The Geophysical Fluid Dynamics Laboratory at the National Oceanic and Atmospheric Administration developed the Earth System Model Version 2G (note: the general convention, which we use, is to use the Laboratory’s abbreviation to identify this model). It includes an atmospheric circulation model and an oceanic circulation model, and takes into account land, sea ice, and iceberg dynamics.\nHadGEM: The United Kingdom’s Met Office developed the Hadley Global Environment Model 2—Earth System. It is used for both operational weather forecasting and climate research, and includes coupled atmosphere‐ocean analysis and an earth system component that includes dynamic vegetation, ocean biology, and atmospheric chemistry."
  },
  {
    "objectID": "qmd/01-ClimRR/0-ClimRR.html#ensemble-means",
    "href": "qmd/01-ClimRR/0-ClimRR.html#ensemble-means",
    "title": "Climate Risk & Resilience Portal",
    "section": "Ensemble Means",
    "text": "Ensemble Means\nAll data layers in ClimRR represent a climate variable along with its associated time period and climate scenario (e.g. mid-century RCP4.5). Each time period comprises one decade’s worth of information:\n\nhistorical: (1995 — 2004)\nmid-century: (2045 — 2054)\nend-of-century: (2085 — 2094)\n\nFor each scenario, the WRF model is run with each of the three GCM outputs, producing three individual decades of weather data for each scenario.\nIn other words, 30 years of downscaled climate data is produced for each decadal scenario.\nBy using the outputs from three different GCMs, rather than a single model, Argonne’s climate projections better account for the internal uncertainty associated with any single model.\nEach year’s worth of data includes weather outputs for every 3 hours, or 8 modeled outputs per day.\nWhile this allows for a high degree of granularity in assessing future climate models, there are many different ways to analyze this data; however, there are several important common methodologies share across all variables presented in this portal.\nMost variables are presented as annual or seasonal averages of daily observations, yet each annual / seasonal average draws upon all three different climate model runs for that scenario and the ten years of data produced by each model.\n\n\n\n\n\n\nEnsemble Mean\n\n\n\n\n\nEach variable (e.g. total_annual_precipitation) for a given scenario (e.g. Mid-century RCP4.5) is produced by calculating an individual estimate for each of the 30 years of climate data associated with that scenario, and then taking the average of 30 estimates.\nThis result is what we term the ensemble mean."
  },
  {
    "objectID": "qmd/01-ClimRR/0-ClimRR.html#metadata",
    "href": "qmd/01-ClimRR/0-ClimRR.html#metadata",
    "title": "Climate Risk & Resilience Portal",
    "section": "Metadata",
    "text": "Metadata\nThe links below direct to the REST service of the gridded data. Metadata, descriptions, and field names were last updated on 11/7/2022.\n\nTemperature Minimum – Annual\nTemperature Minimum – Seasonal\nTemperature Maximum – Annual\nTemperature Maximum – Seasonal\nPrecipitation – Annual Total\nPrecipitation None – Annual Average\nWind Speed – Annual Average\nCooling Degree Days – Annual Total\nHeating Degree Days – Annual Total\n\nThe definitions for each of these terms can be found here."
  },
  {
    "objectID": "qmd/01-ClimRR/2-chicago-temp.html",
    "href": "qmd/01-ClimRR/2-chicago-temp.html",
    "title": "Chicago Temperature Analysis",
    "section": "",
    "text": "Target Goals\n\n\n\n\n\n\nRepeat this analysis with:\n\nDifferent climate variables\nAnother state / geographic area\nAnother climate scenario\n\nAny interesting trends or insights to be drawn from the data\n\n\n\n\n\n\nImports\n%matplotlib inline\nimport matplotlib_inline\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport warnings\n\nimport matplotlib.pyplot as plt\n\n# from enrich.console import Console, get_theme\nmatplotlib_inline.backend_inline.set_matplotlib_formats('svg')\nfrom ClimRR.data import DATA_DIR\nfrom ClimRR import get_logger, set_plot_style\nset_plot_style()\nlog = get_logger('ClimRR')\nfrom rich.console import Console as rConsole\nfrom enrich.style import STYLES\nfrom rich.theme import Theme\n\ntheme = Theme(STYLES)\nlog = get_logger('ClimRR')\nconsole = rConsole(theme=theme, log_path=False, markup=True)\n\n\nUsing updated plot style for matplotlib\n\n\n\n\nfrom ClimRR.data import load_shapefile, load_csvs\n\nshape = load_shapefile()\ndata = load_csvs(shape)\n\ndata['FireWeatherIndex_Wildfire'].shape=(62834, 35)\n\n\n\ndata['HeatingDegreeDays'].shape=(62834, 10)\n\n\n\ndata['AnnualTemperatureMinimum'].shape=(62834, 18)\n\n\n\ndata['SeasonalTemperatureMaximum'].shape=(62834, 27)\n\n\n\ndata['ConsecutiveDayswithNoPrecipitation'].shape=(55896, 19)\n\n\n\ndata['SeasonalTemperatureMinimum'].shape=(62834, 27)\n\n\n\ndata['WindSpeed'].shape=(62834, 18)\n\n\n\ndata['AnnualTemperatureMaximum'].shape=(62834, 18)\n\n\n\ndata['Precipitation_inches_AnnualTotal'].shape=(55896, 18)\n\n\n\n\nconsole.print(\"Data: \\n\" + f\"\\n\".join(list(data.keys())))\n\nData: \nFireWeatherIndex_Wildfire\nHeatingDegreeDays\nAnnualTemperatureMinimum\nSeasonalTemperatureMaximum\nConsecutiveDayswithNoPrecipitation\nSeasonalTemperatureMinimum\nWindSpeed\nAnnualTemperatureMaximum\nPrecipitation_inches_AnnualTotal\n\n\n\n\n# counties = gpd.read_file(\n#     'https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/georef-united-states-of-america-county/exports/shp?lang=en&timezone=America%2FChicago'\n# )\nfrom ClimRR.data import load_counties\ncounties = load_counties(crs=shape.crs)\n\n\ncounties.head(n=5)\n\n\n\n\n\n\n\n\nyear\nste_code\nste_name\ncoty_code\ncoty_name\ncoty_area_\ncoty_type\ncoty_name_\ncoty_fp_co\ncoty_gnis_\ngeometry\n\n\n\n\n0\n2022\n['29']\n['Missouri']\n['29081']\n['Harrison']\nUSA\ncounty\n['Harrison County']\n081\n00758495\nPOLYGON ((-10489884.973 4949400.757, -10487772...\n\n\n1\n2022\n['29']\n['Missouri']\n['29099']\n['Jefferson']\nUSA\ncounty\n['Jefferson County']\n099\n00758504\nPOLYGON ((-10089996.419 4590245.129, -10090028...\n\n\n2\n2022\n['29']\n['Missouri']\n['29145']\n['Newton']\nUSA\ncounty\n['Newton County']\n145\n00758527\nPOLYGON ((-10470623.473 4445817.195, -10470640...\n\n\n3\n2022\n['29']\n['Missouri']\n['29223']\n['Wayne']\nUSA\ncounty\n['Wayne County']\n223\n00758564\nPOLYGON ((-10105533.614 4446123.627, -10105492...\n\n\n4\n2022\n['30']\n['Montana']\n['30053']\n['Lincoln']\nUSA\ncounty\n['Lincoln County']\n053\n01720038\nPOLYGON ((-12771356.786 6274948.609, -12771395...\n\n\n\n\n\n\n\n\nillinois = counties[counties['ste_name'] == \"['Illinois']\"]\nconsole.log(f\"illinois.shape={illinois.shape}\")\nillinois.head(n=5)\n\n[07:47:47] illinois.shape=(102, 11)                                                          \n\n\n\n\n\n\n\n\n\n\nyear\nste_code\nste_name\ncoty_code\ncoty_name\ncoty_area_\ncoty_type\ncoty_name_\ncoty_fp_co\ncoty_gnis_\ngeometry\n\n\n\n\n31\n2022\n['17']\n['Illinois']\n['17025']\n['Clay']\nUSA\ncounty\n['Clay County']\n025\n00424214\nPOLYGON ((-9873318.708 4709448.559, -9873005.6...\n\n\n32\n2022\n['17']\n['Illinois']\n['17065']\n['Hamilton']\nUSA\ncounty\n['Hamilton County']\n065\n00424234\nPOLYGON ((-9874775.991 4566267.709, -9874777.2...\n\n\n33\n2022\n['17']\n['Illinois']\n['17077']\n['Jackson']\nUSA\ncounty\n['Jackson County']\n077\n00424240\nPOLYGON ((-9927204.688 4572408.800, -9925575.1...\n\n\n97\n2022\n['17']\n['Illinois']\n['17001']\n['Adams']\nUSA\ncounty\n['Adams County']\n001\n00424202\nPOLYGON ((-10120274.096 4894041.102, -10120277...\n\n\n98\n2022\n['17']\n['Illinois']\n['17067']\n['Hancock']\nUSA\ncounty\n['Hancock County']\n067\n00424235\nPOLYGON ((-10120274.096 4894041.102, -10120442...\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(10, 7))\nax = illinois.boundary.plot(ax=ax, color='#666666', linewidth=0.8)\nax.set_axis_off()\n\n\n\n\n\nillinois_hdd = data[\"HeatingDegreeDays\"].clip(illinois)\nillinois_hdd.head(n=2)\n\n\n\n\n\n\n\n\nOBJECTID\nCrossmodel\nShape_Leng\nShape_Area\ngeometry\nhist\nrcp85_midc\nmid85_hist\nboundary\ncentroid\n\n\n\n\n21130\n21131\nR137C419\n61562.240069\n2.368692e+08\nPOLYGON ((-9925519.402 4437348.204, -9922237.2...\n5618.240234\n5188.899902\n-429.347992\nLINESTRING (-9910499.397 4433932.370, -9913921...\nPOINT (-9919714.441 4428138.497)\n\n\n15883\n15884\nR137C418\n61585.714048\n2.370499e+08\nMULTIPOLYGON (((-9940550.883 4440740.008, -993...\n5668.370117\n5196.740234\n-471.623993\nLINESTRING (-9943924.960 4425714.844, -9940550...\nPOINT (-9934728.187 4431536.593)\n\n\n\n\n\n\n\n\n_, ax = plt.subplots(figsize=(10, 7))\nax = illinois_hdd.boundary.plot(color='#666666', linewidth=0.8, ax=ax, alpha=0.2)\nax = illinois_hdd.plot(column='hist', ax=ax, legend=True)\nax.set_axis_off()\nax.set_title('Historical Heating Degree Days across Illinois')\nplt.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots(ncols=3, figsize=(16, 7), sharey='row')\nax0 = illinois_hdd.plot('hist', ax=ax[0], legend=True)\nax1 = illinois_hdd.plot('rcp85_midc', ax=ax[1], legend=True)\nax2 = illinois_hdd.plot('mid85_hist', ax=ax[2], legend=True)\nax0.set_title(\"HDD: Historical\")\nax1.set_title(\"HDD: Mid-Century RCP8.5\")\nax2.set_title(\"HDD: (Mid-Century - Historical) RCP8.5\")\nax0.set_axis_off()\nax1.set_axis_off()\nax2.set_axis_off()\nplt.tight_layout()\n\n\n\n\n\n_, ax = plt.subplots(figsize=(10, 7))\nax = illinois_hdd.boundary.plot(color='#666666', linewidth=0.8, ax=ax, alpha=0.2)\nax = illinois_hdd.plot(column='rcp85_midc', ax=ax, legend=True)\nax.set_axis_off()\nax.set_title('RCP8.5 Mid-Century Heating Degree Days across Illinois')\nplt.tight_layout()\n\n\n\n\n\n_, ax = plt.subplots(figsize=(10, 7))\nax = illinois_hdd.boundary.plot(color='#666666', linewidth=0.8, ax=ax, alpha=0.2)\nax = illinois_hdd.plot(column='mid85_hist', ax=ax, legend=True)\nax.set_axis_off()\nax.set_title('RCP8.5 End-Century Heating Degree Days across Illinois')\nplt.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(10, 7))\nwind_il = data['WindSpeed'].clip(\n    illinois,\n    # how='intersection'\n)\n# ax = wind_il.boundary.plot(ax=ax, color='#666666', linewidth=0.8)\nax = wind_il.plot(column='hist', ax=ax, linewidth=0.8, legend=True)\nax.set_axis_off()\n\n\n\n\n\n_, ax = plt.subplots(figsize=(10, 7))\nax = wind_il.boundary.plot(color='#666666', linewidth=0.8, ax=ax, alpha=0.2)\nax = wind_il.plot(column='hist', ax=ax, legend=True)\nax.set_axis_off()\nax.set_title('Historical Wind Data across Illinois')\nplt.tight_layout()\n\n\n\n\n\n# wind_il.explore(column='hist')\nwind_il.head(n=2)\n\n\n\n\n\n\n\n\nOBJECTID\nCrossmodel\nShape_Leng\nShape_Area\ngeometry\nhist\nrcp45_midc\nrcp45_endc\nrcp85_midc\nrcp85_endc\nmid45_hist\nend45_hist\nmid85_hist\nend85_hist\nmid85_45\nend85_45\nboundary\ncentroid\n\n\n\n\n21130\n21131\nR137C419\n61562.240069\n2.368692e+08\nPOLYGON ((-9925519.402 4437348.204, -9922237.2...\n7.36933\n7.40137\n7.53169\n7.46885\n7.43563\n0.032043\n0.162359\n0.099523\n0.066305\n0.067481\n-0.096054\nLINESTRING (-9910499.397 4433932.370, -9913921...\nPOINT (-9919714.441 4428138.497)\n\n\n15883\n15884\nR137C418\n61585.714048\n2.370499e+08\nMULTIPOLYGON (((-9940550.883 4440740.008, -993...\n7.76390\n7.78540\n7.90540\n7.86042\n7.82429\n0.021496\n0.141499\n0.096518\n0.060394\n0.075023\n-0.081105\nLINESTRING (-9943924.960 4425714.844, -9940550...\nPOINT (-9934728.187 4431536.593)\n\n\n\n\n\n\n\n\n_, ax = plt.subplots()\nax = wind_il.plot(column='hist', ax=ax, legend=True)\n_ = ax.set_title('WindSpeed, historical')\nax.set_axis_off()\n\n\n\n\n\nfig, ax = plt.subplots()\nax = wind_il.plot(column='rcp45_midc', ax=ax, legend=True)\nax.set_axis_off()\n_ = ax.set_title('WindSpeed, Mid-Century [RCP45]')\n\n\n\n\n\nfig, ax = plt.subplots()\n_ = ax.set_title('WindSpeed, End-Century [RCP45]')\n# _ = ax.legend(loc='best')\nax = wind_il.plot(column='rcp45_endc', ax=ax, legend=True)\nax.set_axis_off()\n\n\n\n\n\nfig, ax = plt.subplots(ncols=3, figsize=(16, 7))\nax0 = wind_il.plot('hist', ax=ax[0], legend=True)\nax1 = wind_il.plot('rcp45_midc', ax=ax[1], legend=True)\nax2 = wind_il.plot('rcp45_endc', ax=ax[2], legend=True)\nax0.set_title(\"Wind Speed: Historical\")\nax1.set_title(\"Wind Speed: Mid-Century RCP4.5\")\nax2.set_title(\"Wind Speed: End-Century RCP4.5\")\nax0.set_axis_off()\nax1.set_axis_off()\nax2.set_axis_off()\nplt.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots(ncols=3, figsize=(16, 7))\nax0 = wind_il.plot('hist', ax=ax[0], legend=True)\nax1 = wind_il.plot('rcp85_midc', ax=ax[1], legend=True)\nax2 = wind_il.plot('rcp85_endc', ax=ax[2], legend=True)\nax0.set_title(\"Wind Speed: Historical\")\nax1.set_title(\"Wind Speed: Mid-Century RCP8.5\")\nax2.set_title(\"Wind Speed: End-Century RCP8.5\")\nax0.set_axis_off()\nax1.set_axis_off()\nax2.set_axis_off()\nplt.tight_layout()\n\n\n\n\n\ndata['WindSpeed'].shape\n\n(62834, 18)\n\n\n\nselection = shape[0:5]\n\nfor index, row in selection.iterrows():\n    # get the area of the polygon\n    poly_area = row['geometry'].area\n    console.print(f\"Polygon area at {index} is {poly_area:.3f}\")\n\nPolygon area at 0 is 252927293.657\n\n\n\nPolygon area at 1 is 235501313.715\n\n\n\nPolygon area at 2 is 233416379.950\n\n\n\nPolygon area at 3 is 261761834.191\n\n\n\nPolygon area at 4 is 226073092.218\n\n\n\n\n\n\nCitationBibTeX citation:@misc{foreman2023,\n  author = {Foreman, Sam},\n  date = {2023-08-02},\n  url = {https://saforem2.github.io/climate-analysis},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nForeman, Sam. 2023. Intro to HPC: Climate Analysis with ClimRR.\nhttps://saforem2.github.io/climate-analysis."
  },
  {
    "objectID": "qmd/00-GettingStarted/0-python.html",
    "href": "qmd/00-GettingStarted/0-python.html",
    "title": "Overview of Python",
    "section": "",
    "text": "Reference\n\n\n\n\n\nMaterial below modified from1: Python Fundamentals"
  },
  {
    "objectID": "qmd/00-GettingStarted/0-python.html#invoking-python",
    "href": "qmd/00-GettingStarted/0-python.html#invoking-python",
    "title": "Overview of Python",
    "section": "Invoking Python",
    "text": "Invoking Python\nThere are three main ways to use Python:\n\nRunning / executing a Python file, e.g. python filename.py\n\nthis will launch python, execute (line by line) the contents of filename.py, and return\n\nInteractively, either through:\n\na console (e.g. the Python interpreter python or an IPython shell ipython)\na notebook (e.g. Jupyter notebook)*\n\n\n*we will (mostly) focus on using Jupyter notebooks for this project."
  },
  {
    "objectID": "qmd/00-GettingStarted/0-python.html#footnotes",
    "href": "qmd/00-GettingStarted/0-python.html#footnotes",
    "title": "Overview of Python",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWhich itself is modified from the official python tutorial↩︎"
  },
  {
    "objectID": "qmd/extras/0-illinois.html",
    "href": "qmd/extras/0-illinois.html",
    "title": "Continued Analysis",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport geopandas as gpd\n\nfrom typing import Optional\nfrom enrich.style import STYLES\nfrom rich.theme import Theme\nfrom rich.console import Console\n\nfrom ClimRR import (\n    set_plot_style,\n    get_logger,\n    DEFAULT_CRS,\n)\nfrom ClimRR.data import (\n    load_shapefile,\n    load_csvs,\n    load_counties,\n    load_chicago_data\n)\n\nset_plot_style()\ntheme = Theme(STYLES)\nlog = get_logger('ClimRR')\nconsole = Console(theme=theme, log_path=False, markup=True)\n\nUsing updated plot style for matplotlib\n\n\n\n\nshape = load_shapefile()\ndata = load_csvs(shape)\nchidata = load_chicago_data(shape.crs)\n\ndata['FireWeatherIndex_Wildfire'].shape=(62834, 35)\n\n\n\ndata['HeatingDegreeDays'].shape=(62834, 10)\n\n\n\ndata['AnnualTemperatureMinimum'].shape=(62834, 18)\n\n\n\ndata['SeasonalTemperatureMaximum'].shape=(62834, 27)\n\n\n\ndata['ConsecutiveDayswithNoPrecipitation'].shape=(55896, 19)\n\n\n\ndata['SeasonalTemperatureMinimum'].shape=(62834, 27)\n\n\n\ndata['WindSpeed'].shape=(62834, 18)\n\n\n\ndata['AnnualTemperatureMaximum'].shape=(62834, 18)\n\n\n\ndata['Precipitation_inches_AnnualTotal'].shape=(55896, 18)\n\n\n\n\ncounties = load_counties(shape.crs)\n\n\nillinois = counties[counties[\"ste_name\"] == \"['Illinois']\"]\nwind_il = data[\"WindSpeed\"].overlay(illinois, how='intersection')\n\n\nfig, ax = plt.subplots(figsize=(10, 7))\nwind_il.plot(ax=ax, column='hist', legend=True)\nax.set_axis_off()\nplt.show()\n\n\n\n\n\nconsole.log(\"\\n\".join(list(data.keys())))\n\n[07:54:38] FireWeatherIndex_Wildfire                                                         \n           HeatingDegreeDays                                                                 \n           AnnualTemperatureMinimum                                                          \n           SeasonalTemperatureMaximum                                                        \n           ConsecutiveDayswithNoPrecipitation                                                \n           SeasonalTemperatureMinimum                                                        \n           WindSpeed                                                                         \n           AnnualTemperatureMaximum                                                          \n           Precipitation_inches_AnnualTotal                                                  \n\n\n\n\ndef get_state(\n        state: str,\n        counties: Optional[gpd.GeoDataFrame] = None,\n) -&gt; gpd.GeoDataFrame:\n    counties = load_counties(DEFAULT_CRS) if counties is None else counties\n    assert counties is not None and isinstance(counties, gpd.GeoDataFrame)\n    assert counties.crs == DEFAULT_CRS\n    return counties[counties[\"ste_name\"] == f\"['{state}']\"]\n\n\ndef get_variable_for_state(\n        data: gpd.GeoDataFrame,\n        state: gpd.GeoDataFrame,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Returns `data.overlay(state, how='intersection')`\"\"\"\n    return data.overlay(state, how='intersection')\n\n\ncalifornia = get_state('California', counties=counties)\n\n\nfig, ax = plt.subplots(figsize=(10, 7))\nax = california.plot(ax=ax)\nax.set_axis_off()\n\n\n\n\n\ncali_temp_max = get_variable_for_state(\n    data[\"SeasonalTemperatureMaximum\"],\n    california\n)\n\n\nfig, ax = plt.subplots(figsize=(16, 7), nrows=2, ncols=3, sharey='row', sharex='col')\nax = ax.flatten()\nax0 = cali_temp_max.plot(ax=ax[0], column='hist_winter', legend=True)\nax0.set_title('Winter [Historical]')\nax0.set_axis_off()\nax1 = cali_temp_max.plot(ax=ax[1], column='rcp85_midc_winter', legend=True)\nax1.set_axis_off()\nax1.set_title('Winter [RCP85: Mid-Century]')\nax2 = cali_temp_max.plot(ax=ax[2], column='rcp85_endc_winter', legend=True)\nax2.set_axis_off()\nax2.set_title('Winter [RCP85: End-Century]')\n\nax3 = cali_temp_max.plot(ax=ax[3], column='hist_summer', legend=True)\nax3.set_title('Summer [Historical]')\nax3.set_axis_off()\nax4 = cali_temp_max.plot(ax=ax[4], column='rcp85_mid_summer', legend=True)\nax4.set_axis_off()\nax4.set_title('Summer [RCP85: Mid-Century]')\nax5 = cali_temp_max.plot(ax=ax[5], column='rcp85_end_summer', legend=True)\nax5.set_axis_off()\nax5.set_title('Summer [RCP85: End-Century]')\nplt.tight_layout()\n\n\n\n\n\n\n\nCitationBibTeX citation:@misc{foreman2023,\n  author = {Foreman, Sam},\n  date = {2023-08-02},\n  url = {https://saforem2.github.io/climate-analysis},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nForeman, Sam. 2023. Intro to HPC: Climate Analysis with ClimRR.\nhttps://saforem2.github.io/climate-analysis."
  },
  {
    "objectID": "qmd/overview.html",
    "href": "qmd/overview.html",
    "title": "Project Overview: ClimRR",
    "section": "",
    "text": "In this project we will learn to (+ about):"
  },
  {
    "objectID": "qmd/overview.html#footnotes",
    "href": "qmd/overview.html#footnotes",
    "title": "Project Overview: ClimRR",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOur project directory is at:\n/global/cfs/cdirs/m4388/Project2-ClimRR/↩︎\nGetting Python setup correctly can be surprisingly difficult↩︎"
  },
  {
    "objectID": "qmd/extras/1-iris.html",
    "href": "qmd/extras/1-iris.html",
    "title": "Mapping and Plotting Tools with GeoPandas",
    "section": "",
    "text": "import geodatasets\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n\nchicago = gpd.read_file(geodatasets.get_path('geoda.chicago_commpop'))\ngroceries = gpd.read_file(geodatasets.get_path('geoda.groceries'))\nchicago.head()\n\n\n\n\n\n\n\n\ncommunity\nNID\nPOP2010\nPOP2000\nPOPCH\nPOPPERCH\npopplus\npopneg\ngeometry\n\n\n\n\n0\nDOUGLAS\n35\n18238\n26470\n-8232\n-31.099358\n0\n1\nMULTIPOLYGON (((-87.60914 41.84469, -87.60915 ...\n\n\n1\nOAKLAND\n36\n5918\n6110\n-192\n-3.142390\n0\n1\nMULTIPOLYGON (((-87.59215 41.81693, -87.59231 ...\n\n\n2\nFULLER PARK\n37\n2876\n3420\n-544\n-15.906433\n0\n1\nMULTIPOLYGON (((-87.62880 41.80189, -87.62879 ...\n\n\n3\nGRAND BOULEVARD\n38\n21929\n28006\n-6077\n-21.698922\n0\n1\nMULTIPOLYGON (((-87.60671 41.81681, -87.60670 ...\n\n\n4\nKENWOOD\n39\n17841\n18363\n-522\n-2.842673\n0\n1\nMULTIPOLYGON (((-87.59215 41.81693, -87.59215 ...\nax = chicago.plot()\nax.set_axis_off()\n\nax = chicago.plot(\n    column='POP2010',\n    legend=True,\n    legend_kwds={\n        'label': 'Population in 2010',\n        'orientation': 'vertical',\n    }\n)\nplt.tight_layout()\nax.set_axis_off()\nax = chicago.boundary.plot()\nax.set_axis_off()\nax = groceries.plot(marker='.', color='red', markersize=5)\ngroceries = groceries.to_crs(chicago.crs)\nimport geopandas\nimport geodatasets\n\nnybb = geopandas.read_file(geodatasets.get_path(\"nybb\"))\nchicago = geopandas.read_file(geodatasets.get_path(\"geoda.chicago_commpop\"))\ngroceries = geopandas.read_file(\n    geodatasets.get_path(\"geoda.groceries\")\n).explode(ignore_index=True)"
  },
  {
    "objectID": "qmd/extras/1-iris.html#climate-plots-using-iris",
    "href": "qmd/extras/1-iris.html#climate-plots-using-iris",
    "title": "Mapping and Plotting Tools with GeoPandas",
    "section": "Climate Plots using Iris",
    "text": "Climate Plots using Iris\nIris: A powerful, format-agnostic, community-drive Python package for analysing and visualizing Earth science data.\n\n\n\n\n\n\nNote\n\n\n\nThe plots below are just for testing functionality, WIP to replace with ClimRR data\n\n\n\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport warnings\n\nimport cartopy.crs as ccrs\nimport matplotlib.pyplot as plt\n\nimport iris\nimport iris.plot as iplt\nimport iris.quickplot as qplt\n\nwarnings.filterwarnings('ignore')\n# testing comment\n%matplotlib inline\nimport matplotlib_inline\nmatplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n\nfrom pathlib import Path\n\nfrom ClimRR import DATA_DIR\nplt.rcParams.update({\n    'axes.facecolor': 'none',\n    'figure.facecolor': 'none',\n    'savefig.facecolor': 'none',\n    'savefig.format': 'svg',\n    'axes.edgecolor': 'none',\n    'axes.grid': True,\n    'axes.labelcolor': '#666',\n    'axes.titlecolor': '#666',\n    'grid.color': '#666',\n    'text.color': '#666',\n    'grid.linestyle': '--',\n    'grid.linewidth': 0.5,\n    'grid.alpha': 0.4,\n    'xtick.color': 'none',\n    'ytick.color': 'none',\n    'xtick.labelcolor': '#666',\n    'legend.edgecolor': 'none',\n    'ytick.labelcolor': '#666',\n    'savefig.transparent': True,\n    'figure.figsize': (12.4, 4.8),\n})\n\n\nshape = gpd.read_file(\n    DATA_DIR.joinpath(\n        \"GridCellsShapefile/GridCells.shp\"\n    )\n)\nprint(f\"shape: {shape}\")\n\nshape:        OBJECTID Crossmodel    Shape_Leng    Shape_Area  \\\n0             1   R161C438  63614.764866  2.529273e+08   \n1             2   R125C222  61384.219597  2.355013e+08   \n2             3   R121C235  61111.892875  2.334164e+08   \n3             4   R169C431  64716.234995  2.617618e+08   \n4             5   R146C497  60142.919468  2.260731e+08   \n...         ...        ...           ...           ...   \n62829     62830   R055C359  54822.101620  1.878414e+08   \n62830     62831   R072C387  55964.448729  1.957512e+08   \n62831     62832   R085C337  57646.273207  2.076932e+08   \n62832     62833   R082C288  57528.265213  2.068438e+08   \n62833     62834   R088C416  56916.790562  2.024700e+08   \n\n                                                geometry  \n0      POLYGON ((-9530601.177 4726046.614, -9534793.8...  \n1      POLYGON ((-12959076.287 4395610.472, -12974301...  \n2      POLYGON ((-12754805.395 4355815.951, -12770000...  \n3      POLYGON ((-9605729.481 4879238.815, -9609863.1...  \n4      POLYGON ((-8733007.764 4224658.634, -8738250.3...  \n...                                                  ...  \n62829  POLYGON ((-10965528.715 3400674.224, -10966978...  \n62830  POLYGON ((-10550370.700 3584259.218, -10552496...  \n62831  POLYGON ((-11249641.912 3850046.022, -11235259...  \n62832  POLYGON ((-11942487.554 3816894.598, -11956857...  \n62833  POLYGON ((-10110300.079 3720413.967, -10124231...  \n\n[62834 rows x 5 columns]\n\n\n\nshape.plot()\n\n&lt;Axes: &gt;\n\n\n\n\n\n\nimport cartopy.crs as ccrs\nimport matplotlib.pyplot as plt\n\nimport iris\nimport iris.analysis.cartography\nimport iris.plot as iplt\nimport iris.quickplot as qplt\n\n# Load some test data.\nfname = iris.sample_data_path(\"rotated_pole.nc\")\nair_pressure = iris.load_cube(fname)\n\n# Plot #1: Point plot showing data values & a colorbar\n# plt.figure()\nfig, ax = plt.subplots()\npoints = qplt.points(air_pressure, c=air_pressure.data)\ncb = plt.colorbar(points, orientation=\"horizontal\")\ncb.set_label(air_pressure.units)\nplt.gca().coastlines()\n\n# Plot #2: Contourf of the point based data\nplt.figure()\nqplt.contourf(air_pressure, 15)\nplt.gca().coastlines()\n# iplt.show()\n\n# Plot #3: Contourf overlaid by coloured point data\nplt.figure()\nqplt.contourf(air_pressure)\niplt.points(air_pressure, c=air_pressure.data)\nplt.gca().coastlines()\n\n# For the purposes of this example, add some bounds to the latitude\n# and longitude\nair_pressure.coord(\"grid_latitude\").guess_bounds()\nair_pressure.coord(\"grid_longitude\").guess_bounds()\n\n# Plot #4: Block plot\nplt.figure()\n# fig, ax = plt.subplots()\nplt.axes(projection=ccrs.PlateCarree())\niplt.pcolormesh(air_pressure)\nplt.gca().stock_img()\nplt.gca().coastlines()\n\n&lt;cartopy.mpl.feature_artist.FeatureArtist at 0x2ad0ccf10&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfname = iris.sample_data_path(\"air_temp.pp\")\ntemperature = iris.load_cube(fname)\n\nfig, ax = plt.subplots()\n\n# Plot #1: contourf with axes longitude from -180 to 180\n#plt.figure(figsize=(8, 5))\nplt.subplot(121)\nqplt.contourf(temperature, 15)\nfig.gca().coastlines()\n\n# Plot #2: contourf with axes longitude from 0 to 360\nproj = ccrs.PlateCarree(central_longitude=-180.0)\nplt.subplot(122, projection=proj)\nqplt.contourf(temperature, 15)\nfig.gca().coastlines()\n\n&lt;cartopy.mpl.feature_artist.FeatureArtist at 0x2ad3d8250&gt;\n\n\n\n\n\n\nfname = iris.sample_data_path(\"air_temp.pp\")\n\nfig, ax = plt.subplots()\n# Load exactly one cube from the given file.\ntemperature = iris.load_cube(fname)\n# We only want a small number of latitudes, so filter some out\n# using \"extract\".\ntemperature = temperature.extract(\n    iris.Constraint(latitude=lambda cell: 68 &lt;= cell &lt; 78)\n)\n\nfor cube in temperature.slices(\"longitude\"):\n    # Create a string label to identify this cube (i.e. latitude: value).\n    cube_label = \"latitude: %s\" % cube.coord(\"latitude\").points[0]\n\n    # Plot the cube, and associate it with a label.\n    qplt.plot(cube, label=cube_label)\n\n# Add the legend with 2 columns.\nax.legend(ncol=2)\n# Put a grid on the plot.\nax.grid(True)\n# Tell matplotlib not to extend the plot axes range to nicely\n# rounded numbers.\nplt.axis(\"tight\")\n\n(-17.81249542236328, 374.0624038696289, 253.4506408691406, 277.34959106445314)"
  },
  {
    "objectID": "qmd/extras/1-iris.html#test-data-showing-inset-plots",
    "href": "qmd/extras/1-iris.html#test-data-showing-inset-plots",
    "title": "Mapping and Plotting Tools with GeoPandas",
    "section": "Test Data Showing Inset Plots",
    "text": "Test Data Showing Inset Plots\nThis example demonstrates the use of a single 3D data cube with time, latitude and longitude dimensions to plot a temperature series for a single latitude coordinate, with an inset plot of the data region.\n\nimport numpy as np\ncube1 = iris.load_cube(iris.sample_data_path(\"ostia_monthly.nc\"))\n# Slice into cube to retrieve data for the inset map showing the\n# data region\nregion = cube1[-1, :, :]\n# Average over latitude to reduce cube to 1 dimension\nplot_line = region.collapsed(\"latitude\", iris.analysis.MEAN)\n\n# Open a window for plotting\nfig = plt.figure()\n# Add a single subplot (axes). Could also use \"ax_main = plt.subplot()\"\nax_main = fig.add_subplot(1, 1, 1)\n# Produce a quick plot of the 1D cube\nqplt.plot(plot_line)\n\n# Set x limits to match the data\nax_main.set_xlim(0, plot_line.coord(\"longitude\").points.max())\n# Adjust the y limits so that the inset map won't clash with main plot\nax_main.set_ylim(294, 310)\nax_main.set_title(\"Meridional Mean Temperature\")\n# Add grid lines\nax_main.grid()\n\n# Add a second set of axes specifying the fractional coordinates within\n# the figure with bottom left corner at x=0.55, y=0.58 with width\n# 0.3 and height 0.25.\n# Also specify the projection\nax_sub = fig.add_axes(\n  [0.55, 0.58, 0.3, 0.25],\n  projection=ccrs.Mollweide(central_longitude=180),\n)\n\n# Use iris.plot (iplt) here so colour bar properties can be specified\n# Also use a sequential colour scheme to reduce confusion for those with\n# colour-blindness\niplt.pcolormesh(region, cmap=\"Blues\")\n# Manually set the orientation and tick marks on your colour bar\nticklist = np.linspace(np.min(region.data), np.max(region.data), 4)\nplt.colorbar(orientation=\"horizontal\", ticks=ticklist)\nax_sub.set_title(\"Data Region\")\n# Add coastlines\nax_sub.coastlines()\n# request to show entire map, using the colour mesh on the data region only\nax_sub.set_global()\n\n\n\n\n\nimport iris\n\nimport numpy as np\nimport iris.plot as iplt\nimport iris.quickplot as qplt\n\nfrom iris.analysis import MEAN\n\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\n\n# Loads air_temp.pp and \"collapses\" longitude into a single, average value.\nfname = iris.sample_data_path(\"air_temp.pp\")\ntemperature = iris.load_cube(fname)\ncollapsed_temp = temperature.collapsed(\"longitude\", MEAN)\n\n\n# Set y-axes with -90 and 90 limits and steps of 15 per tick.\nstart, stop, step = -90, 90, 15\nyticks = np.arange(start, stop + step, step)\nylim = [start, stop]\n\n# Plot \"temperature\" on a cartographic plot and set the ticks and titles\n# on the axes.\nfig = plt.figure(figsize=[12, 8])\n#fig, ax = plt.subplots()\n\nax1 = fig.add_subplot(111, projection=ccrs.PlateCarree())\nim = iplt.contourf(temperature, cmap=\"RdYlBu_r\")\nax1.coastlines()\nax1.gridlines()\nax1.set_xticks([-180, -90, 0, 90, 180])\nax1.set_yticks(yticks)\nax1.set_title(\"Air Temperature\")\nax1.set_ylabel(f\"Latitude / {temperature.coord('latitude').units}\")\nax1.set_xlabel(f\"Longitude / {temperature.coord('longitude').units}\")\nax1.set_ylim(*ylim)\n\n# Create a Matplotlib AxesDivider object to allow alignment of other\n# Axes objects.\ndivider = make_axes_locatable(ax1)\n\n# Gives the air temperature bar size, colour and a title.\nax2 = divider.new_vertical(\n    size=\"5%\", pad=0.5, axes_class=plt.Axes, pack_start=True\n)  # creates 2nd axis\nfig.add_axes(ax2)\ncbar = plt.colorbar(\n    im, cax=ax2, orientation=\"horizontal\"\n)  # puts colour bar on second axis\ncbar.ax.set_xlabel(f\"{temperature.units}\")  # labels colour bar\n\n# Plot \"collapsed_temp\" on the mean graph and set the ticks and titles\n# on the axes.\nax3 = divider.new_horizontal(\n    size=\"30%\", pad=0.4, axes_class=plt.Axes\n)  # create 3rd axis\nfig.add_axes(ax3)\nqplt.plot(\n    collapsed_temp, collapsed_temp.coord(\"latitude\")\n)  # plots temperature collapsed over longitude against latitude\nax3.axhline(0, color=\"k\", linewidth=0.5)\n\n# Creates zonal mean details\nax3.set_title(\"Zonal Mean\")\nax3.yaxis.set_label_position(\"right\")\nax3.yaxis.tick_right()\nax3.set_yticks(yticks)\nax3.grid()\n\n# Round each tick for the third ax to the nearest 20 (ready for use).\ndata_max = collapsed_temp.data.max()\nx_max = data_max - data_max % -20\ndata_min = collapsed_temp.data.min()\nx_min = data_min - data_min % 20\nax3.set_xlim(x_min, x_max)\nax3.set_ylim(*ylim)\nplt.tight_layout()\n\n\n\n\n\nfname = iris.sample_data_path(\"air_temp.pp\")\n\n# Load exactly one cube from the given file.\ntemperature = iris.load_cube(fname)\n\n# We only want a small number of latitudes, so filter some out\n# using \"extract\".\ntemperature = temperature.extract(\n    iris.Constraint(latitude=lambda cell: 68 &lt;= cell &lt; 78)\n)\n\nfig, ax = plt.subplots()\n\nfor cube in temperature.slices(\"longitude\"):\n    # Create a string label to identify this cube (i.e. latitude: value).\n    cube_label = \"latitude: %s\" % cube.coord(\"latitude\").points[0]\n\n    # Plot the cube, and associate it with a label.\n    qplt.plot(cube, label=cube_label)\n\n# Add the legend with 2 columns.\nax.legend(ncol=2)\n\n# Put a grid on the plot.\nax.grid(True)\n\n# Tell matplotlib not to extend the plot axes range to nicely\n# rounded numbers.\nplt.axis(\"tight\")\n\n(-17.81249542236328, 374.0624038696289, 253.4506408691406, 277.34959106445314)\n\n\n\n\n\n\nimport iris.coord_categorisation\nimport matplotlib.colors as mcols\n\n\nfig, ax = plt.subplots()\n# Load a sample air temperatures sequence.\nfile_path = iris.sample_data_path(\"E1_north_america.nc\")\ntemperatures = iris.load_cube(file_path)\n\n# Create a year-number coordinate from the time information.\niris.coord_categorisation.add_year(temperatures, \"time\")\n\n# Create a sample anomaly field for one chosen year, by extracting that\n# year and subtracting the time mean.\nsample_year = 1982\nyear_temperature = temperatures.extract(iris.Constraint(year=sample_year))\ntime_mean = temperatures.collapsed(\"time\", iris.analysis.MEAN)\nanomaly = year_temperature - time_mean\n\n# Construct a plot title string explaining which years are involved.\nyears = temperatures.coord(\"year\").points\nplot_title = \"Temperature anomaly\"\nplot_title += \"\\n{} differences from {}-{} average.\".format(\n    sample_year, years[0], years[-1]\n)\n\n# Define scaling levels for the logarithmic colouring.\nminimum_log_level = 0.1\nmaximum_scale_level = 3.0\n\n# Use a standard colour map which varies blue-white-red.\n# For suitable options, see the 'Diverging colormaps' section in:\n# http://matplotlib.org/stable/gallery/color/colormap_reference.html\nanom_cmap = \"bwr\"\n\n# Create a 'logarithmic' data normalization.\nanom_norm = mcols.SymLogNorm(\n    linthresh=minimum_log_level,\n    linscale=0.01,\n    vmin=-maximum_scale_level,\n    vmax=maximum_scale_level,\n)\n# Setting \"linthresh=minimum_log_level\" makes its non-logarithmic\n# data range equal to our 'zero band'.\n# Setting \"linscale=0.01\" maps the whole zero band to the middle colour value\n# (i.e., 0.5), which is the neutral point of a \"diverging\" style colormap.\n\n# Create an Axes, specifying the map projection.\nplt.axes(projection=ccrs.LambertConformal())\n\n# Make a pseudocolour plot using this colour scheme.\nmesh = iplt.pcolormesh(anomaly, cmap=anom_cmap, norm=anom_norm)\n\n# Add a colourbar, with extensions to show handling of out-of-range values.\nbar = plt.colorbar(mesh, orientation=\"horizontal\", extend=\"both\")\n\n# Set some suitable fixed \"logarithmic\" colourbar tick positions.\ntick_levels = [-3, -1, -0.3, 0.0, 0.3, 1, 3]\nbar.set_ticks(tick_levels)\n\n# Modify the tick labels so that the centre one shows \"+/-&lt;minumum-level&gt;\".\ntick_levels[3] = r\"$\\pm${:g}\".format(minimum_log_level)\nbar.set_ticklabels(tick_levels)\n\n# Label the colourbar to show the units.\nbar.set_label(\"[{}, log scale]\".format(anomaly.units))\n\n# Add coastlines and a title.\nplt.gca().coastlines()\nplt.title(plot_title)\n\nText(0.5, 1.0, 'Temperature anomaly\\n1982 differences from 1860-2099 average.')"
  },
  {
    "objectID": "qmd/00-GettingStarted/3-example-groceries.html",
    "href": "qmd/00-GettingStarted/3-example-groceries.html",
    "title": "Example: Groceries in Chicago",
    "section": "",
    "text": "Imports\nfrom rich.console import Console as Console\nfrom enrich.style import STYLES\nfrom rich.theme import Theme\nconsole = Console(theme=Theme(STYLES), log_path=False, markup=True)"
  },
  {
    "objectID": "qmd/00-GettingStarted/3-example-groceries.html#imports",
    "href": "qmd/00-GettingStarted/3-example-groceries.html#imports",
    "title": "Example: Groceries in Chicago",
    "section": "Imports",
    "text": "Imports\n\n%load_ext autoreload\n%autoreload 2\n%matplotlib inline\nimport matplotlib_inline\nimport matplotlib.pyplot as plt\nmatplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n\nimport geopandas as gpd\nfrom shapely.geometry import box\nimport geodatasets\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload"
  },
  {
    "objectID": "qmd/00-GettingStarted/3-example-groceries.html#get-or-create-example-data",
    "href": "qmd/00-GettingStarted/3-example-groceries.html#get-or-create-example-data",
    "title": "Example: Groceries in Chicago",
    "section": "Get or Create Example Data",
    "text": "Get or Create Example Data\nBelow, the example GeoPandas data is imported and opened as a GeoDataFrame.\nAdditionally, a polygon is created with shapely and then converted into a GeoDataFrame with the same CRS as the GeoPandas dataset\n\nimport geodatasets\nchicago = gpd.read_file(geodatasets.get_path(\"geoda.chicago_commpop\"))\ngroceries = gpd.read_file(geodatasets.get_path(\"geoda.groceries\")).to_crs(chicago.crs)\n\nCreate a subset of the chicago data that is just the near west side\n\nnear_west_side = chicago[chicago[\"community\"] == \"NEAR WEST SIDE\"]\nlincoln_park = chicago[chicago[\"community\"] == \"LINCOLN PARK\"]\nlogan_square = chicago[chicago[\"community\"] == \"LOGAN SQUARE\"]\n\nCreate a custom polygon\n\npolygon = box(-87.8, 41.9, -87.5, 42)\npoly_gdf = gpd.GeoDataFrame([1], geometry=[polygon], crs=chicago.crs)"
  },
  {
    "objectID": "qmd/00-GettingStarted/3-example-groceries.html#plot-the-unclipped-data",
    "href": "qmd/00-GettingStarted/3-example-groceries.html#plot-the-unclipped-data",
    "title": "Example: Groceries in Chicago",
    "section": "Plot the Unclipped Data",
    "text": "Plot the Unclipped Data\n\nfig, (ax1, ax2) = plt.subplots(figsize=(14, 6), ncols=2, sharey='col')\npoly_gdf.boundary.plot(ax=ax1, color=COLORS['red'])\nchicago.boundary.plot(ax=ax1, color=COLORS['grey060'], linewidth=0.6, zorder=-1)\n# near_west_side.boundary.plot(ax=ax2, color=COLORS['red'])\n# near_west_side.plot(ax=ax2, color=COLORS['green'], alpha=0.3)\n# west_town.plot(ax=ax2, color=COLORS['green'], alpha=0.3)\nchicago.plot(ax=ax1, alpha=0.4)\npoly_gdf.boundary.plot(ax=ax2, color=COLORS['red'])\nchicago.boundary.plot(ax=ax2, color=COLORS['grey060'], linewidth=0.6, zorder=-1)\ngroceries.plot(ax=ax2, color=COLORS['blue'], zorder=1, marker='.', alpha=0.66)\nax1.set_title(\"All Unclipped Chicago Communities\", fontsize=20)\nax2.set_title(\"All Unclipped Groceries\", fontsize=20)\nax1.set_axis_off()\nax2.set_axis_off()\nplt.tight_layout()"
  },
  {
    "objectID": "qmd/00-GettingStarted/3-example-groceries.html#clip-the-data",
    "href": "qmd/00-GettingStarted/3-example-groceries.html#clip-the-data",
    "title": "Example: Groceries in Chicago",
    "section": "Clip the Data",
    "text": "Clip the Data\nThe object on which you call clip is the object that will be clipped.\nThe object you pass is the clip extent.\nThe returned output will be a new clipped GeoDataFrame. All of the attributes for each returned geometry will be retained when you clip.\n\n\n\n\n\n\nCoordinate Reference System\n\n\n\n\n\nRecall that the data must be in the same CRS in order to use the clip method.\nIf the data is not in the same CRS, be sure to use the GeoDataFrame.to_crs method to ensure both datasets are in the same CRS.\n\n\n\n\n# clip the data to the boundary of the polygon\nchicago_clipped = chicago.clip(polygon)\ngroceries_clipped = groceries.clip(polygon)\n\n# create figure with two columns\nfig, ax = plt.subplots(figsize=(14, 6), ncols=2, sharey='col')\n\n# aggregate data into a dictionary for each column\nclipped = {\n    'chicago': {\n        'ax': ax[0],\n        'color': 'C0',\n        'marker': None,\n        'data': chicago_clipped,\n        'label': 'Chicago Clipped'\n    },\n    'groceries': {\n        'ax': ax[1],\n        'color': 'C1',\n        'marker': '.',\n        'data': groceries_clipped,\n        'label': 'Groceries Clipped'\n    }\n}\n\n# iterate over the dictionary, plotting\n# each entry in its own subplot (column)\nfor key, val in clipped.items():\n    _ = val['data'].plot(\n        ax=val['ax'],\n        color=val['color'],\n        marker=val['marker'],\n        alpha=0.5,\n    )\n    _ = chicago.boundary.plot(\n        ax=val['ax'],\n        color=COLORS['grey060'],\n        zorder=-1,\n        linewidth=0.6\n    )\n    ax = poly_gdf.boundary.plot(\n        ax=val['ax'],\n        color=COLORS['red']\n    )\n    ax.set_title(val['label'], fontsize=20)\n    ax.set_axis_off()\n\nplt.tight_layout()"
  },
  {
    "objectID": "qmd/00-GettingStarted/3-example-groceries.html#clip-the-chicago-data",
    "href": "qmd/00-GettingStarted/3-example-groceries.html#clip-the-chicago-data",
    "title": "Example: Groceries in Chicago",
    "section": "Clip the Chicago Data",
    "text": "Clip the Chicago Data\n\nchicago_clipped = chicago.clip(polygon)\ngroceries_clipped = groceries.clip(polygon)\n# plot the clipped data\nfig, ax = plt.subplots(figsize=(14, 6), ncols=2)\nax0 = chicago_clipped.plot(ax=ax[0], color='C0', alpha=0.66)\nax0 = chicago.boundary.plot(ax=ax[0], color=COLORS['grey060'], zorder=-1, linewidth=0.6)\nax0 = poly_gdf.boundary.plot(ax=ax[0], color=COLORS['red'])\n\nax1 = groceries_clipped.plot(ax=ax[1], color='C1', alpha=0.66, zorder=10, marker='.')\n# chicago.boundary.plot(ax=ax[1], color='#444444')\nax1 = chicago.boundary.plot(ax=ax[1], color=COLORS['grey060'], zorder=-1, linewidth=0.6)\nax1 = poly_gdf.boundary.plot(ax=ax[1], color=COLORS['red'])\n\nax0.set_title(\"Chicago Clipped\", fontsize=20)\nax0.set_axis_off()\nax1.set_title(\"Groceries Clipped\", fontsize=20)\nax1.set_axis_off()\nplt.tight_layout()"
  },
  {
    "objectID": "qmd/00-GettingStarted/3-example-groceries.html#clip-the-groceries-data",
    "href": "qmd/00-GettingStarted/3-example-groceries.html#clip-the-groceries-data",
    "title": "Example: Groceries in Chicago",
    "section": "Clip the Groceries Data",
    "text": "Clip the Groceries Data\nNext we’ll look at the distribution of grocery stores in two different communities.\n\n\n\nfig, (ax1, ax2) = plt.subplots(figsize=(14, 6), ncols=2, sharey='col')\n\nchicago.plot(ax=ax1, alpha=0.4)\n\n# near_west_side.boundary.plot(ax=ax2, color=COLORS['red'])\n# logan_square.boundary.plot(ax=ax2, color=COLORS['red'])\n\nnear_west_side.plot(ax=ax2, color=COLORS['red'], alpha=0.3)\nlogan_square.plot(ax=ax2, color=COLORS['red'], alpha=0.3)\n\nchicago.boundary.plot(ax=ax1, color=COLORS['grey060'], linewidth=0.6, zorder=-1)\nchicago.boundary.plot(ax=ax2, color=COLORS['grey060'], linewidth=0.6, zorder=-1)\n\ngroceries.plot(ax=ax2, color=COLORS['blue'], zorder=1, marker='.', alpha=0.66)\nax1.set_title(\"Chicago Communities\", fontsize=20)\nax2.set_title(\"Grocery Stores\", fontsize=20)\nax1.set_axis_off()\nax2.set_axis_off()\nplt.tight_layout()\n\n\n\n\nFigure 2: Visualization of the communities of Chicago (left) and the locations of grocery stores throughout the city."
  },
  {
    "objectID": "qmd/00-GettingStarted/3-example-groceries.html#groceries-in-near-west-side",
    "href": "qmd/00-GettingStarted/3-example-groceries.html#groceries-in-near-west-side",
    "title": "Example: Groceries in Chicago",
    "section": "Groceries in Near West Side",
    "text": "Groceries in Near West Side\n\n\ngroceries_west_side = groceries.clip(near_west_side)\nfig, ax = plt.subplots(figsize=(14, 6))\ngroceries_west_side.plot(ax=ax, color='C2', marker='.', alpha=0.6)\nchicago.boundary.plot(ax=ax, color=COLORS['grey060'], linewidth=0.6, zorder=-1)\nnear_west_side.boundary.plot(ax=ax, color='#444444')\nnear_west_side.boundary.plot(ax=ax, color=COLORS['red'])\nnear_west_side.plot(ax=ax, color=COLORS['green'], alpha=0.3)\nax.set_title(\"Groceries in the Near West Side\")\nax.set_axis_off()"
  },
  {
    "objectID": "qmd/00-GettingStarted/3-example-groceries.html#groceries-in-logan-square",
    "href": "qmd/00-GettingStarted/3-example-groceries.html#groceries-in-logan-square",
    "title": "Example: Groceries in Chicago",
    "section": "Groceries in Logan Square",
    "text": "Groceries in Logan Square\n\n\ngroceries_logan_square = groceries.clip(logan_square)\nfig, ax = plt.subplots(figsize=(14,6))\ngroceries_logan_square.plot(ax=ax, color='C2', marker='.', alpha=0.6)\nchicago.boundary.plot(ax=ax, color=COLORS['grey060'], linewidth=0.6, zorder=-1)\nlogan_square.boundary.plot(ax=ax, color='#444444')\nlogan_square.boundary.plot(ax=ax, color=COLORS['red'])\nlogan_square.plot(ax=ax, color=COLORS['green'], alpha=0.3)\nax.set_title(\"Groceries in Logan Square\")\nax.set_axis_off()"
  },
  {
    "objectID": "qmd/00-GettingStarted/3-example-groceries.html#groceries-in-lincoln-park",
    "href": "qmd/00-GettingStarted/3-example-groceries.html#groceries-in-lincoln-park",
    "title": "Example: Groceries in Chicago",
    "section": "Groceries in Lincoln Park",
    "text": "Groceries in Lincoln Park\n\n\ngroceries_lp = groceries.clip(lincoln_park)\nfig, ax = plt.subplots(figsize=(14,6))\ngroceries_lp.plot(ax=ax, color='C2')\nchicago.boundary.plot(ax=ax, color=COLORS['grey060'], linewidth=0.6, zorder=-1)\nlincoln_park.boundary.plot(ax=ax, color='#444444')\nlincoln_park.boundary.plot(ax=ax, color=COLORS['red'])\nlincoln_park.plot(ax=ax, color=COLORS['green'], alpha=0.3)\nax.set_title(\"Groceries in Lincoln Park\")\nax.set_axis_off()"
  },
  {
    "objectID": "qmd/00-GettingStarted/3-example-groceries.html#additional-questions",
    "href": "qmd/00-GettingStarted/3-example-groceries.html#additional-questions",
    "title": "Example: Groceries in Chicago",
    "section": "Additional Questions",
    "text": "Additional Questions\n\nCan you identify which neighborhoods have the most grocery stores? How many?\n\nWhich have the least? How many?"
  },
  {
    "objectID": "qmd/00-GettingStarted/3-example-groceries.html#reference",
    "href": "qmd/00-GettingStarted/3-example-groceries.html#reference",
    "title": "Example: Groceries in Chicago",
    "section": "Reference",
    "text": "Reference\nGeoPandas: Clip Vector Data"
  }
]